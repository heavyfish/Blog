<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/heavyfish.github.io/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/heavyfish.github.io/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/heavyfish.github.io/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/heavyfish.github.io/images/logo.svg" color="#222">

<link rel="stylesheet" href="/heavyfish.github.io/css/main.css">


<link rel="stylesheet" href="/heavyfish.github.io/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"heavyfish.github.io","root":"/heavyfish.github.io/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="速查笔记">
<meta property="og:url" content="https://heavyfish.github.io/index.html">
<meta property="og:site_name" content="速查笔记">
<meta property="og:locale">
<meta property="article:author" content="Shenxr">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://heavyfish.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>速查笔记</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/heavyfish.github.io/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">速查笔记</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/heavyfish.github.io/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/heavyfish.github.io/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://heavyfish.github.io/2020/11/24/k8s/%E4%BB%8B%E7%BB%8DKubernetes%E5%AE%B9%E5%99%A8%E5%AD%98%E5%82%A8%E6%8E%A5%E5%8F%A3%EF%BC%88CSI%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/heavyfish.github.io/images/avatar.gif">
      <meta itemprop="name" content="Shenxr">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="速查笔记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/heavyfish.github.io/2020/11/24/k8s/%E4%BB%8B%E7%BB%8DKubernetes%E5%AE%B9%E5%99%A8%E5%AD%98%E5%82%A8%E6%8E%A5%E5%8F%A3%EF%BC%88CSI%EF%BC%89/" class="post-title-link" itemprop="url">CSI简介</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-24 14:25:08" itemprop="dateCreated datePublished" datetime="2020-11-24T14:25:08+08:00">2020-11-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-14 22:54:49" itemprop="dateModified" datetime="2021-01-14T22:54:49+08:00">2021-01-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/heavyfish.github.io/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Kubernetes-设计文档中的-CSI-Volume-Plugins"><a href="#Kubernetes-设计文档中的-CSI-Volume-Plugins" class="headerlink" title="Kubernetes 设计文档中的 CSI Volume Plugins"></a>Kubernetes 设计文档中的 CSI Volume Plugins</h1><p>本文翻译于 <a target="_blank" rel="noopener" href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/storage/container-storage-interface.md">CSI Volume Plugins in Kubernetes Design Doc</a></p>
<h2 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h2><table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody><tr>
<td>Container Storage Interface (CSI)</td>
<td>一种规范，试图建立一个行业标准接口，Container Orchestration Systems（COs）可以使用该接口将任意存储系统暴露在其容器化工作负载下。</td>
</tr>
<tr>
<td>in-tree</td>
<td>存在于核心Kubernetes存储库中的代码。</td>
</tr>
<tr>
<td>out-of-tree</td>
<td>存在于核心Kubernetes存储库之外的代码。</td>
</tr>
<tr>
<td>CSI Volume Plugin</td>
<td>一个新的in-tree volume plugin，充当适配器，支持在Kubernetes中使用 out-of-tree 第三方 CSI volume drivers。</td>
</tr>
<tr>
<td>CSI Volume Driver</td>
<td>一个与 out-of-tree CSI兼容的volume plugin 实现，可以通过Kubernetes CSI volume plugin 在Kubernetes中使用</td>
</tr>
</tbody></table>
<h2 id="背景和动机"><a href="#背景和动机" class="headerlink" title="背景和动机"></a>背景和动机</h2><p>容器存储接口（CSI）是一种规范，它是由来自不同COs的社区成员之间的合作所产生的，包括Kubernetes、Mesos、CloudFoundry和Docker。该接口的目标是为COs建立标准化机制，以将任意存储系统暴露到其容器化工作负载中。</p>
<p>存储供应商采用该接口的主要动机是希望让他们的系统尽可能多地为用户所用，而只需尽可能少的工作。COs采用该接口的主要动机是采用一种机制，使其用户能够使用尽可能多的不同存储系统。此外，对于Kubernetes，采用CSI还有一个额外的好处：将卷插件移出树，并使卷插件能够被容器化。</p>
<p><strong>Links</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/container-storage-interface/spec/blob/master/spec.md">Container Storage Interface (CSI) Spec</a></li>
</ul>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>本文档的目的是记录在Kubernetes中启用CSI兼容的卷插件（CSI卷驱动程序）的所有要求</p>
<h3 id="主要目标"><a href="#主要目标" class="headerlink" title="主要目标"></a>主要目标</h3><ul>
<li>Define Kubernetes API 和 任意第三方 CSI volume drivers 交互.</li>
<li>定义Kubernetes主节点组件和工作节点组件与任意第三方CSI volume drivers安全通信的机制</li>
<li>定义一种机制，Kubernetes主组件和节点组件将发现并注册部署在Kubernetes上的任意第三方CSI卷驱动程序。</li>
<li>对 Kubernetes兼容的第三方CSI卷驱动程序的打包要求 提出 建议。</li>
<li>对 Kubernetes集群上与Kubernetes兼容的第三方CSI卷驱动程序的部署过程 提出建议</li>
</ul>
<h3 id="不包含目标"><a href="#不包含目标" class="headerlink" title="不包含目标"></a>不包含目标</h3><p>Replace <a target="_blank" rel="noopener" href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-storage/flexvolume.md">Flex Volume plugin</a></p>
<ul>
<li>Flex卷插件是作为一种基于exec的机制来创建“out-of-tree”卷插件的</li>
<li>因为Flex驱动程序存在并依赖于Flex接口，因此它将继续得到稳定API的支持。.</li>
<li>CSI卷插件将与Flex卷插件共存。</li>
</ul>
<h2 id="设计概述"><a href="#设计概述" class="headerlink" title="设计概述"></a>设计概述</h2><p>为了支持CSI兼容的卷插件，Kubernetes将引入一个新的树内（in-tree）CSI卷插件。这个新的卷插件将是Kubernetes用户（应用程序开发人员和集群管理员）与外部CSI卷驱动程序交互的机制。</p>
<p>新的树内CSI卷插件的<code>SetUp/TearDown</code>调用将通过节点计算机上的unix域套接字直接调用<code>NodePublishVolume</code>和<code>NodeUnpublishVolume</code> CSI RPCs。</p>
<p>Provision/delete and attach/detach 必须由某个外部组件处理，该组件代表CSI卷驱动程序监视Kubernetes API，并针对它调用相应的CSI RPC。</p>
<p>为了简化集成，Kubernetes团队将提供一个容器，该容器捕获所有Kubernetes特定的逻辑，并充当第三方容器化CSI卷驱动程序和Kubernetes之间的适配器（CSI驱动程序的每个部署都有自己的适配器实例）。</p>
<h2 id="设计细节"><a href="#设计细节" class="headerlink" title="设计细节"></a>设计细节</h2><h3 id="Third-Party-CSI-Volume-Drivers"><a href="#Third-Party-CSI-Volume-Drivers" class="headerlink" title="Third-Party CSI Volume Drivers"></a>Third-Party CSI Volume Drivers</h3><p>Kubernetes在CSI卷驱动程序的打包和部署上尽可能少做规范。在Kubernetes中，启用任意外部CSI兼容存储驱动程序的唯一要求是使用 <em>Communication Channels</em></p>
<p>本文推荐一种标准机制，用于在Kubernetes上部署任意的容器化CSI驱动程序。存储提供商可以使用这一点简化Kubernetes上容器化CSI兼容卷驱动程序的部署（请参阅下面的“在Kubernetes上部署CSI驱动程序的推荐机制”一节）。然而，这种机制是严格可选的。</p>
<h3 id="Communication-Channels"><a href="#Communication-Channels" class="headerlink" title="Communication Channels"></a>Communication Channels</h3><h4 id="Kubelet-to-CSI-Driver-Communication"><a href="#Kubelet-to-CSI-Driver-Communication" class="headerlink" title="Kubelet to CSI Driver Communication"></a>Kubelet to CSI Driver Communication</h4><p><strong>Kubelet（负责mount and unmount）</strong>将通过一个Unix域套接字与运行在同一台主机（无论是否容器化）上的外部“CSI卷驱动程序”通信。</p>
<p>CSI卷驱动程序应在节点计算机上的以下路径创建一个套接字：</p>
<p><code>/var/lib/kubelet/plugins/[SanitizedCSIDriverName]/csi.sock</code>，对于 alpha，kubelet将假定这是Unix域套接字与CSI卷驱动程序对话的位置。对于beta版的实现，我们考虑使用 <a target="_blank" rel="noopener" href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-management/device-plugin.md#unix-socket">Device Plugin Unix Domain Socket Registration</a> 机制向kubelet注册Unix域套接字。这个机制需要被扩展以支持CSI卷驱动程序和设备插件的独立注册。</p>
<p><code>Sanitized CSIDriverName</code>是CSI驱动程序名称，不包含危险字符，可以用作 annotation 名称。它可以遵循与<a target="_blank" rel="noopener" href="https://git.k8s.io/utils/strings/escape.go#L28">volume plugins</a>相同的模式。太长或太复杂的驱动程序名称可能会被拒绝，也就是说，本文档中描述的所有组件都将报告错误，并且不会与该CSI驱动程序通信。</p>
<ul>
<li>在初始化外部“CSI volume driver”时，kubelet必须调用CSI method <code>NodeGetInfo</code>以获取从Kubernetes Node names 到CSI driver NodeID的映射以及相关的<code>accessible_topology</code>。它必须：<ul>
<li>这将使发出<code>ControllerPublishVolume</code>调用的组件能够使用<code>CSINodeInfo</code>作为从 cluster node ID 到 storage node ID的映射。</li>
<li>这将使发出<code>CreateVolume</code>的组件能够重建 <code>accessible_topology</code> ，并提供可从特定节点访问的卷。</li>
<li>每个驱动程序必须完全覆盖其以前版本的NodeID和topology keys（如果存在的话）</li>
<li>如果<code>NodeGetInfo</code>调用失败，kubelet必须删除此驱动程序以前的任何 NodeID和topology keys </li>
<li>在实现kubelet插件注销机制时，在注销驱动程序时删除 NodeID and topology keys</li>
</ul>
</li>
<li>Create/update Node API object ，将<code>accessible_topology</code> 作为 lable，标签格式没有硬限制，但是对于推荐的设置使用的格式，请参考 <a target="_blank" rel="noopener" href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/storage/container-storage-interface.md#topology-representation-in-node-objects">Topology Representation in Node Objects</a></li>
</ul>
<p>为了方便部署外部容器化CSI卷驱动程序，Kubernetes团队将提供一个sidecar“Kubernetes CSI Helper”容器，它可以管理unix域套接字注册和Node Id初始化。下面的“在Kubernetes上部署CSI驱动程序的建议机制”一节对此进行了详细说明。</p>
<h4 id="Master-to-CSI-Driver-Communication"><a href="#Master-to-CSI-Driver-Communication" class="headerlink" title="Master to CSI Driver Communication"></a>Master to CSI Driver Communication</h4><p>因为CSI卷驱动程序代码被认为是不可信的，所以它可能不允许在 master 上运行。因此，<strong>Kube controller manager（负责create, delete, attach, 和 detach）</strong>不能通过Unix域套接字与“CSI卷驱动程序”容器通信。相反，Kube controller manager 将通过 kubernetes Api与外部“CSI卷驱动程序”通信。</p>
<p>更具体地说，某些外部组件必须代表外部CSI卷驱动程序 watch kubernetes API，并触发适当的操作。这消除了在Kube controller manager 和CSI卷驱动程序之间发现和保护 channel 的问题。</p>
<p>为了方便在Kubernetes上部署外部容器化CSI卷驱动程序，而不让驱动程序Kubernetes知道，Kubernetes将提供一个sidecar “Kubernetes To CSI”  代理容器，该容器将监视Kubernetes API并触发针对“CSI卷驱动程序”容器的适当操作。下面的“在Kubernetes上部署CSI驱动程序的建议机制”一节对此进行了详细说明。</p>
<p>代表外部CSI卷驱动程序监视kubernetes api的<strong>外部组件必须处理provisioning, deleting, attaching, and detaching.。</strong></p>
<h5 id="Provisioning-and-Deleting"><a href="#Provisioning-and-Deleting" class="headerlink" title="Provisioning and Deleting"></a>Provisioning and Deleting</h5><p>使用现有的 external provisioner mechanism 处理 Provisioning 和 deletion 操作 。其中代表外部CSI卷驱动程序监视Kubernetes API的外部组件将充当external provisioner（外部供应器）。</p>
<p>简言之，要动态地配置新的CSI volume，集群管理员将创建一个<code>StorageClass</code>，其provisioner与代表CSI卷驱动程序处理配置请求的 external provisioner 的名称相对应。</p>
<p>To provision a new CSI volume, an end user would create a <code>PersistentVolumeClaim</code> object referencing this <code>StorageClass</code>. The external provisioner will react to the creation of the PVC and issue the <code>CreateVolume</code> call against the CSI volume driver to provision the volume. The <code>CreateVolume</code> name will be auto-generated as it is for other dynamically provisioned volumes. The <code>CreateVolume</code> capacity will be taken from the <code>PersistentVolumeClaim</code> object. The <code>CreateVolume</code> parameters will be passed through from the <code>StorageClass</code> parameters (opaque/不透明 to Kubernetes).</p>
<p>要删除CSI卷，最终用户将删除相应的PersistentVolumeClaim对象。外部供应器将对PVC的删除做出反应，并根据其回收策略，针对CSI卷驱动程序命令发出<code>DeleteVolume</code>调用以删除卷。然后它将删除PersistentVolume对象。</p>
<h5 id="Attaching-and-Detaching"><a href="#Attaching-and-Detaching" class="headerlink" title="Attaching and Detaching"></a>Attaching and Detaching</h5><p>Attach/detach  操作也必须由外部组件（“attacher”）处理。attacher代表外部CSI卷驱动程序监视Kubernetes API以获取新的<code>VolumeAttachment</code>对象（定义见下文），并触发针对CSI卷驱动程序的适当调用以附加卷。即使底层CSI驱动程序不支持<code>ControllerPublishVolume</code>调用，附件也必须监视<code>VolumeAttachment</code>对象并将其标记为已附加，因为Kubernetes对此一无所知。</p>
<p>更具体地说，外部“attacher”必须代表外部CSI卷驱动程序监视kubernetes api来处理Attach/detach请求。</p>
<h3 id="Kubernetes-In-Tree-CSI-Volume-Plugin"><a href="#Kubernetes-In-Tree-CSI-Volume-Plugin" class="headerlink" title="Kubernetes In-Tree CSI Volume Plugin"></a>Kubernetes In-Tree CSI Volume Plugin</h3><p>一个新的树内Kubernetes CSI卷插件将包含Kubernetes与任意、树外、第三方CSI兼容的卷驱动程序通信所需的所有逻辑。</p>
<p>现有的Kubernetes卷组件（attach/detach controller、PVC/PV controller、Kubelet volume manager）将处理CSI卷插件操作的生命周期（ volume provisioning/deleting, attaching/detaching, and mounting/unmounting ）与它们对现有树内卷插件所做的一样。</p>
<h4 id="Internal-Interfaces"><a href="#Internal-Interfaces" class="headerlink" title="Internal Interfaces"></a>Internal Interfaces</h4><p>树内CSI卷插件将实现以下内部Kubernetes卷接口：</p>
<ol>
<li><code>VolumePlugin</code><ul>
<li>Mounting/Unmounting of a volume to a specific path.</li>
</ul>
</li>
<li><code>AttachableVolumePlugin</code><ul>
<li>Attach/detach of a volume to a given node.</li>
</ul>
</li>
</ol>
<p>值得注意的是，由于CSI卷的 provisioning 和 deleting 由外部供应器处理，因此未实现<code>ProvisionableVolumePlugin</code>和<code>DeletableVolumePlugin</code>。</p>
<h4 id="Mount-and-Unmount"><a href="#Mount-and-Unmount" class="headerlink" title="Mount and Unmount"></a>Mount and Unmount</h4><p>树内卷插件的SetUp和TearDown方法将通过Unix域套接字触发<code>NodePublishVolume</code>和NodeUnpublishVolume CSI调用。Kubernetes将生成一个唯一的<code>target_path</code>（unique per pod per volume）通过<code>NodePublishVolume</code>传递给CSI插件来 mount 卷。成功完成<code>NodeUnpublishVolume</code>调用后（一旦验证了卷 unmount），Kubernetes将删除该目录。</p>
<p>Kubernetes卷子系统目前不支持 block volumes（only file），因此对于alpha，Kubernetes CSI卷插件只支持file。</p>
<h4 id="Attaching-and-Detaching-1"><a href="#Attaching-and-Detaching-1" class="headerlink" title="Attaching and Detaching"></a>Attaching and Detaching</h4><p>attach/detach controller 作为主节点上 kube-controller-manager 二进制文件的一部分运行，决定何时必须从特定节点连接或分离CSI Volume。</p>
<h3 id="在Kubernetes上部署CSI驱动程序的推荐机制"><a href="#在Kubernetes上部署CSI驱动程序的推荐机制" class="headerlink" title="在Kubernetes上部署CSI驱动程序的推荐机制"></a>在Kubernetes上部署CSI驱动程序的推荐机制</h3><p>尽管Kubernetes没有规定CSI卷驱动程序的打包，但是它提供了以下建议，以简化在Kubernetes上部署集容器化CSI卷驱动程序。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114225314151.png" alt="image-20210114225314151"></p>
<p>要部署容器化的第三方CSI卷驱动程序，建议存储供应商：</p>
<ul>
<li>Create a “CSI volume driver” container，该容器实现卷插件行为并通过unix域套接字公开gRPC接口，如CSI规范（包括Controller, Node,和 Identity services）中定义的那样</li>
<li>将“CSI volume driver”容器与Kubernetes团队将提供的helper容器捆绑在一起（external-attacher, external-provisioner, node-driver-registrar, cluster-driver-registrar, external-resizer, external-snapshotter, livenessprobe），（这些辅助容器将帮助“CSI卷驱动程序”容器与Kubernetes系统交互）。更具体地说，创建以下Kubernetes对象：<ul>
<li>为了方便与 Kubernetes controllers, a <code>StatefulSet</code> or a <code>Deployment</code> 通信(depending on the user’s need; see <a target="_blank" rel="noopener" href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/storage/container-storage-interface.md#cluster-level-deployment">Cluster-Level Deployment</a>) 需要有:<ul>
<li>The following containers<ul>
<li>The “CSI volume driver” container created by the storage vendor.</li>
<li>Containers provided by the Kubernetes team (all of which are optional):<ul>
<li><code>cluster-driver-registrar</code> (refer to the README in <code>cluster-driver-registrar</code> repository for when the container is required)</li>
<li><code>external-provisioner</code> (required for provision/delete operations)</li>
<li><code>external-attacher</code> (required for attach/detach operations. If you wish to skip the attach step, CSISkipAttach feature must be enabled in Kubernetes in addition to omitting this container)</li>
<li><code>external-resizer</code> (required for resize operations)</li>
<li><code>external-snapshotter</code> (required for volume-level snapshot operations)</li>
<li><code>livenessprobe</code></li>
</ul>
</li>
</ul>
</li>
<li>The following volumes:<ul>
<li><code>emptyDir</code> volume<ul>
<li>Mounted by all containers, including the “CSI volume driver”.</li>
<li>The “CSI volume driver” container should create its Unix Domain Socket in this directory to enable communication with the Kubernetes helper container(s).</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>A <code>DaemonSet</code> (to facilitate communication with every instance of kubelet) that has:<ul>
<li>The following containers<ul>
<li>The “CSI volume driver” container created by the storage vendor.</li>
<li>Containers provided by the Kubernetes team:<ul>
<li><code>node-driver-registrar</code> - Responsible for registering the unix domain socket with kubelet.</li>
<li><code>livenessprobe</code> (optional)</li>
</ul>
</li>
</ul>
</li>
<li>The following volumes:<ul>
<li><code>hostpath</code> volume<ul>
<li>Expose <code>/var/lib/kubelet/plugins_registry</code> from the host.</li>
<li>Mount only in <code>node-driver-registrar</code> container at <code>/registration</code></li>
<li><code>node-driver-registrar</code> will use this unix domain socket to register the CSI driver’s unix domain socket with kubelet.</li>
</ul>
</li>
<li><code>hostpath</code> volume<ul>
<li>Expose <code>/var/lib/kubelet/</code> from the host.</li>
<li>Mount only in “CSI volume driver” container at <code>/var/lib/kubelet/</code></li>
<li>Ensure <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/storage/volumes/#mount-propagation">bi-directional mount propagation</a> is enabled, so that any mounts setup inside this container are propagated back to the host machine.</li>
</ul>
</li>
<li><code>hostpath</code> volume<ul>
<li>Expose <code>/var/lib/kubelet/plugins/[SanitizedCSIDriverName]/</code> from the host as <code>hostPath.type = &quot;DirectoryOrCreate&quot;</code>.</li>
<li>Mount inside “CSI volume driver” container at the path the CSI gRPC socket will be created.</li>
<li>This is the primary means of communication between Kubelet and the “CSI volume driver” container (gRPC over UDS).</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>让群集管理员部署上述<code>StatefulSet</code>和 <code>DaemonSet</code>，以添加对Kubernetes群集中存储系统的支持。</li>
</ul>
<p>Alternatively, deployment could be simplified by having all components (including external-provisioner and external-attacher) in the same pod (DaemonSet). Doing so, however, would consume more resources, and require a leader election protocol (likely <a target="_blank" rel="noopener" href="https://git.k8s.io/contrib/election">https://git.k8s.io/contrib/election</a>) in the <code>external-provisioner</code> and <code>external-attacher</code> components.</p>
<p>Containers provided by Kubernetes are maintained in <a target="_blank" rel="noopener" href="https://github.com/kubernetes-csi">GitHub kubernetes-csi organization</a>.</p>
<h3 id="示例流程"><a href="#示例流程" class="headerlink" title="示例流程"></a>示例流程</h3><h4 id="Provisioning-Volumes"><a href="#Provisioning-Volumes" class="headerlink" title="Provisioning Volumes"></a>Provisioning Volumes</h4><ol>
<li>A cluster admin creates a <code>StorageClass</code> pointing to the CSI driver’s external-provisioner and specifying any parameters required by the driver.</li>
<li>A user creates a <code>PersistentVolumeClaim</code> referring to the new <code>StorageClass</code>.</li>
<li>The persistent volume controller realizes（发现） that dynamic provisioning is needed, and marks the PVC with a <code>volume.beta.kubernetes.io/storage-provisioner</code> annotation.</li>
<li>The external-provisioner for the CSI driver sees the <code>PersistentVolumeClaim</code> with the <code>volume.beta.kubernetes.io/storage-provisioner</code> annotation so it starts dynamic volume provisioning:<ol>
<li>它取消对<code>StorageClass</code>的引用，以收集用于 Provisioning 的不透明参数.</li>
<li>它使用<code>StorageClass</code>和PersistentVolumeClaim对象中的参数对CSI driver container调用<code>CreateVolume</code>。</li>
</ol>
</li>
<li>成功创建卷后，external-provisioner 将创建一个<code>PersistentVolume</code>对象来表示新创建的卷，并将其绑定到<code>PersistentVolumeClaim</code></li>
</ol>
<h4 id="Deleting-Volumes"><a href="#Deleting-Volumes" class="headerlink" title="Deleting Volumes"></a>Deleting Volumes</h4><ol>
<li>A user deletes a <code>PersistentVolumeClaim</code> object bound to a CSI volume.</li>
<li>The external-provisioner for the CSI driver sees the <code>PersistentVolumeClaim</code> was deleted and triggers the retention（保留） policy:</li>
<li>If the retention policy is <code>delete</code> 1. The external-provisioner triggers volume deletion by issuing a <code>DeleteVolume</code> call against the CSI volume plugin container. 2. Once the volume is successfully deleted, the external-provisioner deletes the corresponding（相应的） <code>PersistentVolume</code> object.</li>
<li>If the retention policy is <code>retain</code> 1. The external-provisioner does not delete the <code>PersistentVolume</code> object.</li>
</ol>
<h4 id="Attaching-Volumes"><a href="#Attaching-Volumes" class="headerlink" title="Attaching Volumes"></a>Attaching Volumes</h4><ol>
<li>The Kubernetes attach/detach controller, running as part of the <code>kube-controller-manager</code> binary on the master, sees that a pod referencing a CSI volume plugin is scheduled to a node, so it calls the in-tree CSI volume plugin’s attach method.</li>
<li>The in-tree volume plugin creates a new <code>VolumeAttachment</code> object in the kubernetes API and waits for its status to change to completed or error.</li>
<li>The external-attacher sees the <code>VolumeAttachment</code> object and triggers a <code>ControllerPublish</code> against the CSI volume driver container to fulfil it (meaning the external-attacher container issues a gRPC call via underlying UNIX domain socket to the CSI driver container).</li>
<li>Upon successful completion of the <code>ControllerPublish</code> call the external-attacher updates the status of the <code>VolumeAttachment</code> object to indicate the volume is successfully attached.</li>
<li>The in-tree volume plugin watching the status of the <code>VolumeAttachment</code> object in the Kubernetes API, sees the <code>Attached</code> field set to true indicating the volume is attached, so it updates the attach/detach controller’s internal state to indicate the volume is attached.</li>
</ol>
<h4 id="Detaching-Volumes"><a href="#Detaching-Volumes" class="headerlink" title="Detaching Volumes"></a>Detaching Volumes</h4><ol>
<li>The Kubernetes attach/detach controller, running as part of the <code>kube-controller-manager</code> binary on the master, sees that a pod referencing an attached CSI volume plugin is terminated or deleted, so it calls the in-tree CSI volume plugin’s detach method.</li>
<li>The in-tree volume plugin deletes the corresponding <code>VolumeAttachment</code> object.</li>
<li>The external-attacher sees a <code>deletionTimestamp</code> set on the <code>VolumeAttachment</code> object and triggers a <code>ControllerUnpublish</code> against the CSI volume driver container to detach it.</li>
<li>Upon successful completion of the <code>ControllerUnpublish</code> call, the external-attacher removes the finalizer from the <code>VolumeAttachment</code> object to indicate successful completion of the detach operation allowing the <code>VolumeAttachment</code> object to be deleted.</li>
<li>The in-tree volume plugin waiting for the <code>VolumeAttachment</code> object sees it deleted and assumes the volume was successfully detached, so It updates the attach/detach controller’s internal state to indicate the volume is detached.</li>
</ol>
<h4 id="Mounting-Volumes"><a href="#Mounting-Volumes" class="headerlink" title="Mounting Volumes"></a>Mounting Volumes</h4><ol>
<li>The volume manager component of kubelet notices a new volume, referencing a CSI volume, has been scheduled to the node, so it calls the in-tree CSI volume plugin’s <code>WaitForAttach</code> method.</li>
<li>The in-tree volume plugin’s <code>WaitForAttach</code> method watches the <code>Attached</code> field of the <code>VolumeAttachment</code> object in the kubernetes API to become <code>true</code>, it then returns without error.</li>
<li>Kubelet then calls the in-tree CSI volume plugin’s <code>MountDevice</code> method which is a no-op and returns immediately.</li>
<li>Finally kubelet calls the in-tree CSI volume plugin’s mount (setup) method, which causes the in-tree volume plugin to issue a <code>NodePublishVolume</code> call via the registered unix domain socket to the local CSI driver.</li>
<li>Upon successful completion of the <code>NodePublishVolume</code> call the specified path is mounted into the pod container.</li>
</ol>
<h4 id="Unmounting-Volumes"><a href="#Unmounting-Volumes" class="headerlink" title="Unmounting Volumes"></a>Unmounting Volumes</h4><ol>
<li>The volume manager component of kubelet, notices a mounted CSI volume, referenced by a pod that has been deleted or terminated, so it calls the in-tree CSI volume plugin’s <code>UnmountDevice</code> method which is a no-op and returns immediately.</li>
<li>Next kubelet calls the in-tree CSI volume plugin’s unmount (teardown) method, which causes the in-tree volume plugin to issue a <code>NodeUnpublishVolume</code> call via the registered unix domain socket to the local CSI driver. If this call fails from any reason, kubelet re-tries the call periodically.</li>
<li>Upon successful completion of the <code>NodeUnpublishVolume</code> call the specified path is unmounted from the pod container.</li>
</ol>
<h1 id="Container-Storage-Interface-CSI"><a href="#Container-Storage-Interface-CSI" class="headerlink" title="Container Storage Interface (CSI)"></a>Container Storage Interface (CSI)</h1><p>本文翻译于<a target="_blank" rel="noopener" href="https://github.com/container-storage-interface/spec/blob/master/spec.md">Container Storage Interface (CSI)</a></p>
<h2 id="术语-1"><a href="#术语-1" class="headerlink" title="术语"></a>术语</h2><table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody><tr>
<td>Volume</td>
<td>通过CSI在 CO 管理的容器内提供的一种存储单元</td>
</tr>
<tr>
<td>Block Volume</td>
<td>在容器中显示为块设备的卷。</td>
</tr>
<tr>
<td>Mounted Volume</td>
<td>A volume that will be mounted using the specified file system and appear as a directory inside the container.</td>
</tr>
<tr>
<td>CO</td>
<td>Container Orchestration system, 使用 CSI service RPCs 与 Plugins 通信 .</td>
</tr>
<tr>
<td>SP</td>
<td>Storage Provider, the vendor of a CSI plugin implementation.</td>
</tr>
<tr>
<td>RPC</td>
<td><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Remote_procedure_call">Remote Procedure Call</a>.</td>
</tr>
<tr>
<td>Node</td>
<td>A host where the user workload will be running, 从插件的角度来看，可以通过 node ID 唯一标识</td>
</tr>
<tr>
<td>Plugin</td>
<td>“plugin implementation”, a gRPC endpoint that implements the CSI Services.</td>
</tr>
<tr>
<td>Plugin Supervisor</td>
<td>控制插件生命周期的进程, MAY be the CO.</td>
</tr>
<tr>
<td>Workload</td>
<td>The atomic unit of “work” scheduled by a CO. This MAY be a container or a collection of containers.</td>
</tr>
</tbody></table>
<h2 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h2><p>定义一个行业标准的  “Container Storage Interface” (CSI) 使存储厂商 (SP) 能够一次性开发一个插件，并使其在多个 container orchestration (CO) systems 使用。</p>
<h3 id="Goals-in-MVP"><a href="#Goals-in-MVP" class="headerlink" title="Goals in MVP"></a>Goals in MVP</h3><p>The Container Storage Interface (CSI) will</p>
<ul>
<li>Enable SP authors to write one CSI compliant Plugin that “just works” across all COs that implement CSI.</li>
<li>Define API (RPCs) that enable:<ul>
<li>Dynamic provisioning and deprovisioning of a volume.</li>
<li>Attaching or detaching a volume from a node.</li>
<li>Mounting/unmounting a volume from a node.</li>
<li>Consumption（消耗） of both block and mountable volumes.</li>
<li>Local storage providers (e.g., device mapper, lvm).</li>
<li>Creating and deleting a snapshot (source of the snapshot is a volume).</li>
<li>Provisioning a new volume from a snapshot (reverting（恢复） snapshot, where data in the original volume is erased and replaced with data in the snapshot, is out of scope).</li>
</ul>
</li>
<li>定义 plugin 协议规范<ul>
<li>描述 Supervisor 配置一个 Plugin 的过程.</li>
<li>容器部署注意事项 (<code>CAP_SYS_ADMIN</code>, mount namespace, etc.).</li>
</ul>
</li>
</ul>
<h3 id="Non-Goals-in-MVP"><a href="#Non-Goals-in-MVP" class="headerlink" title="Non-Goals in MVP"></a>Non-Goals in MVP</h3><p>容器存储接口（CSI）不会明确定义、提供或规定:</p>
<ul>
<li>Plugin Supervisor 管理插件生命周期的特定机制，包括:<ul>
<li>How to maintain state (e.g. what is attached, mounted, etc.).</li>
<li>How to deploy, install, upgrade, uninstall, monitor, or respawn (in case of unexpected termination) Plugins.</li>
</ul>
</li>
<li>A first class message structure/field to represent “grades of storage” (aka “storage class”).</li>
<li>Protocol-level authentication and authorization.</li>
<li>Packaging of a Plugin.</li>
<li>POSIX兼容：CSI不能保证提供的 volume 是与POSIX兼容的文件系统。合规性由 plugin 实现（及其依赖的任何后端存储系统）决定。CSI不得妨碍 Plugin Supervisor 或CO以符合POSIX的方式与插件管理的 volume 进行交互</li>
</ul>
<h3 id="解决方案概述"><a href="#解决方案概述" class="headerlink" title="解决方案概述"></a>解决方案概述</h3><p>本规范定义了一个接口以及存储提供商（SP）实现CSI兼容插件的最低操作和打包建议。Plugin 必须暴露接口声明的RPCS：这是CSI规范的主要焦点。任何 operational 和 packaging 建议都为促进交叉兼容提供了额外的指导。</p>
<h4 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h4><p>本规范的主要焦点是CO和插件之间的协议。多种架构的插件应该是兼容的。CO应该能够处理集中式和分布式插件，以及 split-component 和 unified（一体化） plugins。下图说明了其中几种可能性：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">                             CO &quot;Master&quot; Host</span><br><span class="line">+-------------------------------------------+</span><br><span class="line">|                                           |</span><br><span class="line">|  +------------+           +------------+  |</span><br><span class="line">|  |     CO     |   gRPC    | Controller |  |</span><br><span class="line">|  |            +-----------&gt;   Plugin   |  |</span><br><span class="line">|  +------------+           +------------+  |</span><br><span class="line">|                                           |</span><br><span class="line">+-------------------------------------------+</span><br><span class="line"></span><br><span class="line">                            CO &quot;Node&quot; Host(s)</span><br><span class="line">+-------------------------------------------+</span><br><span class="line">|                                           |</span><br><span class="line">|  +------------+           +------------+  |</span><br><span class="line">|  |     CO     |   gRPC    |    Node    |  |</span><br><span class="line">|  |            +-----------&gt;   Plugin   |  |</span><br><span class="line">|  +------------+           +------------+  |</span><br><span class="line">|                                           |</span><br><span class="line">+-------------------------------------------+</span><br><span class="line"></span><br><span class="line">Figure 1: The Plugin runs on all nodes in the cluster: </span><br><span class="line">a centralized Controller Plugin is available on the CO master host </span><br><span class="line">and the Node Plugin is available on all of the CO Nodes.</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">                            CO &quot;Node&quot; Host(s)</span><br><span class="line">+-------------------------------------------+</span><br><span class="line">|                                           |</span><br><span class="line">|  +------------+           +------------+  |</span><br><span class="line">|  |     CO     |   gRPC    | Controller |  |</span><br><span class="line">|  |            +--+--------&gt;   Plugin   |  |</span><br><span class="line">|  +------------+  |        +------------+  |</span><br><span class="line">|                  |                        |</span><br><span class="line">|                  |                        |</span><br><span class="line">|                  |        +------------+  |</span><br><span class="line">|                  |        |    Node    |  |</span><br><span class="line">|                  +--------&gt;   Plugin   |  |</span><br><span class="line">|                           +------------+  |</span><br><span class="line">|                                           |</span><br><span class="line">+-------------------------------------------+</span><br><span class="line"></span><br><span class="line">Figure 2: Headless Plugin deployment, only the CO Node hosts run</span><br><span class="line">Plugins. Separate（单独地）, split-component Plugins supply the Controller</span><br><span class="line">Service and the Node Service respectively（分别）.</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">                            CO &quot;Node&quot; Host(s)</span><br><span class="line">+-------------------------------------------+</span><br><span class="line">|                                           |</span><br><span class="line">|  +------------+           +------------+  |</span><br><span class="line">|  |     CO     |   gRPC    | Controller |  |</span><br><span class="line">|  |            +-----------&gt;    Node    |  |</span><br><span class="line">|  +------------+           |   Plugin   |  |</span><br><span class="line">|                           +------------+  |</span><br><span class="line">|                                           |</span><br><span class="line">+-------------------------------------------+</span><br><span class="line"></span><br><span class="line">Figure 3: Headless Plugin deployment, only the CO Node hosts run</span><br><span class="line">Plugins. A unified Plugin component supplies both the Controller</span><br><span class="line">Service and Node Service.</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">                            CO &quot;Node&quot; Host(s)</span><br><span class="line">+-------------------------------------------+</span><br><span class="line">|                                           |</span><br><span class="line">|  +------------+           +------------+  |</span><br><span class="line">|  |     CO     |   gRPC    |    Node    |  |</span><br><span class="line">|  |            +-----------&gt;   Plugin   |  |</span><br><span class="line">|  +------------+           +------------+  |</span><br><span class="line">|                                           |</span><br><span class="line">+-------------------------------------------+</span><br><span class="line"></span><br><span class="line">Figure 4: Headless Plugin deployment, only the CO Node hosts run</span><br><span class="line">Plugins. A Node-only Plugin component supplies only the Node Service.</span><br><span class="line">Its GetPluginCapabilities RPC does not report the CONTROLLER_SERVICE capability.</span><br></pre></td></tr></table></figure>
<h4 id="Volume-Lifecycle"><a href="#Volume-Lifecycle" class="headerlink" title="Volume Lifecycle"></a>Volume Lifecycle</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">   CreateVolume +------------+ DeleteVolume</span><br><span class="line"> +-------------&gt;|  CREATED   +--------------+</span><br><span class="line"> |              +---+----^---+              |</span><br><span class="line"> |       Controller |    | Controller       v</span><br><span class="line">+++         Publish |    | Unpublish       +++</span><br><span class="line">|X|          Volume |    | Volume          | |</span><br><span class="line">+-+             +---v----+---+             +-+</span><br><span class="line">                | NODE_READY |</span><br><span class="line">                +---+----^---+</span><br><span class="line">               Node |    | Node</span><br><span class="line">            Publish |    | Unpublish</span><br><span class="line">             Volume |    | Volume</span><br><span class="line">                +---v----+---+</span><br><span class="line">                | PUBLISHED  |</span><br><span class="line">                +------------+</span><br><span class="line"></span><br><span class="line">Figure 5: The lifecycle of a dynamically provisioned volume, from creation to destruction（销毁）.</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">   CreateVolume +------------+ DeleteVolume</span><br><span class="line"> +-------------&gt;|  CREATED   +--------------+</span><br><span class="line"> |              +---+----^---+              |</span><br><span class="line"> |       Controller |    | Controller       v</span><br><span class="line">+++         Publish |    | Unpublish       +++</span><br><span class="line">|X|          Volume |    | Volume          | |</span><br><span class="line">+-+             +---v----+---+             +-+</span><br><span class="line">                | NODE_READY |</span><br><span class="line">                +---+----^---+</span><br><span class="line">               Node |    | Node</span><br><span class="line">              Stage |    | Unstage</span><br><span class="line">             Volume |    | Volume</span><br><span class="line">                +---v----+---+</span><br><span class="line">                |  VOL_READY |</span><br><span class="line">                +---+----^---+</span><br><span class="line">               Node |    | Node</span><br><span class="line">            Publish |    | Unpublish</span><br><span class="line">             Volume |    | Volume</span><br><span class="line">                +---v----+---+</span><br><span class="line">                | PUBLISHED  |</span><br><span class="line">                +------------+</span><br><span class="line"></span><br><span class="line">Figure 6: The lifecycle of a dynamically provisioned volume, from creation to destruction, when the Node Plugin advertises the STAGE_UNSTAGE_VOLUME capability.</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    Controller                  Controller</span><br><span class="line">       Publish                  Unpublish</span><br><span class="line">        Volume  +------------+  Volume</span><br><span class="line"> +-------------&gt;+ NODE_READY +--------------+</span><br><span class="line"> |              +---+----^---+              |</span><br><span class="line"> |             Node |    | Node             v</span><br><span class="line">+++         Publish |    | Unpublish       +++</span><br><span class="line">|X| &lt;-+      Volume |    | Volume          | |</span><br><span class="line">+++   |         +---v----+---+             +-+</span><br><span class="line"> |    |         | PUBLISHED  |</span><br><span class="line"> |    |         +------------+</span><br><span class="line"> +----+</span><br><span class="line">   Validate</span><br><span class="line">   Volume</span><br><span class="line">   Capabilities</span><br><span class="line"></span><br><span class="line">Figure 7: The lifecycle of a pre-provisioned volume that requires </span><br><span class="line">controller to publish to a node (&#96;ControllerPublishVolume&#96;) prior to（在...前）</span><br><span class="line">publishing on the node (&#96;NodePublishVolume&#96;).</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">       +-+  +-+</span><br><span class="line">       |X|  | |</span><br><span class="line">       +++  +^+</span><br><span class="line">        |    |</span><br><span class="line">   Node |    | Node</span><br><span class="line">Publish |    | Unpublish</span><br><span class="line"> Volume |    | Volume</span><br><span class="line">    +---v----+---+</span><br><span class="line">    | PUBLISHED  |</span><br><span class="line">    +------------+</span><br><span class="line"></span><br><span class="line">Figure 8: 插件可以通过 capabilities API 禁止其他生命周期步骤。与此类插件的交互量减少到“ NodePublishVolume”和“ NodeUnpublishVolume”调用。</span><br></pre></td></tr></table></figure>
<p>上面的图表说明了关于CO如何通过本规范中提供的API来管理卷的生命周期的一般期望。插件应该公开来自接口的所有RPCS：Controller plugins 应该实现 <code>Controller</code> 服务的所有RPC。不受支持的RPC应该返回一个适当的错误代码来指明这一点（例如CALL_NOT_IMPLEMENTED）。插件功能的完整列表记录在<code>ControllerGetCapabilities</code>和NodeGetCapabilities RPC中。</p>
<h1 id="Kubernetes存储架构整体介绍"><a href="#Kubernetes存储架构整体介绍" class="headerlink" title="Kubernetes存储架构整体介绍"></a>Kubernetes存储架构整体介绍</h1><p>见此文：<a target="_blank" rel="noopener" href="https://gitchat.csdn.net/columnTopic/5dd3f1e479b8c11c313571a1">课时 21：Kubernetes 存储架构及插件使用</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://heavyfish.github.io/2020/11/23/Go/GRPC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/heavyfish.github.io/images/avatar.gif">
      <meta itemprop="name" content="Shenxr">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="速查笔记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/heavyfish.github.io/2020/11/23/Go/GRPC/" class="post-title-link" itemprop="url">GRPC</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-23 12:22:49" itemprop="dateCreated datePublished" datetime="2020-11-23T12:22:49+08:00">2020-11-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-14 23:15:19" itemprop="dateModified" datetime="2021-01-14T23:15:19+08:00">2021-01-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/heavyfish.github.io/categories/Go/" itemprop="url" rel="index"><span itemprop="name">Go</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<blockquote>
<p>一个高性能、开源的通用RPC框架</p>
</blockquote>
</blockquote>
<h1 id="Why-gRPC"><a href="#Why-gRPC" class="headerlink" title="Why gRPC"></a>Why gRPC</h1><p>gRPC是一个现代的开源高性能RPC框架，可以在任何环境下运行。它可以有效地连接数据中心内和跨数据中心的服务，支持负载平衡、跟踪、健康检查和身份验证。它也适用于分布式计算的最后一英里，将设备、移动应用程序和浏览器连接到后端服务</p>
<h1 id="gRPC简介"><a href="#gRPC简介" class="headerlink" title="gRPC简介"></a>gRPC简介</h1><p>本页介绍 gRPC 和 protocol buffers。gRPC可以使用 protocol buffers 作为其 接口定义语言（<strong>IDL</strong> / Interface Definition Language）和底层消息交换格式。如果你不熟悉gRPC 或 protocol buffers，请阅读本文。</p>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>在gRPC中，client 应用程序可以像本地对象一样直接调用另一台计算机上的 server application 上的方法，从而使您更容易创建分布式应用程序和服务。与许多RPC系统一样，gRPC基于定义服务的思想，指定可以通过参数和返回类型远程调用的方法。在 server 端，server 实现这个接口并运行gRPC server 来处理 client 调用。在client端，client 有一个存根（<strong>stub</strong>）（在某些语言中称为 client），它提供与服务器相同的方法。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/landing-2.svg" alt="Concept Diagram"></p>
<p>gRPC clients 和 servers 可以在各种环境中运行和相互交流，从Google内部的服务器到您自己的桌面，并且可以用gRPC支持的任何语言编写。因此，例如，您可以使用Go、Python或Ruby 创建 client，而用 Java创建gRPC server。此外，最新的Google APIs将有gRPC版本的接口，让您可以轻松地在应用程序中构建Google功能。</p>
<h2 id="使用Protocol-Buffers"><a href="#使用Protocol-Buffers" class="headerlink" title="使用Protocol Buffers"></a>使用Protocol Buffers</h2><p>默认情况下，gRPC使用<a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/docs/overview">Protocol Buffers</a>，Google成熟的用于序列化 structured data 的开源机制（尽管它可以与JSON等其他数据格式一起使用）。下面是一个如何工作的快速介绍。如果您已经熟悉Protocol Buffers，请跳到下一节。</p>
<p>使用 协议缓冲区 的第一步是定义要在<em>proto file</em>中序列化的数据的结构：这是一个扩展名为<code>.proto</code>的普通文本文件。协议缓冲区数据被结构化为 <code>message</code>，其中每个 message 都是一个小的逻辑信息记录，其中包含一系列名为<em>fields</em> 的 键值对。下面是一个简单的例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">message Person &#123;</span><br><span class="line">  string name &#x3D; 1;</span><br><span class="line">  int32 id &#x3D; 2;</span><br><span class="line">  bool has_ponycopter &#x3D; 3;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后，一旦指定了数据结构，就可以使用 protocol buffer 编译器 <code>protoc</code> ，从你的 proto定义中 生成您首选语言的数据访问类。它们为每个字段提供简单的访问器，如<code>name（）</code>和<code>set_name（）</code>，以及将整个结构 serialize/parse 为原始字节的方法。因此，例如，如果您选择的语言是C++，则在上面的示例中运行编译器将生成一个名为“<code>Person</code>”的类。然后，可以在应用程序中使用该类来填充、序列化和检索<code>Person</code>协议缓冲区消息。</p>
<p>您可以在普通的proto文件中定义gRPC服务，并将RPC方法参数和返回类型指定为协议缓冲区消息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; The greeter service definition.</span><br><span class="line">service Greeter &#123;</span><br><span class="line">  &#x2F;&#x2F; Sends a greeting</span><br><span class="line">  rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; The request message containing the user&#39;s name.</span><br><span class="line">message HelloRequest &#123;</span><br><span class="line">  string name &#x3D; 1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; The response message containing the greetings</span><br><span class="line">message HelloReply &#123;</span><br><span class="line">  string message &#x3D; 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>gRPC使用<code>protoc</code>和一个特殊的gRPC插件从proto文件生成代码：您可以得到生成的gRPC客户端和服务器代码，以及用于填充、序列化和检索消息类型的 常规 协议缓冲代码。下面是一个例子</p>
<p>要了解有关协议缓冲区的更多信息，包括如何使用您选择的语言安装带有gRPC插件的<code>protoc</code>，请参阅<a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/docs/overview">protocol buffers文档</a>。</p>
<h2 id="Protocol-buffer-versions"><a href="#Protocol-buffer-versions" class="headerlink" title="Protocol buffer versions"></a>Protocol buffer versions</h2><p>While <a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/docs/overview">protocol buffers</a> have been available to open source users for some time, most examples from this site use protocol buffers version 3 (proto3), which has a slightly simplified syntax, some useful new features, and supports more languages. Proto3 is currently available in Java, C++, Dart, Python, Objective-C, C#, a lite-runtime (Android Java), Ruby, and JavaScript from the <a target="_blank" rel="noopener" href="https://github.com/google/protobuf/releases">protocol buffers GitHub repo</a>, as well as a Go language generator from the <a target="_blank" rel="noopener" href="https://github.com/golang/protobuf">golang/protobuf GitHub repo</a>, with more languages in development. You can find out more in the <a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/docs/proto3">proto3 language guide</a> and the <a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/docs/reference/overview">reference documentation</a> available for each language. The reference documentation also includes a <a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/docs/reference/proto3-spec">formal specification</a> for the <code>.proto</code> file format.</p>
<p>一般来说，虽然您可以使用proto2（当前默认的协议缓冲区版本），但我们建议您将proto3与gRPC一起使用，因为它允许您使用gRPC支持的所有语言，并避免proto2客户端与proto3服务器通信时的兼容性问题，反之亦然</p>
<h1 id="基础教程"><a href="#基础教程" class="headerlink" title="基础教程"></a>基础教程</h1><p>本教程提供了一个基本的Go程序员使用gRPC的介绍。</p>
<p>通过本例，您将学习如何：</p>
<ul>
<li>Define a service in a <code>.proto</code> file.</li>
<li>Generate server and client code using the protocol buffer compiler.</li>
<li>Use the Go gRPC API to write a simple client and server for your service.</li>
</ul>
<p>It assumes that you have read the <a target="_blank" rel="noopener" href="https://grpc.io/docs/what-is-grpc/introduction/">Introduction to gRPC</a> and are familiar with <a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/docs/overview">protocol buffers</a>. Note that the example in this tutorial uses the proto3 version of the protocol buffers language: you can find out more in the <a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/docs/proto3">proto3 language guide</a> and the <a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/docs/reference/go-generated">Go generated code guide</a>.</p>
<h3 id="什么是-protocol-buffers？"><a href="#什么是-protocol-buffers？" class="headerlink" title="什么是 protocol buffers？"></a>什么是 protocol buffers？</h3><p>protocol buffers 是Google开发的 与语言无关、平台无关、可扩展的序列化结构化数据的机制，类似XML，但是更小、更快、更简单。您只需定义一次数据的结构化方式，然后就可以使用特殊生成的源代码，轻松地将结构化数据写入和读取到各种数据流中，并使用多种语言 </p>
<h3 id="Why-use-gRPC"><a href="#Why-use-gRPC" class="headerlink" title="Why use gRPC?"></a>Why use gRPC?</h3><p>我们的示例是一个简单的路由映射应用程序，它允许 client 获取有关其路由特性的信息，创建其路由的摘要，并与服务器和其他 client 交换路由信息，如流量更新。</p>
<p>有了gRPC，我们可以在<code>.proto</code>文件中定义我们的服务，并用gRPC支持的任何语言生成客户端和服务器，它可以在从大型数据中心内的服务器到您自己的平板电脑的各种环境中运行，不同语言和环境之间的所有复杂通信都由gRPC为您处理。我们还获得了使用协议缓冲区的所有优点，包括高效的序列化、简单的IDL和容易的接口更新。</p>
<h3 id="Get-the-example-code"><a href="#Get-the-example-code" class="headerlink" title="Get the example code"></a>Get the example code</h3><p>The example code is part of the <a target="_blank" rel="noopener" href="https://github.com/grpc/grpc-go">grpc-go</a> repo.</p>
<ol>
<li><p><a target="_blank" rel="noopener" href="https://github.com/grpc/grpc-go/archive/v1.33.1.zip">Download the repo as a zip file</a> and unzip it, or clone the repo:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> -b v1.33.1 https://github.com/grpc/grpc-go</span><br></pre></td></tr></table></figure></li>
<li><p>Change to the example directory:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> grpc-go/examples/route_guide</span><br></pre></td></tr></table></figure>


</li>
</ol>
<h3 id="Defining-the-service"><a href="#Defining-the-service" class="headerlink" title="Defining the service"></a>Defining the service</h3><p>Our first step (as you’ll know from the <a target="_blank" rel="noopener" href="https://grpc.io/docs/what-is-grpc/introduction/">Introduction to gRPC</a>) is to define the gRPC <em>service</em> and the method <em>request</em> and <em>response</em> types using <a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/docs/overview">protocol buffers</a>. For the complete <code>.proto</code> file, see <a target="_blank" rel="noopener" href="https://github.com/grpc/grpc-go/blob/master/examples/route_guide/routeguide/route_guide.proto">routeguide/route_guide.proto</a>.</p>
<p>To define a service, you specify a named <code>service</code> in your .proto file:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service RouteGuide &#123;</span><br><span class="line">   ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Then you define <code>rpc</code> methods inside your service definition, specifying their request and response types. gRPC lets you define four kinds of service method, all of which are used in the <code>RouteGuide</code> service:</p>
<ul>
<li><p>A <em>simple RPC</em> where the client sends a request to the server using the stub and waits for a response to come back, just like a normal function call.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Obtains the feature at a given position.</span><br><span class="line">rpc GetFeature(Point) returns (Feature) &#123;&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>A <em>server-side streaming RPC</em> where the client sends a request to the server and gets a stream to read a sequence of messages back. The client reads from the returned stream until there are no more messages. As you can see in our example, you specify a server-side streaming method by placing the <code>stream</code> keyword before the <em>response</em> type.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Obtains the Features available within the given Rectangle.  Results are</span><br><span class="line">&#x2F;&#x2F; streamed rather than returned at once (e.g. in a response message with a</span><br><span class="line">&#x2F;&#x2F; repeated field), as the rectangle may cover a large area and contain a</span><br><span class="line">&#x2F;&#x2F; huge number of features.</span><br><span class="line">rpc ListFeatures(Rectangle) returns (stream Feature) &#123;&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>A <em>client-side streaming RPC</em> where the client writes a sequence of messages and sends them to the server, again using a provided stream. Once the client has finished writing the messages, it waits for the server to read them all and return its response. You specify a client-side streaming method by placing the <code>stream</code> keyword before the <em>request</em> type.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Accepts a stream of Points on a route being traversed, returning a</span><br><span class="line">&#x2F;&#x2F; RouteSummary when traversal is completed.</span><br><span class="line">rpc RecordRoute(stream Point) returns (RouteSummary) &#123;&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>A <em>bidirectional(双向的) streaming RPC</em> where both sides send a sequence of messages using a read-write stream. The two streams operate independently, so clients and servers can read and write in whatever order they like: for example, the server could wait to receive all the client messages before writing its responses, or it could alternately read a message then write a message, or some other combination of reads and writes. The order of messages in each stream is preserved. You specify this type of method by placing the <code>stream</code> keyword before both the request and the response.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Accepts a stream of RouteNotes sent while a route is being traversed,</span><br><span class="line">&#x2F;&#x2F; while receiving other RouteNotes (e.g. from other users).</span><br><span class="line">rpc RouteChat(stream RouteNote) returns (stream RouteNote) &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>Our <code>.proto</code> file also contains protocol buffer message type definitions for all the request and response types used in our service methods - for example, here’s the <code>Point</code> message type:</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Points are represented as latitude-longitude pairs in the E7 representation</span><br><span class="line">&#x2F;&#x2F; (degrees multiplied by 10**7 and rounded to the nearest integer).</span><br><span class="line">&#x2F;&#x2F; Latitudes should be in the range +&#x2F;- 90 degrees and longitude should be in</span><br><span class="line">&#x2F;&#x2F; the range +&#x2F;- 180 degrees (inclusive).</span><br><span class="line">message Point &#123;</span><br><span class="line">  int32 latitude &#x3D; 1;</span><br><span class="line">  int32 longitude &#x3D; 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Generating-client-and-server-code"><a href="#Generating-client-and-server-code" class="headerlink" title="Generating client and server code"></a>Generating client and server code</h3><p>Next we need to generate the gRPC client and server interfaces from our <code>.proto</code> service definition. We do this using the protocol buffer compiler <code>protoc</code> with a special gRPC Go plugin. This is similar to what we did in the <a target="_blank" rel="noopener" href="https://grpc.io/docs/languages/go/quickstart/">Quick start</a>.</p>
<p>From the <code>examples/route_guide</code> directory, run the following command:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ protoc --go_out=. --go_opt=paths=source_relative \</span><br><span class="line">    --go-grpc_out=. --go-grpc_opt=paths=source_relative \</span><br><span class="line">    routeguide/route_guide.proto</span><br></pre></td></tr></table></figure>
<p>Running this command generates the following files in the <a target="_blank" rel="noopener" href="https://github.com/grpc/grpc-go/blob/master/examples/route_guide/routeguide">routeguide</a> directory:</p>
<ul>
<li><p><code>route_guide.pb.go</code>, which contains all the protocol buffer code to populate, serialize, and retrieve request and response message types.</p>
</li>
<li><pre><code>route_guide_grpc.pb.go</code></pre>
<p>, which contains the following:</p>
<ul>
<li>An interface type (or <em>stub</em>) for clients to call with the methods defined in the <code>RouteGuide</code> service.</li>
<li>An interface type for servers to implement, also with the methods defined in the <code>RouteGuide</code> service.</li>
</ul>
</li>
</ul>
<h3 id="接下来"><a href="#接下来" class="headerlink" title="接下来"></a>接下来</h3><p>接下来是构建 server 端 和 client 端的代码，暂且省略。目前需要明白 protocol buffer 和 gGRPC的大致概念。</p>
<ol>
<li>client 和 server 两端 传输的数据，都是使用 protocol buffer 编码的，它们共享了一个 <code>.proto</code> 文件，因此能够明白 二进制数据如何转换，并共享了 rpc 函数</li>
<li><code>.proto</code> 文件被编译处理后，自动生成的 code 中，是关于<ul>
<li> 处理 protocol buffer 的函数</li>
<li>与gRPC相关的函数。（因为你在 service中定义了 rpc 方法，这个 code 里 自动帮你把这些 rpc 方法写入到了 gRPC 中。 应该是 client 与 server 交互时，经过 gRPC 时，这些代码应该会有用）</li>
</ul>
</li>
</ol>
<h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><p><a target="_blank" rel="noopener" href="https://grpc.io/docs/languages/go/basics/">Basics tutorial</a>-gRPC 官网</p>
<p><a href="grpc/grpc-go">grpc/grpc-go</a> —— gRPC 的 示例代码</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://heavyfish.github.io/2020/11/23/k8s/PLEG%E6%9C%BA%E5%88%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/heavyfish.github.io/images/avatar.gif">
      <meta itemprop="name" content="Shenxr">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="速查笔记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/heavyfish.github.io/2020/11/23/k8s/PLEG%E6%9C%BA%E5%88%B6/" class="post-title-link" itemprop="url">PLEG机制</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-23 11:23:02" itemprop="dateCreated datePublished" datetime="2020-11-23T11:23:02+08:00">2020-11-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-14 22:52:47" itemprop="dateModified" datetime="2021-01-14T22:52:47+08:00">2021-01-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/heavyfish.github.io/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="PLEG前的痛点"><a href="#PLEG前的痛点" class="headerlink" title="PLEG前的痛点"></a>PLEG前的痛点</h2><p>在Kubernetes中，Kubelet是每个节点上 管理Pod的守护进程，它驱动pod状态以匹配它们的pod规范（spec）。为了实现这一点，Kubelet需要对（1）pod specs 和（2）container states 的变化做出反应。对于前者，Kubelet从多个源 <code>watch</code>  pod规范 的变化；对于后者，Kubelet定期轮询容器运行时（例如，10s），以获得所有容器的最新状态。</p>
<p>随着pod/容器数量的增加，轮询会产生不可忽略的开销，并且由于Kubelet的并行性而加剧——每个pod一个worker（goroutine），它单独查询容器运行时。周期性的、并发的、大量的请求会导致高CPU使用率峰值（即使在没有 spec/state 更改的情况下）、性能差和可靠性问题。最后容器运行时可能不堪重负，从而降低系统的可靠性，限制 Kubelet 的可扩展性。</p>
<h2 id="PLEG的目标"><a href="#PLEG的目标" class="headerlink" title="PLEG的目标"></a>PLEG的目标</h2><p>PLEG的目标是通过降低pod管理开销来提高Kubelet的可伸缩性和性能。</p>
<ul>
<li>减少非活跃期间的不必要工作（无 spec/state 更改）</li>
<li>降低对容器运行时的并发请求。</li>
</ul>
<p>设计应该是通用的，这样它就可以支持不同的容器运行时（例如Docker和rkt）</p>
<h2 id="什么是PLEG"><a href="#什么是PLEG" class="headerlink" title="什么是PLEG"></a>什么是PLEG</h2><p>PLEG 全称叫 <code>Pod Lifecycle Event Generator</code>，即 Pod 生命周期事件生成器。实际上它只是 <code>Kubelet</code> 中的一个模块，主要职责就是通过每个匹配的 Pod 级别事件来调整容器运行时的状态，并将调整的结果写入缓存，使 <code>Pod</code> 的缓存保持最新状态</p>
<p>让我们看看流程图的红色虚线，虚线部分是 PLEG 的工作内容</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114225200930.png" alt="image-20210114225200930"></p>
<h3 id="upstream-container-state-event-generator"><a href="#upstream-container-state-event-generator" class="headerlink" title="upstream container state event generator"></a>upstream container state event generator</h3><p>PLEG可以利用提供容器事件的其他组件，并将这些事件转换为pod生命周期事件，而不是依赖于 relisting。这将进一步提高Kubelet的响应能力，并减少频繁 relisting 造成的资源占用。</p>
<p>上游容器事件可来源于：</p>
<ol>
<li><p>每个容器运行时提供的事件流</p>
<p>Docker的API公开了一个<a target="_blank" rel="noopener" href="https://docs.docker.com/engine/api/v1.40/#operation/SystemEvents">事件流</a>。尽管如此，rkt还不支持这一点，但他们最终会支持它（see <a target="_blank" rel="noopener" href="https://github.com/coreos/rkt/issues/1193">coreos/rkt#1193</a>）</p>
</li>
<li><p><em>cgroups event stream by cAdvisor</em></p>
<p>cAdvisor集成在Kubelet中以提供容器统计信息。它使用inotify监视cgroup容器并暴露事件流。即使它还不支持rkt，添加这样的支持应该很简单。</p>
</li>
</ol>
<p>选项（1）可以提供更丰富的事件集，但选项（2）的优点是跨 runtime 时更通用，只要容器运行时使用cgroup。不管现在选择用何种方式实现，容器事件流都应该可以通过清晰定义的接口轻松地交换。</p>
<p>注意，我们不能仅仅依赖上游容器事件，因为可能会丢失事件。PLEG应该不经常 relisting ，以确保没有遗漏任何事件</p>
<h2 id="PLEG-is-not-healthy-是如何发生的"><a href="#PLEG-is-not-healthy-是如何发生的" class="headerlink" title="PLEG is not healthy 是如何发生的?"></a>PLEG is not healthy 是如何发生的?</h2><p><code>Healthy()</code> 函数会以 “PLEG” 的形式添加到 <code>runtimeState</code> 中，Kubelet 在一个同步循环（<code>SyncLoop()</code> 函数）中会定期（默认是 10s）调用 <code>Healthy()</code> 函数。<code>Healthy()</code> 函数会检查 <code>relist</code> 进程（PLEG 的关键任务）是否在 3 分钟内完成。如果 relist 进程的完成时间超过了 3 分钟，就会报告 <strong>PLEG is not healthy</strong>。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114225207826.png" alt="image-20210114225207826"></p>
<p>我会在流程的每一步通过源代码解释其相关的工作原理，源代码基于 Kubernetes 1.11（Openshift 3.11）。如果你不熟悉 Go 的语法也不用担心，只需要看代码中的注释就能明白其原理。我也会在放出代码之前先解读一番，并从源代码中裁剪掉不太重要的内容以提高代码的可读性。下面是调用 healthy() 函数的相关代码：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//// pkg/kubelet/pleg/generic.go - Healthy()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// The threshold 必须大于 relisting period + the relisting time,</span></span><br><span class="line"><span class="comment">//这可能会有很大影响. 设置保守的 threshold，以避免在健康与不健康之间切换。</span></span><br><span class="line">relistThreshold = <span class="number">3</span> * time.Minute</span><br><span class="line">:</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(g *GenericPLEG)</span> <span class="title">Healthy</span><span class="params">()</span> <span class="params">(<span class="keyword">bool</span>, error)</span></span> &#123;</span><br><span class="line">  relistTime := g.getRelistTime()</span><br><span class="line">  elapsed := g.clock.Since(relistTime)</span><br><span class="line">  <span class="keyword">if</span> elapsed &gt; relistThreshold &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>, fmt.Errorf(<span class="string">&quot;pleg was last seen active %v ago; threshold is %v&quot;</span>, elapsed, relistThreshold)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/kubelet.go - NewMainKubelet()</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewMainKubelet</span><span class="params">(kubeCfg *kubeletconfiginternal.KubeletConfiguration, ...</span></span></span><br><span class="line"><span class="function"><span class="params">:</span></span></span><br><span class="line">  klet.runtimeState.addHealthCheck(&quot;PLEG&quot;, klet.pleg.Healthy)</span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/kubelet.go - syncLoop()</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kl *Kubelet)</span> <span class="title">syncLoop</span><span class="params">(updates &lt;-<span class="keyword">chan</span> kubetypes.PodUpdate, handler SyncHandler)</span></span> &#123;</span><br><span class="line">:</span><br><span class="line"></span><br><span class="line"><span class="comment">// resyncTicker唤醒kubelet，以检查是否有 pod workers 需要同步。 </span></span><br><span class="line"><span class="comment">// 一秒钟的时间就足够了，因为同步间隔默认为10s。</span></span><br><span class="line">:</span><br><span class="line">  <span class="keyword">const</span> (</span><br><span class="line">    base   = <span class="number">100</span> * time.Millisecond</span><br><span class="line">    max    = <span class="number">5</span> * time.Second</span><br><span class="line">    factor = <span class="number">2</span></span><br><span class="line">  )</span><br><span class="line">  duration := base</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> rs := kl.runtimeState.runtimeErrors(); <span class="built_in">len</span>(rs) != <span class="number">0</span> &#123;</span><br><span class="line">          glog.Infof(<span class="string">&quot;skipping pod synchronization - %v&quot;</span>, rs)</span><br><span class="line">          <span class="comment">// exponential backoff</span></span><br><span class="line">          time.Sleep(duration)</span><br><span class="line">          duration = time.Duration(math.Min(<span class="keyword">float64</span>(max), factor*<span class="keyword">float64</span>(duration)))</span><br><span class="line">          <span class="keyword">continue</span></span><br><span class="line">      &#125;</span><br><span class="line">    :</span><br><span class="line">  &#125;</span><br><span class="line">:</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/runtime.go - runtimeErrors()</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *runtimeState)</span> <span class="title">runtimeErrors</span><span class="params">()</span> []<span class="title">string</span></span> &#123;</span><br><span class="line">:</span><br><span class="line">    <span class="keyword">for</span> _, hc := <span class="keyword">range</span> s.healthChecks &#123;</span><br><span class="line">        <span class="keyword">if</span> ok, err := hc.fn(); !ok &#123;</span><br><span class="line">            ret = <span class="built_in">append</span>(ret, fmt.Sprintf(<span class="string">&quot;%s is not healthy: %v&quot;</span>, hc.name, err))</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">:</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="深入解读-relist-函数"><a href="#深入解读-relist-函数" class="headerlink" title="深入解读 relist 函数"></a>深入解读 relist 函数</h2><p>上文提到 <code>healthy()</code> 函数会检查 relist 的完成时间，但 relist 究竟是用来干嘛的呢？解释 relist 之前，要先解释一下 Pod 的生命周期事件。Pod 的生命周期事件是在 Pod 层面上对底层容器状态改变的抽象，使其与底层的容器运行时无关，这样就可以让 Kubelet 不受底层容器运行时的影响。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> PodLifeCycleEventType <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">    ContainerStarted      PodLifeCycleEventType = <span class="string">&quot;ContainerStarted&quot;</span></span><br><span class="line">    ContainerStopped      PodLifeCycleEventType = <span class="string">&quot;ContainerStopped&quot;</span></span><br><span class="line">    NetworkSetupCompleted PodLifeCycleEventType = <span class="string">&quot;NetworkSetupCompleted&quot;</span></span><br><span class="line">    NetworkFailed         PodLifeCycleEventType = <span class="string">&quot;NetworkFailed&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// PodLifecycleEvent is an event reflects the change of the pod state.</span></span><br><span class="line"><span class="keyword">type</span> PodLifecycleEvent <span class="keyword">struct</span> &#123;</span><br><span class="line">    <span class="comment">// The pod ID.</span></span><br><span class="line">    ID types.UID</span><br><span class="line">    <span class="comment">// The type of the event.</span></span><br><span class="line">    Type PodLifeCycleEventType</span><br><span class="line">    <span class="comment">// The accompanied data which varies based on the event type.</span></span><br><span class="line">    Data <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以 Docker 为例，在 Pod 中启动一个 infra 容器就会在 Kubelet 中注册一个 <code>NetworkSetupCompleted</code> Pod 生命周期事件。</p>
<p>那么 PLEG 是如何知道新启动了一个 infra 容器呢？它会定期重新列出节点上的所有容器（例如 docker ps），并与上一次的容器列表进行对比，以此来判断容器状态的变化。其实这就是 <code>relist()</code> 函数干的事情，尽管这种方法和以前的 Kubelet 轮询类似，但现在只有一个线程，就是 PLEG。现在不需要所有的线程并发获取容器的状态，只有相关的线程会被唤醒用来同步容器状态。而且 relist 与容器运行时无关，也不需要外部依赖，简直完美。</p>
<p>下面我们来看一下 <code>relist()</code> 函数的内部实现。完整的流程如下图所示：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114225213707.png" alt="image-20210114225213707"></p>
<p>注意图中的 RPC 调用部分，后文将会拎出来详细解读。完整的源代码在<a target="_blank" rel="noopener" href="https://github.com/openshift/origin/blob/release-3.11/vendor/k8s.io/kubernetes/pkg/kubelet/pleg/generic.go#L180-L284">这里</a>。</p>
<p>尽管每秒钟调用一次 <code>relist</code>，但它的完成时间仍然有可能超过 1s。因为下一次调用 <code>relist</code> 必须得等上一次 relist 执行结束，设想一下，如果容器运行时响应缓慢，或者一个周期内有大量的容器状态发生改变，那么 <code>relist</code> 的完成时间将不可忽略，假设是 5s，那么下一次调用 <code>relist</code> 将要等到 6s 之后。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114225218214.png" alt="image-20210114225218214"></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//// pkg/kubelet/kubelet.go - NewMainKubelet()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Generic PLEG 依靠 relisting for discovering container events.</span></span><br><span class="line"><span class="comment">// A longer period means that kubelet will take longer to detect container</span></span><br><span class="line"><span class="comment">// changes and to update pod status. On the other hand, a shorter period</span></span><br><span class="line"><span class="comment">// will cause more frequent relisting (e.g., container runtime operations),</span></span><br><span class="line"><span class="comment">// leading to higher cpu usage.</span></span><br><span class="line"><span class="comment">// Note that even though we set the period to 1s, the relisting itself can</span></span><br><span class="line"><span class="comment">// take more than 1s to finish if the container runtime responds slowly</span></span><br><span class="line"><span class="comment">// and/or when there are many container changes in one cycle.</span></span><br><span class="line">plegRelistPeriod = time.Second * <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// NewMainKubelet实例化一个新的Kubelet对象以及所有必需的内部模块</span></span><br><span class="line"><span class="comment">// 此处不应进行Kubelet及其模块的初始化。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewMainKubelet</span><span class="params">(kubeCfg *kubeletconfiginternal.KubeletConfiguration, ...</span></span></span><br><span class="line"><span class="function"><span class="params">:</span></span></span><br><span class="line"><span class="function"><span class="params">  klet.pleg = pleg.NewGenericPLEG(klet.containerRuntime, plegChannelCapacity, plegRelistPeriod, klet.podCache, clock.RealClock&#123;&#125;)</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/pleg/generic.go - Start()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Start spawns a goroutine to relist periodically.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(g *GenericPLEG)</span> <span class="title">Start</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">go</span> wait.Until(g.relist, g.relistPeriod, wait.NeverStop)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/pleg/generic.go - relist()</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(g *GenericPLEG)</span> <span class="title">relist</span><span class="params">()</span></span> &#123;</span><br><span class="line">... WE WILL REVIEW HERE ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>回到上面那幅图，relist 函数第一步就是记录 <code>Kubelet</code> 的相关指标（例如 <code>kubelet_pleg_relist_latency_microseconds</code>），然后通过 CRI 从容器运行时获取当前的 Pod 列表（包括停止的 Pod）。该 Pod 列表会和之前的 Pod 列表进行比较，检查哪些状态发生了变化，然后同时生成相关的 <strong>Pod 生命周期事件</strong>和<strong>更改后的状态</strong>。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//// pkg/kubelet/pleg/generic.go - relist()</span></span><br><span class="line">  :</span><br><span class="line">  <span class="comment">// get a current timestamp</span></span><br><span class="line">  timestamp := g.clock.Now()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// kubelet_pleg_relist_latency_microseconds for prometheus metrics</span></span><br><span class="line">    <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        metrics.PLEGRelistLatency.Observe(metrics.SinceInMicroseconds(timestamp))</span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Get all the pods.</span></span><br><span class="line">    podList, err := g.runtime.GetPods(<span class="literal">true</span>)</span><br><span class="line">  :</span><br></pre></td></tr></table></figure>
<p>其中 <code>GetPods()</code> 函数的调用堆栈如下图所示：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114225223035.png" alt="image-20210114225223035"></p>
<p>相关的源代码如下：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//// pkg/kubelet/kuberuntime/kuberuntime_manager.go - GetPods()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// GetPods returns a list of containers grouped by pods. The boolean parameter</span></span><br><span class="line"><span class="comment">// specifies whether the runtime returns all containers including those already</span></span><br><span class="line"><span class="comment">// exited and dead containers (used for garbage collection).</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *kubeGenericRuntimeManager)</span> <span class="title">GetPods</span><span class="params">(all <span class="keyword">bool</span>)</span> <span class="params">([]*kubecontainer.Pod, error)</span></span> &#123;</span><br><span class="line">    pods := <span class="built_in">make</span>(<span class="keyword">map</span>[kubetypes.UID]*kubecontainer.Pod)</span><br><span class="line">    sandboxes, err := m.getKubeletSandboxes(all)</span><br><span class="line">:</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/kuberuntime/kuberuntime_sandbox.go - getKubeletSandboxes()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// getKubeletSandboxes lists all (or just the running) sandboxes managed by kubelet.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *kubeGenericRuntimeManager)</span> <span class="title">getKubeletSandboxes</span><span class="params">(all <span class="keyword">bool</span>)</span> <span class="params">([]*runtimeapi.PodSandbox, error)</span></span> &#123;</span><br><span class="line">:</span><br><span class="line">    resp, err := m.runtimeService.ListPodSandbox(filter)</span><br><span class="line">:</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/remote/remote_runtime.go - ListPodSandbox()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ListPodSandbox returns a list of PodSandboxes.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *RemoteRuntimeService)</span> <span class="title">ListPodSandbox</span><span class="params">(filter *runtimeapi.PodSandboxFilter)</span> <span class="params">([]*runtimeapi.PodSandbox, error)</span></span> &#123;</span><br><span class="line">:</span><br><span class="line">    resp, err := r.runtimeClient.ListPodSandbox(ctx, &amp;runtimeapi.ListPodSandboxRequest&#123;</span><br><span class="line">:</span><br><span class="line">    <span class="keyword">return</span> resp.Items, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>获取所有的 Pod 列表后，<code>relist</code> 的完成时间就会更新成当前的时间戳。也就是说，<code>Healthy()</code> 函数可以根据这个时间戳来评估 relist 是否超过了 3 分钟。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//// pkg/kubelet/pleg/generic.go - relist()</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// update as a current timestamp</span></span><br><span class="line">  g.updateRelistTime(timestamp)</span><br></pre></td></tr></table></figure>


<p>将当前的 Pod 列表和上一次 relist 的 Pod 列表进行对比之后，就会针对每一个变化生成相应的 Pod 级别的事件。相关的源代码如下：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//// pkg/kubelet/pleg/generic.go - relist()</span></span><br><span class="line"></span><br><span class="line">  pods := kubecontainer.Pods(podList)</span><br><span class="line">  g.podRecords.setCurrent(pods)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Compare the old and the current pods, and generate events.</span></span><br><span class="line">  eventsByPodID := <span class="keyword">map</span>[types.UID][]*PodLifecycleEvent&#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> pid := <span class="keyword">range</span> g.podRecords &#123;</span><br><span class="line">    oldPod := g.podRecords.getOld(pid)</span><br><span class="line">    pod := g.podRecords.getCurrent(pid)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get all containers in the old and the new pod.</span></span><br><span class="line">    allContainers := getContainersFromPods(oldPod, pod)</span><br><span class="line">    <span class="keyword">for</span> _, container := <span class="keyword">range</span> allContainers &#123;</span><br><span class="line">          events := computeEvents(oldPod, pod, &amp;container.ID)</span><br><span class="line"></span><br><span class="line">          <span class="keyword">for</span> _, e := <span class="keyword">range</span> events &#123;</span><br><span class="line">                updateEvents(eventsByPodID, e)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>


<p>其中 <code>generateEvents()</code> 函数（<code>computeEvents()</code> 函数会调用它）用来生成相应的 Pod 级别的事件（例如 <code>ContainerStarted</code>、<code>ContainerDied</code> 等等），然后通过 <code>updateEvents()</code> 函数来更新事件。</p>
<p><code>computeEvents()</code> 函数的内容如下：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//// pkg/kubelet/pleg/generic.go - computeEvents()</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">computeEvents</span><span class="params">(oldPod, newPod *kubecontainer.Pod, cid *kubecontainer.ContainerID)</span> []*<span class="title">PodLifecycleEvent</span></span> &#123;</span><br><span class="line">:</span><br><span class="line">    <span class="keyword">return</span> generateEvents(pid, cid.ID, oldState, newState)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/pleg/generic.go - generateEvents()</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">generateEvents</span><span class="params">(podID types.UID, cid <span class="keyword">string</span>, oldState, newState plegContainerState)</span> []*<span class="title">PodLifecycleEvent</span></span> &#123;</span><br><span class="line">:</span><br><span class="line">    glog.V(<span class="number">4</span>).Infof(<span class="string">&quot;GenericPLEG: %v/%v: %v -&gt; %v&quot;</span>, podID, cid, oldState, newState)</span><br><span class="line">    <span class="keyword">switch</span> newState &#123;</span><br><span class="line">    <span class="keyword">case</span> plegContainerRunning:</span><br><span class="line">      <span class="keyword">return</span> []*PodLifecycleEvent&#123;&#123;ID: podID, Type: ContainerStarted, Data: cid&#125;&#125;</span><br><span class="line">    <span class="keyword">case</span> plegContainerExited:</span><br><span class="line">      <span class="keyword">return</span> []*PodLifecycleEvent&#123;&#123;ID: podID, Type: ContainerDied, Data: cid&#125;&#125;</span><br><span class="line">    <span class="keyword">case</span> plegContainerUnknown:</span><br><span class="line">      <span class="keyword">return</span> []*PodLifecycleEvent&#123;&#123;ID: podID, Type: ContainerChanged, Data: cid&#125;&#125;</span><br><span class="line">    <span class="keyword">case</span> plegContainerNonExistent:</span><br><span class="line">      <span class="keyword">switch</span> oldState &#123;</span><br><span class="line">      <span class="keyword">case</span> plegContainerExited:</span><br><span class="line">        <span class="comment">// We already reported that the container died before.</span></span><br><span class="line">        <span class="keyword">return</span> []*PodLifecycleEvent&#123;&#123;ID: podID, Type: ContainerRemoved, Data: cid&#125;&#125;</span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        <span class="keyword">return</span> []*PodLifecycleEvent&#123;&#123;ID: podID, Type: ContainerDied, Data: cid&#125;, &#123;ID: podID, Type: ContainerRemoved, Data: cid&#125;&#125;</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="built_in">panic</span>(fmt.Sprintf(<span class="string">&quot;unrecognized container state: %v&quot;</span>, newState))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>relist 的最后一个任务是检查是否有与 Pod 关联的事件，并按照下面的流程更新 <code>podCache</code>。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//// pkg/kubelet/pleg/generic.go - relist()</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// If there are events associated with a pod, we should update the</span></span><br><span class="line">  <span class="comment">// podCache.</span></span><br><span class="line">  <span class="keyword">for</span> pid, events := <span class="keyword">range</span> eventsByPodID &#123;</span><br><span class="line">    pod := g.podRecords.getCurrent(pid)</span><br><span class="line">    <span class="keyword">if</span> g.cacheEnabled() &#123;</span><br><span class="line">      <span class="comment">// updateCache() will inspect the pod and update the cache. If an</span></span><br><span class="line">      <span class="comment">// error occurs during the inspection, we want PLEG to retry again</span></span><br><span class="line">      <span class="comment">// in the next relist. To achieve this, we do not update the</span></span><br><span class="line">      <span class="comment">// associated podRecord of the pod, so that the change will be</span></span><br><span class="line">      <span class="comment">// detect again in the next relist.</span></span><br><span class="line">      <span class="comment">// <span class="doctag">TODO:</span> If many pods changed during the same relist period,</span></span><br><span class="line">      <span class="comment">// inspecting the pod and getting the PodStatus to update the cache</span></span><br><span class="line">      <span class="comment">// serially may take a while. We should be aware of this and</span></span><br><span class="line">      <span class="comment">// parallelize if needed.</span></span><br><span class="line">      <span class="keyword">if</span> err := g.updateCache(pod, pid); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        glog.Errorf(<span class="string">&quot;PLEG: Ignoring events for pod %s/%s: %v&quot;</span>, pod.Name, pod.Namespace, err)</span><br><span class="line">        :</span><br><span class="line">      &#125;</span><br><span class="line">      :</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Update the internal storage and send out the events.</span></span><br><span class="line">    g.podRecords.update(pid)</span><br><span class="line">    <span class="keyword">for</span> i := <span class="keyword">range</span> events &#123;</span><br><span class="line">      <span class="comment">// Filter out events that are not reliable and no other components use yet.</span></span><br><span class="line">      <span class="keyword">if</span> events[i].Type == ContainerChanged &#123;</span><br><span class="line">           <span class="keyword">continue</span></span><br><span class="line">      &#125;</span><br><span class="line">      g.eventChannel &lt;- events[i]</span><br><span class="line">     &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p><code>updateCache()</code> 将会检查每个 Pod，并在单个循环中依次对其进行更新。因此，如果在同一个 relist 中更改了大量的 Pod，那么 updateCache 过程将会成为瓶颈。最后，更新后的 Pod 生命周期事件将会被发送到 <code>eventChannel</code>。</p>
<p>某些远程客户端还会调用每一个 Pod 来获取 Pod 的 spec 定义信息，这样一来，Pod 数量越多，延时就可能越高，因为 Pod 越多就会生成越多的事件。</p>
<p><code>updateCache()</code> 的详细调用堆栈如下图所示，其中 <code>GetPodStatus()</code> 用来获取 Pod 的 spec 定义信息：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114225229827.png" alt="image-20210114225229827"></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//// pkg/kubelet/pleg/generic.go - updateCache()</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(g *GenericPLEG)</span> <span class="title">updateCache</span><span class="params">(pod *kubecontainer.Pod, pid types.UID)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">:</span><br><span class="line">    timestamp := g.clock.Now()</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> Consider adding a new runtime method</span></span><br><span class="line">    <span class="comment">// GetPodStatus(pod *kubecontainer.Pod) so that Docker can avoid listing</span></span><br><span class="line">    <span class="comment">// all containers again.</span></span><br><span class="line">    status, err := g.runtime.GetPodStatus(pod.ID, pod.Name, pod.Namespace)</span><br><span class="line">  :</span><br><span class="line">    g.cache.Set(pod.ID, status, err, timestamp)</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/kuberuntime/kuberuntime_manager.go - GetPodStatus()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// GetPodStatus retrieves the status of the pod, including the</span></span><br><span class="line"><span class="comment">// information of all containers in the pod that are visible in Runtime.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *kubeGenericRuntimeManager)</span> <span class="title">GetPodStatus</span><span class="params">(uid kubetypes.UID, name, namespace <span class="keyword">string</span>)</span> <span class="params">(*kubecontainer.PodStatus, error)</span></span> &#123;</span><br><span class="line">  podSandboxIDs, err := m.getSandboxIDByPodUID(uid, <span class="literal">nil</span>)</span><br><span class="line">  :</span><br><span class="line">    <span class="keyword">for</span> idx, podSandboxID := <span class="keyword">range</span> podSandboxIDs &#123;</span><br><span class="line">        podSandboxStatus, err := m.runtimeService.PodSandboxStatus(podSandboxID)</span><br><span class="line">    :</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get statuses of all containers visible in the pod.</span></span><br><span class="line">    containerStatuses, err := m.getPodContainerStatuses(uid, name, namespace)</span><br><span class="line">  :</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/kuberuntime/kuberuntime_sandbox.go - getSandboxIDByPodUID()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// getPodSandboxID gets the sandbox id by podUID and returns ([]sandboxID, error).</span></span><br><span class="line"><span class="comment">// Param state could be nil in order to get all sandboxes belonging to same pod.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *kubeGenericRuntimeManager)</span> <span class="title">getSandboxIDByPodUID</span><span class="params">(podUID kubetypes.UID, state *runtimeapi.PodSandboxState)</span> <span class="params">([]<span class="keyword">string</span>, error)</span></span> &#123;</span><br><span class="line">  :</span><br><span class="line">  sandboxes, err := m.runtimeService.ListPodSandbox(filter)</span><br><span class="line">  :  </span><br><span class="line">  <span class="keyword">return</span> sandboxIDs, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/remote/remote_runtime.go - PodSandboxStatus()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// PodSandboxStatus returns the status of the PodSandbox.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *RemoteRuntimeService)</span> <span class="title">PodSandboxStatus</span><span class="params">(podSandBoxID <span class="keyword">string</span>)</span> <span class="params">(*runtimeapi.PodSandboxStatus, error)</span></span> &#123;</span><br><span class="line">    ctx, cancel := getContextWithTimeout(r.timeout)</span><br><span class="line">    <span class="keyword">defer</span> cancel()</span><br><span class="line"></span><br><span class="line">    resp, err := r.runtimeClient.PodSandboxStatus(ctx, &amp;runtimeapi.PodSandboxStatusRequest&#123;</span><br><span class="line">        PodSandboxId: podSandBoxID,</span><br><span class="line">    &#125;)</span><br><span class="line">  :</span><br><span class="line">    <span class="keyword">return</span> resp.Status, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//// pkg/kubelet/kuberuntime/kuberuntime_container.go - getPodContainerStatuses()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// getPodContainerStatuses gets all containers&#x27; statuses for the pod.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *kubeGenericRuntimeManager)</span> <span class="title">getPodContainerStatuses</span><span class="params">(uid kubetypes.UID, name, namespace <span class="keyword">string</span>)</span> <span class="params">([]*kubecontainer.ContainerStatus, error)</span></span> &#123;</span><br><span class="line">  <span class="comment">// Select all containers of the given pod.</span></span><br><span class="line">  containers, err := m.runtimeService.ListContainers(&amp;runtimeapi.ContainerFilter&#123;</span><br><span class="line">    LabelSelector: <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>&#123;types.KubernetesPodUIDLabel: <span class="keyword">string</span>(uid)&#125;,</span><br><span class="line">  &#125;)</span><br><span class="line">  :</span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> optimization: set maximum number of containers per container name to examine.</span></span><br><span class="line">  <span class="keyword">for</span> i, c := <span class="keyword">range</span> containers &#123;</span><br><span class="line">    status, err := m.runtimeService.ContainerStatus(c.Id)</span><br><span class="line">    :</span><br><span class="line">  &#125;</span><br><span class="line">  :</span><br><span class="line">  <span class="keyword">return</span> statuses, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面就是 relist() 函数的完整调用堆栈，我在讲解的过程中结合了相关的源代码，希望能为你提供有关 PLEG 的更多细节。为了实时了解 PLEG 的健康状况，最好的办法就是监控 relist。</p>
<h2 id="监控-relist"><a href="#监控-relist" class="headerlink" title="监控 relist"></a>监控 relist</h2><p>我们可以通过监控 Kubelet 的指标来了解 <code>relist</code> 的延时。<code>relist</code> 的调用周期是 1s，那么 <strong>relist 的完成时间 + 1s</strong> 就等于 <code>kubelet_pleg_relist_interval_microseconds</code> 指标的值。你也可以监控容器运行时每个操作的延时，这些指标在排查故障时都能提供线索。</p>
<p><img src="https://hugo-picture.oss-cn-beijing.aliyuncs.com/images/pleg-kubelet-metrics-table.png" alt="img"></p>
<p>你可以在每个节点上通过访问 URL <code>https://127.0.0.1:10250/metrics</code> 来获取 Kubelet 的指标。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># HELP kubelet_pleg_relist_interval_microseconds Interval in microseconds between relisting in PLEG.</span><br><span class="line"># TYPE kubelet_pleg_relist_interval_microseconds summary</span><br><span class="line">kubelet_pleg_relist_interval_microseconds&#123;quantile&#x3D;&quot;0.5&quot;&#125; 1.054052e+06</span><br><span class="line">kubelet_pleg_relist_interval_microseconds&#123;quantile&#x3D;&quot;0.9&quot;&#125; 1.074873e+06</span><br><span class="line">kubelet_pleg_relist_interval_microseconds&#123;quantile&#x3D;&quot;0.99&quot;&#125; 1.126039e+06</span><br><span class="line">kubelet_pleg_relist_interval_microseconds_count 5146</span><br><span class="line"></span><br><span class="line"># HELP kubelet_pleg_relist_latency_microseconds Latency in microseconds for relisting pods in PLEG.</span><br><span class="line"># TYPE kubelet_pleg_relist_latency_microseconds summary</span><br><span class="line">kubelet_pleg_relist_latency_microseconds&#123;quantile&#x3D;&quot;0.5&quot;&#125; 53438</span><br><span class="line">kubelet_pleg_relist_latency_microseconds&#123;quantile&#x3D;&quot;0.9&quot;&#125; 74396</span><br><span class="line">kubelet_pleg_relist_latency_microseconds&#123;quantile&#x3D;&quot;0.99&quot;&#125; 115232</span><br><span class="line">kubelet_pleg_relist_latency_microseconds_count 5106</span><br><span class="line"></span><br><span class="line"># HELP kubelet_runtime_operations Cumulative number of runtime operations by operation type.</span><br><span class="line"># TYPE kubelet_runtime_operations counter</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;container_status&quot;&#125; 472</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;create_container&quot;&#125; 93</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;exec&quot;&#125; 1</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;exec_sync&quot;&#125; 533</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;image_status&quot;&#125; 579</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;list_containers&quot;&#125; 10249</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;list_images&quot;&#125; 782</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;list_podsandbox&quot;&#125; 10154</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;podsandbox_status&quot;&#125; 315</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;pull_image&quot;&#125; 57</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;remove_container&quot;&#125; 49</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;run_podsandbox&quot;&#125; 28</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;start_container&quot;&#125; 93</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;status&quot;&#125; 1116</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;stop_container&quot;&#125; 9</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;stop_podsandbox&quot;&#125; 33</span><br><span class="line">kubelet_runtime_operations&#123;operation_type&#x3D;&quot;version&quot;&#125; 564</span><br><span class="line"></span><br><span class="line"># HELP kubelet_runtime_operations_latency_microseconds Latency in microseconds of runtime operations. Broken down by operation type.</span><br><span class="line"># TYPE kubelet_runtime_operations_latency_microseconds summary</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;container_status&quot;,quantile&#x3D;&quot;0.5&quot;&#125; 12117</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;container_status&quot;,quantile&#x3D;&quot;0.9&quot;&#125; 26607</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;container_status&quot;,quantile&#x3D;&quot;0.99&quot;&#125; 27598</span><br><span class="line">kubelet_runtime_operations_latency_microseconds_count&#123;operation_type&#x3D;&quot;container_status&quot;&#125; 486</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;list_containers&quot;,quantile&#x3D;&quot;0.5&quot;&#125; 29972</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;list_containers&quot;,quantile&#x3D;&quot;0.9&quot;&#125; 47907</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;list_containers&quot;,quantile&#x3D;&quot;0.99&quot;&#125; 80982</span><br><span class="line">kubelet_runtime_operations_latency_microseconds_count&#123;operation_type&#x3D;&quot;list_containers&quot;&#125; 10812</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;list_podsandbox&quot;,quantile&#x3D;&quot;0.5&quot;&#125; 18053</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;list_podsandbox&quot;,quantile&#x3D;&quot;0.9&quot;&#125; 28116</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;list_podsandbox&quot;,quantile&#x3D;&quot;0.99&quot;&#125; 68748</span><br><span class="line">kubelet_runtime_operations_latency_microseconds_count&#123;operation_type&#x3D;&quot;list_podsandbox&quot;&#125; 10712</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;podsandbox_status&quot;,quantile&#x3D;&quot;0.5&quot;&#125; 4918</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;podsandbox_status&quot;,quantile&#x3D;&quot;0.9&quot;&#125; 15671</span><br><span class="line">kubelet_runtime_operations_latency_microseconds&#123;operation_type&#x3D;&quot;podsandbox_status&quot;,quantile&#x3D;&quot;0.99&quot;&#125; 18398</span><br><span class="line">kubelet_runtime_operations_latency_microseconds_count&#123;operation_type&#x3D;&quot;podsandbox_status&quot;&#125; 323</span><br></pre></td></tr></table></figure>
<p>可以通过 Prometheus 对其进行监控：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114225238233.png" alt="image-20210114225238233"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以我的经验，造成 <strong>PLEG is not healthy</strong> 的因素有很多，而且我相信还有更多潜在的因素我们还没有遇到过。我只提供几个我能想到的原因：</p>
<ul>
<li>RPC 调用过程中容器运行时响应超时（有可能是性能下降，死锁或者出现了 bug）。</li>
<li>节点上的 Pod 数量太多，导致 <code>relist</code> 无法在 3 分钟内完成。事件数量和延时与 Pod 数量成正比，与节点资源无关。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/issues/72482">relist 出现了死锁</a>，该 bug 已在 Kubernetes 1.14 中修复。</li>
<li>获取 Pod 的网络堆栈信息时 CNI 出现了 bug。</li>
</ul>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114225243628.png" alt="image-20210114225243628"></p>
<h2 id="摘抄文档"><a href="#摘抄文档" class="headerlink" title="摘抄文档"></a>摘抄文档</h2><p><a target="_blank" rel="noopener" href="https://fuckcloudnative.io/posts/understanding-the-pleg-is-not-healthy/">深入理解 Kubelet 中的 PLEG is not healthy</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/pod-lifecycle-event-generator.md">Kubelet: Pod Lifecycle Event Generator (PLEG)</a>-Github</p>
<p><a target="_blank" rel="noopener" href="https://my.oschina.net/jxcdwangtao/blog/2253578">Kubelet PLEG源码分析</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://heavyfish.github.io/2020/11/20/k8s/%E4%BB%8B%E7%BB%8DKubernetes%E4%B8%AD%E7%9A%84%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E6%8E%A5%E5%8F%A3%EF%BC%88CRI%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/heavyfish.github.io/images/avatar.gif">
      <meta itemprop="name" content="Shenxr">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="速查笔记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/heavyfish.github.io/2020/11/20/k8s/%E4%BB%8B%E7%BB%8DKubernetes%E4%B8%AD%E7%9A%84%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E6%8E%A5%E5%8F%A3%EF%BC%88CRI%EF%BC%89/" class="post-title-link" itemprop="url">CRI简介</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-20 17:19:06" itemprop="dateCreated datePublished" datetime="2020-11-20T17:19:06+08:00">2020-11-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-14 23:08:45" itemprop="dateModified" datetime="2021-01-14T23:08:45+08:00">2021-01-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/heavyfish.github.io/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="1、CRI"><a href="#1、CRI" class="headerlink" title="1、CRI"></a>1、CRI</h1><p><strong>本文翻译于<a target="_blank" rel="noopener" href="https://kubernetes.io/blog/2016/12/container-runtime-interface-cri-in-kubernetes/">Introducing Container Runtime Interface (CRI) in Kubernetes</a></strong></p>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>在Kubernetes节点的最底层是一个软件，它可以启动和停止容器。我们称之为“容器运行时/<strong>Container Runtime</strong>”。最广为人知的容器运行时是Docker，但在这个领域它并不是唯一的。事实上，容器运行时领域一直在快速发展。作为使Kubernetes更具可扩展性的一部分，我们一直在为Kubernetes中的容器运行时开发一个新的插件API，称为“CRI”。</p>
<h2 id="什么是CRI？为什么Kubernetes需要它？"><a href="#什么是CRI？为什么Kubernetes需要它？" class="headerlink" title="什么是CRI？为什么Kubernetes需要它？"></a>什么是CRI？为什么Kubernetes需要它？</h2><p>每个容器运行时都有自己的优势，许多用户要求Kubernetes支持更多的<code>runtime</code>。在kubernetes1.5版本中，我们很自豪地引入了<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/242a97307b34076d5d8f5bbeb154fa4d97c9ef1d/docs/devel/container-runtime-interface.md"><strong>Container Runtime Interface（CRI）</strong></a>——一个插件接口，它使kubelet能够使用各种各样的容器运行时，而无需重新编译。CRI包括一个协议缓冲区（ <a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/">protocol buffers</a>）和<a target="_blank" rel="noopener" href="http://www.grpc.io/"><strong>grpc api</strong></a>，以及一些正在开发的附加规范和工具的库。CRI在Kubernetes1.5中以Alpha的形式发布。</p>
<p>在Kubernetes中，支持可互换的容器运行时并不是一个新概念。在1.3版本中，我们宣布了rktnetes项目，以启用rkt容器引擎作为Docker容器运行时的替代方案。然而，Docker和rkt都是通过一个内部的 <code>volatile</code> 接口直接和深入地集成到kubelet源代码中的。这样的集成过程需要深入了解Kubelet的内部结构，并且会给Kubernetes社区带来大量的维护开销。这些因素对新生的容器运行时形成了很高的进入壁垒。通过提供一个明确定义的抽象层，我们消除了障碍，并允许开发人员专注于构建他们的容器运行时。这是朝着真正实现可插拔容器运行时和构建更健康的生态系统迈出的一小步，但却是重要的一步。</p>
<h2 id="CRI概览"><a href="#CRI概览" class="headerlink" title="CRI概览"></a>CRI概览</h2><p>Kubelet使用gRPC框架通过Unix套接字与容器运行时（或运行时的CRI-shim）通信，Kubelet充当client，CRI-shim作为server。</p>
<p>![img](<a target="_blank" rel="noopener" href="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/Image">https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/Image</a> 2016-12-19 at 17.13.16-20210114230423672.png)</p>
<p>protocol buffers API包括两个gRPC服务，ImageService和RuntimeService。ImageService提供了从仓库中提取image、检查和删除image的RPC。RuntimeService包含用于管理pod和容器生命周期的rpc，以及与容器交互的调用（exec/attach/port forward）。一个同时管理镜像和容器（例如Docker和rkt）的单一容器运行时可以通过单个套接字同时提供这两种服务。可以通过<code>--container-runtime-endpoint</code>和<code>--image-service-endpoint</code> 在Kubelet中设置套接字。</p>
<p><strong>Pod and container lifecycle management</strong></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">service RuntimeService &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Sandbox operations.</span></span><br><span class="line"></span><br><span class="line">    rpc RunPodSandbox(RunPodSandboxRequest) returns (RunPodSandboxResponse) &#123;&#125;  </span><br><span class="line">    rpc StopPodSandbox(StopPodSandboxRequest) returns (StopPodSandboxResponse) &#123;&#125;  </span><br><span class="line">    rpc RemovePodSandbox(RemovePodSandboxRequest) returns (RemovePodSandboxResponse) &#123;&#125;  </span><br><span class="line">    rpc PodSandboxStatus(PodSandboxStatusRequest) returns (PodSandboxStatusResponse) &#123;&#125;  </span><br><span class="line">    rpc ListPodSandbox(ListPodSandboxRequest) returns (ListPodSandboxResponse) &#123;&#125;  </span><br><span class="line"></span><br><span class="line">    <span class="comment">// Container operations.  </span></span><br><span class="line">    rpc CreateContainer(CreateContainerRequest) returns (CreateContainerResponse) &#123;&#125;  </span><br><span class="line">    rpc StartContainer(StartContainerRequest) returns (StartContainerResponse) &#123;&#125;  </span><br><span class="line">    rpc StopContainer(StopContainerRequest) returns (StopContainerResponse) &#123;&#125;  </span><br><span class="line">    rpc RemoveContainer(RemoveContainerRequest) returns (RemoveContainerResponse) &#123;&#125;  </span><br><span class="line">    rpc ListContainers(ListContainersRequest) returns (ListContainersResponse) &#123;&#125;  </span><br><span class="line">    rpc ContainerStatus(ContainerStatusRequest) returns (ContainerStatusResponse) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    ...  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Pod由一组应用程序容器组成，这些容器位于一个有资源限制的隔离环境中。在CRI中，这种环境被称为PodSandbox。我们有意为容器运行时留出一些空间，以根据它们内部的操作方式对PodSandbox进行不同的解释。对于基于hypervisor的运行时，PodSandbox可能表示一个虚拟机。对于其他，比如Docker，它可能是Linux名称空间。PodSandbox必须遵守pod资源规范。在<code>v1alpha1 API</code>中，这是通过启动kubelet创建并传递给运行时的pod级cgroup中的所有进程来实现的。</p>
<p>在启动Pod之前，kubelet call RuntimeService.RunPodSandbox创造环境。这包括为pod设置网络（例如，分配IP）。一旦PodSandbox处于活动状态，就可以独立地创建/启动/停止/删除单个容器。为了删除pod，kubelet将在停止并移除PodSandbox之前停止并移除容器。</p>
<p>Kubelet负责通过RPC管理容器的生命周期，执行容器生命周期挂钩和<code>liveness/readiness</code>检查，同时遵守pod的重启策略。</p>
<h2 id="为什么是一个强制性的以容器为中心的接口"><a href="#为什么是一个强制性的以容器为中心的接口" class="headerlink" title="为什么是一个强制性的以容器为中心的接口?"></a>为什么是一个强制性的以容器为中心的接口?</h2><p>Kubernetes有一个带有Pod resource的声明性API。我们考虑的一个可能的设计是让CRI在其抽象中重用声明性Pod对象，让容器运行时自由地实现和执行自己的控制逻辑，以达到所需的状态。这将大大简化API，并允许CRI使用更广泛的运行时。我们在设计阶段的早期讨论了这种方法，并基于几个原因决定不采用它。首先，kubelet中有许多Pod级特性和特定机制（例如，崩溃循环退避逻辑），这将是所有运行时重新实现的一个重大负担。第二，也是更重要的是，Pod规范过去（现在）仍在快速发展。许多新特性（例如init容器）不需要对底层容器运行时进行任何更改,只需要kubelet直接管理容器。CRI采用了一个命令式容器级接口，这样运行时就可以共享这些共同的特性，从而获得更好的开发速度。这并不意味着我们偏离了“水平触发/level triggered”的哲学——kubelet负责确保实际状态被驱动到声明状态。</p>
<p><strong>Exec/attach/port-forward requests</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">service RuntimeService &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ExecSync runs a command in a container synchronously.  </span><br><span class="line">    rpc ExecSync(ExecSyncRequest) returns (ExecSyncResponse) &#123;&#125;  </span><br><span class="line">    &#x2F;&#x2F; Exec prepares a streaming endpoint to execute a command in the container.  </span><br><span class="line">    rpc Exec(ExecRequest) returns (ExecResponse) &#123;&#125;  </span><br><span class="line">    &#x2F;&#x2F; Attach prepares a streaming endpoint to attach to a running container.  </span><br><span class="line">    rpc Attach(AttachRequest) returns (AttachResponse) &#123;&#125;  </span><br><span class="line">    &#x2F;&#x2F; PortForward prepares a streaming endpoint to forward ports from a PodSandbox.  </span><br><span class="line">    rpc PortForward(PortForwardRequest) returns (PortForwardResponse) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    ...  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Kubernetes提供了一些特性（例如kubectl exec/attach/port forward）供用户与pod和其中的容器进行交互。现在，Kubelet通过调用容器运行时的本地方法调用或使用节点上可用的工具（例如nsenter和socat）来支持这些特性。在节点上使用工具不是一个可移植的解决方案，因为大多数工具都假设pod是使用Linux名称空间隔离的。在CRI中，我们在API中显式地定义这些调用，以允许特定于运行时的实现。</p>
<p>目前kubelet实现的另一个潜在问题是kubelet处理所有 数据流请求的连接，因此它可能成为节点上网络流量的瓶颈。在设计CRI时，我们结合了这个反馈，以允许运行时消除中间件。容器运行时可以根据请求启动一个单独的<code>streaming server</code>（并且可以潜在地将资源使用情况计入pod！），并将服务器的位置返回给kubelet。然后Kubelet将这些信息返回给Kubernetes API server ，后者直接打开到运行时提供的服务器的流连接，并将其连接到客户端。</p>
<p>CRI还有许多其他方面没有在这篇博文中涉及。详情请参阅<a target="_blank" rel="noopener" href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md#design-docs-and-proposals">设计文件及建议书</a>一览表</p>
<h2 id="当前状态"><a href="#当前状态" class="headerlink" title="当前状态"></a>当前状态</h2><p>尽管CRI仍处于早期阶段，但已经有几个项目正在开发中，以使用CRI集成容器运行时。以下是几个例子：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://cri-o.io/">cri-o</a>: 符合OCI的运行时</li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes-incubator/rktlet">rktlet</a>: rkt容器运行时</li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/frakti">frakti</a>: 基于hypervisor的容器运行时</li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/tree/release-1.5/pkg/kubelet/dockershim">docker CRI shim</a>.</li>
</ul>
<h1 id="2、概念解释"><a href="#2、概念解释" class="headerlink" title="2、概念解释"></a>2、概念解释</h1><p>docker、containered，runc，CRI，cri-o，docker CRI shim，shim，docker-init，docker-proxy</p>
<h2 id="OCI"><a href="#OCI" class="headerlink" title="OCI"></a>OCI</h2><p>开放容器计划（<strong>Open Container Initiative</strong>）是一个开放治理结构，其明确目的是围绕容器格式和运行时创建开放行业标准。</p>
<p>OCI由Docker和其他容器行业的领导者于2015年6月建立，目前包含两个规范：运行时规范（runtime-spec）和镜像规范（image-spec）。运行时规范概述了如何运行在解压到磁盘上的“<code>文件系统包/filesystem bundle</code>”。在较高级别上，OCI实现将下载OCI镜像，然后将该镜像解压缩为OCI Runtime filesystem bundle。此时，OCI Runtime filesystem bundle将由OCI运行时运行。</p>
<p>详情参见：</p>
<p><a target="_blank" rel="noopener" href="https://opencontainers.org/">OCI官网</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/yanjingnan/p/6474272.html">OCI(Open Container Initiative) &amp; OCF (Open Container Format)-博客园</a></p>
<h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><p>在1.11版本之前，Docker的实现是一个单片守护进程。monolith将所有事情都作为一个包来完成，比如下载容器映像、启动容器进程、暴露远程API、充当日志收集守护进程，所有这些都在一个以root用户身份运行的集中进程中。</p>
<p>这种集中式体系结构在部署方面有一些好处，但也暴露出其他一些基本问题。例如，它没有遵循Unix进程和权限分离的最佳实践。此外，这种单片实现使得Docker很难与Linux init systems正确集成，如 upstart和systemd 等。</p>
<p>当Docker1.11发布时，这导致了Docker被分成了不同的部分，如下面开头的段落所述。</p>
<blockquote>
<p>“我们很高兴推出DockerEngine1.11，这是我们基于<em>runC</em> 和 <em>containerd</em> 的第一个版本。Docker也是第一个发布基于OCI技术的runtime。</p>
</blockquote>
<p>有关OCI的信息参见其<a target="_blank" rel="noopener" href="https://www.opencontainers.org/">官网</a>。</p>
<p>下图展示了Docker1.11在runC 和 containerd 上构建的新架构：</p>
<img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20201120182454155.png" alt="image-20201120182454155" style="zoom:50%;" />

<p>自此，containerd现在处理容器的执行，这以前是由docker守护进程自己完成的。如下是确切的流程：</p>
<ol>
<li>用户从Docker CLI运行命令</li>
<li>Docker CLI与Docker daemon（dockerd）对话</li>
<li>Docker daemon（dockerd）监听请求并通过containerd管理容器的生命周期</li>
<li>containerd通过runC接收请求并启动一个容器，并在主机内执行所有的容器生命周期</li>
</ol>
<p>注意：简而言之，<strong>runc</strong>是用于根据OCI规范生成和运行容器的CLI工具。</p>
<p>更具体的细节如下：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/v2-73abb366122482d1050d4863105532e8_1440w.jpg" alt="img"></p>
<ol>
<li>containerd 收到请求后, 并不会自己直接去操作容器, 而是创建一个叫做 containerd-shim 的进程, 让 containerd-shim 去操作容器。</li>
<li>因为容器进程需要一个父进程来做诸如收集状态, 维持 stdin 等 fd 打开等工作. 而假如这个父进程就是 containerd, 那每次 containerd 挂掉或升级, 整个宿主机上所有的容器都得退出了。 而引入了 containerd-shim 就规避了这个问题(containerd 和 shim 并不需要是父子进程关系, 当 containerd 退出或重启时, shim 会 re-parent 到 systemd 这样的 1 号进程上);</li>
<li>我们知道创建容器需要做一些设置 namespaces 和 cgroups, 挂载 root filesystem 等等操作, 而这些事该怎么做已经有了公开的规范了, 那就是 OCI(Open Container Initiative, 开放容器标准). 它的一个参考实现叫做 runc. 于是, containerd-shim 在这一步需要调用 runc 这个命令行工具, 来启动容器;</li>
<li>runc 启动完容器后本身会直接退出, containerd-shim 则会成为容器进程的父进程, 负责收集容器进程的状态, 上报给 containerd, 并在容器中 pid 为 1 的进程退出后接管容器中的子进程进行清理, 确保不会出现僵尸进程;</li>
</ol>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker     ctr</span><br><span class="line">  |         |</span><br><span class="line">  V         V</span><br><span class="line">dockerd -&gt; containerd ---&gt; shim -&gt; runc -&gt; runc init -&gt; process</span><br><span class="line">                      |-- &gt; shim -&gt; runc -&gt; runc init -&gt; process</span><br><span class="line">                      +-- &gt; shim -&gt; runc -&gt; runc init -&gt; process```</span><br></pre></td></tr></table></figure>


<h2 id="Containerd"><a href="#Containerd" class="headerlink" title="Containerd"></a>Containerd</h2><p><a target="_blank" rel="noopener" href="https://github.com/docker/containerd">containerd </a>是容器技术标准化之后的产物，为了能够兼容<a target="_blank" rel="noopener" href="https://www.opencontainers.org/"> OCI 标准</a>，将容器运行时及其管理功能从 Docker Daemon 剥离，形成了containerd。理论上，即使不运行 dockerd，也能够直接通过 containerd 来管理容器。当然，containerd 本身也只是一个守护进程，容器的实际运行时由后面介绍的 runC 控制。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/c1dcc33c3ca13f1f07b2a1fdcf8cadc8.png" alt="img"></p>
<p>containerd 向上为 Docker Daemon 提供了 gRPC 接口，使得 Docker Daemon 屏蔽下面的结构变化，确保原有接口向下兼容。向下通过 containerd-shim 结合 runC，使得引擎可以独立升级，避免之前 Docker Daemon 升级会导致所有容器不可用的问题。</p>
<p>现在，让我们转移我们的注意力，来了解<code>containerd</code>的全部含义。从较高的角度来看，containerd是控制runC的守护程序。在<a target="_blank" rel="noopener" href="https://containerd.io/">containerd</a>官网上，“ containerd管理着其主机系统的整个容器生命周期，从镜像传输和存储到容器执行和监督，再到低级存储再到网络附件等等。</p>
<p>containerd帮助抽象化系统调用或特定于操作系统的功能，以在Linux，Windows或任何其他操作系统上运行容器。它提供了一个client层，任何其他平台（例如Docker或Kubernetes）都可以在该client层上构建，而无需关心内核级别的细节。应该注意的是，在Kubernetes中，containerd可以用作CRI runtime。这些是通过利用containerd获得的：</p>
<ul>
<li>获得 push 和 pull 功能</li>
<li>镜像管理API，用于创建，执行和管理容器及其任务</li>
<li>快照管理。</li>
<li>您将获得所有这些，而不必再为底层的操作系统细节而费解</li>
</ul>
<h2 id="CRI-O"><a href="#CRI-O" class="headerlink" title="CRI-O"></a>CRI-O</h2><p>现在进入CRI-O。在深入研究CRI-O之前，让我们先简要介绍一下CRI pool，即Container Runtime Interface。 CRI是一个插件接口，使kubelet能够使用不同的OCI兼容容器运行时（例如containerd，docker或cri-o），而无需重新编译Kubernetes。如您所知，Kubelet是用于创建Pod和启动容器的集群节点代理</p>
<p>要了解对CRI的需求，明智的是了解Kubernetes在此之前所经历的痛点。 Kubernetes以前绑定到特定的容器运行时，这为上游Kubernetes社区带来了大量维护开销。此外，在Kubernetes上构建解决方案的供应商也经历了相同的开销。这就需要开发CRI，以使Kubernetes容器与各种运行时解耦，从而使其与运行时无关。</p>
<p>由于已经构建了插件，因此CRI-O项目已开始提供专门用于Kubernetes的轻量级运行时。 CRI-O使Kubernetes无需大量工具和代码即可直接运行容器。</p>
<h3 id="CRI-O的组件"><a href="#CRI-O的组件" class="headerlink" title="CRI-O的组件"></a>CRI-O的组件</h3><ul>
<li>OCI兼容的runtime：默认为<code>runC</code>，还支持其他OCI兼容，例如Kata容器。</li>
<li>containers/storage：库用于从仓库中提取镜像。用于管理层和为Pod中的容器创建根文件系统的库。</li>
<li>containers/image：用于从仓库中提取镜像的库。</li>
<li>networking (CNI)：用于为Pod设置网络。 Flannel，Weave和OpenShift-SDN CNI插件已经过测试</li>
<li>container monitoring (conmon)：CRI-O中的实用程序，用于监视容器</li>
<li>Linux的几个核心功能提供了安全性</li>
</ul>
<p>下面的截图说明了整个Kubernetes和CRI-O过程</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230525843.png" alt="image-20210114230525843"></p>
<h2 id="runc"><a href="#runc" class="headerlink" title="runc"></a>runc</h2><p>OCI 定义了容器运行时标准，runC 是 Docker 按照开放容器格式标准（OCF, Open Container Format）制定的一种具体实现。</p>
<p>runC 是从 Docker 的 libcontainer 中迁移而来的，实现了容器启停、资源隔离等功能。RunC 作为容器的runtime，不包含镜像的管理，如果直接使用，需要先准备好镜像</p>
<h2 id="OCI-Bundle"><a href="#OCI-Bundle" class="headerlink" title="OCI Bundle"></a>OCI Bundle</h2><p>OCI Bundle 是指满足 OCI 标准的一系列文件，这些文件包含了运行容器所需要的所有数据，它们存放在一个共同的目录，该目录包含以下两项：</p>
<ul>
<li><code>config.json</code> 包含容器运行的配置数据；</li>
<li>容器的 root filesystem 。</li>
</ul>
<p>如果主机上安装了 Docker，那么可以使用 <code>docker export</code> 命令将已有镜像导出为 OCI Bundle 的格式。</p>
<h2 id="Container-runtime"><a href="#Container-runtime" class="headerlink" title="Container runtime"></a>Container runtime</h2><p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/runtimes.png" alt="img"></p>
<img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20201122234600468.png" alt="image-20201122234600468" style="zoom:50%;" />

<p>container runtime 分为了 low-level 和 high-level</p>
<img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20201122233439802.png" alt="image-20201122233439802" style="zoom:50%;" />

<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230603051.png" alt="image-20210114230603051"></p>
<blockquote>
<p>目前最好的配置是containerD + runc。但Dockershim+runc 是多数环境的默认配置。</p>
</blockquote>
<h2 id="Kubernetes-中-runtime-一览"><a href="#Kubernetes-中-runtime-一览" class="headerlink" title="Kubernetes 中 runtime 一览"></a>Kubernetes 中 runtime 一览</h2><p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230614969.png" alt="image-20210114230614969"></p>
<p>docker-shim 作为一个实现了CRI 接口的gRPC服务器，供 kubelet 使用。这样的过程其实就是，kubelet作为客户端 通过gRPC调用dockershim服务器，dockershim 内部又通过docker客户端走 http 调用 docker daemon api，多走了一次通讯的开销。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230620576.png" alt="image-20210114230620576"></p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230626144.png" alt="image-20210114230626144"></p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230632126.png" alt="image-20210114230632126"></p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230641228.png" alt="image-20210114230641228"></p>
<h2 id="本节参考文档"><a href="#本节参考文档" class="headerlink" title="本节参考文档"></a>本节参考文档</h2><p><a target="_blank" rel="noopener" href="https://opencontainers.org/">OCI官网</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/yanjingnan/p/6474272.html">OCI(Open Container Initiative) &amp; OCF (Open Container Format)-博客园</a></p>
<p><a target="_blank" rel="noopener" href="https://computingforgeeks.com/docker-vs-cri-o-vs-containerd/">Docker vs CRI-O vs Containerd</a></p>
<p><a target="_blank" rel="noopener" href="https://www.infoq.cn/article/2017/02/Docker-Containerd-RunC">Docker、Containerd、RunC…：你应该知道的所有</a></p>
<p><a target="_blank" rel="noopener" href="https://gohalo.me/post/docker-component-runc-introduce.html">Docker RunC 简介</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/87602649">kubelet之cri演变史</a>——重要</p>
<p><a target="_blank" rel="noopener" href="https://xuxinkun.github.io/2017/12/12/docker-oci-runc-and-kubernetes/">docker、oci、runc以及kubernetes梳理</a></p>
<p><a href="chrome-extension://ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html?file=https%3A%2F%2Fevents19.linuxfoundation.org%2Fwp-content%2Fuploads%2F2017%2F11%2FHow-Container-Runtime-Matters-in-Kubernetes_-OSS-Kunal-Kushwaha.pdf">How Container Runtimes matter in Kubernetes?</a>——重要</p>
<p><a target="_blank" rel="noopener" href="https://www.ianlewis.org/en/container-runtimes-part-1-introduction-container-r">Container Runtimes Part 1: An Introduction to Container Runtimes</a>——重要</p>
<h1 id="3、CRI-O"><a href="#3、CRI-O" class="headerlink" title="3、CRI-O"></a>3、CRI-O</h1><h2 id="CRI-O是什么"><a href="#CRI-O是什么" class="headerlink" title="CRI-O是什么"></a>CRI-O是什么</h2><p>CRI-O 这个名字来源于CRI plus Open Container Initiative（OCI），因为CRI-O严格关注符合OCI的 runtime 和 container images。</p>
<p>CRI-O是kubernetescri（容器运行时接口）的一个实现，可以使用与OCI（opencontainer Initiative）兼容的运行时。它是使用Docker作为kubernetes运行时的轻量级替代方案。它允许Kubernetes使用任何符合OCI的运行时作为运行pod的容器运行时。今天，它支持runc和Kata容器作为容器运行时，但是任何符合OCI的运行时原则上都可以插入。</p>
<p>今天，CRI-O支持runc和Clear Container runtimes。它可以从任何容器仓库中提取镜像，并使用容器网络接口（<a target="_blank" rel="noopener" href="https://github.com/containernetworking/cni">CNI</a>）处理网络，这样任何与CNI兼容的网络插件都可能与此项目一起工作。</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>当Kubernetes需要运行一个容器时，它与CRI-O对话，CRI-O守护进程与runc（或其他符合OCI的运行时）一起启动容器。当Kubernetes需要停止容器时，CRI-O处理这个问题。没有什么特别的，它只是在幕后管理Linux容器，这样用户就不必担心容器编排的这一关键部分。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230649022.png" alt="image-20210114230649022"></p>
<p>让我们看下更细致的架构：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230656903.png" alt="image-20210114230656903"></p>
<p>架构中的组件如下：</p>
<ul>
<li>Kubernetes 联系 kubelet 启动一个 pod.<ul>
<li>Pods是一个kubernetes概念，由一个或多个容器组成，这些容器共享相同的IPC、NET和PID名称空间，并位于同一个cgroup中.</li>
</ul>
</li>
<li>kubelet 转发请求给 CRI-O daemon 通过 kubernetes CRI (Container runtime interface) 以启动一个新 POD.</li>
<li>CRI-O 使用 <code>containers/image</code> library 从镜像仓库拉取镜像.</li>
<li>下载好的镜像被解压到 container’s root filesystems, 存储到 COW file systems, 使用 containers/storage library 操作。</li>
<li>在为容器创建rootfs之后，CRI-O生成一个OCI运行时规范json文件，描述如何使用OCI Generate工具运行容器</li>
<li>然后，CRI-O使用该json规范启动一个与OCI兼容的运行时来运行容器进程。默认的OCI运行时是runc.</li>
<li>每个容器都由一个单独的<code>conmon</code>进程监视。<code>conmon</code>进程持有容器进程的PID1的pty。它处理容器的日志记录并记录容器进程的退出代码.</li>
<li>pod的网络是通过使用<a target="_blank" rel="noopener" href="https://github.com/containernetworking/cni">CNI</a>设置的，因此任何CNI插件都可以与CRI-O一起使用.</li>
</ul>
<h2 id="CRI-O-不是什么"><a href="#CRI-O-不是什么" class="headerlink" title="CRI-O 不是什么"></a>CRI-O 不是什么</h2><p>CRI-O的范围是与Kubernetes合作，管理和运行OCI容器。它并不是一个面向开发人员的工具，尽管该项目确实有一些面向用户的工具用于故障排除。</p>
<p>例如，构建镜像超出了CRI-O的范围，这就留给了Docker的build命令、<a target="_blank" rel="noopener" href="https://github.com/projectatomic/buildah">Buildah</a>或<a target="_blank" rel="noopener" href="https://github.com/openshift/source-to-image">OpenShift的Source-to-Image</a>（S2I）之类的工具了。</p>
<p>虽然CRI-O确实包含命令行接口（CLI），但它主要用于测试CRI-O，而不是作为在生产环境中管理容器的方法</p>
<h2 id="本节参考文档-1"><a href="#本节参考文档-1" class="headerlink" title="本节参考文档"></a>本节参考文档</h2><p><a target="_blank" rel="noopener" href="https://www.redhat.com/en/blog/introducing-cri-o-10">Introducing CRI-O 1.0</a></p>
<p><a target="_blank" rel="noopener" href="https://cri-o.io/">https://cri-o.io/</a></p>
<h1 id="从容器化到编排"><a href="#从容器化到编排" class="headerlink" title="从容器化到编排"></a>从容器化到编排</h1><p>本文翻译于<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/journey-from-containerization-to-orchestration-and-beyond/#runtime-shims">A journey from containerization to orchestration and beyond</a></p>
<p>容器催生了更高级的服务器端架构和复杂的部署技术。容器现在是如此广泛，以至于已经有一堆标准的类似规范（<a target="_blank" rel="noopener" href="https://github.com/opencontainers/runtime-spec">1</a>，<a target="_blank" rel="noopener" href="https://github.com/opencontainers/image-spec">2</a>，<a target="_blank" rel="noopener" href="https://kubernetes.io/blog/2016/12/container-runtime-interface-cri-in-kubernetes/">3</a>，<a target="_blank" rel="noopener" href="https://github.com/containernetworking/cni">4</a>，…）来描述容器的不同方面。当然，最底层的是Linux原语，比如<em>namespaces</em>和<em>cgroup</em>。但是容器化软件已经非常庞大，如果没有它自己的关注点分离层，几乎不可能实现它。在这项持续的努力中，我试图实现的目标是引导自己从最底层开始到最高层，尽可能多地练习（代码、安装、配置、集成等），当然，也要尽可能的有趣。这个页面的内容会随着时间的推移而变化，反映出我对这个主题的理解。</p>
<h2 id="Container-Runtimes"><a href="#Container-Runtimes" class="headerlink" title="Container Runtimes"></a>Container Runtimes</h2><p>我想从最底层的非内核原语——<strong>container runtime</strong>开始这段旅程。在容器中，runtime这个词有点不明确。每个项目、公司或社区对“container runtime”这一术语有自己的、通常是上下文相关的理解。大多数情况下，运行时的特点是由一组职责定义，从最基本的（创建命名空间、启动init进程）到全面的容器管理（包括（但不限于）镜像操作）。<a target="_blank" rel="noopener" href="https://www.ianlewis.org/en/container-runtimes-part-1-introduction-container-r">本文</a>对运行时有一个很好的概述。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230711783.png" alt="image-20210114230711783"></p>
<p>本节专门介绍<em>low-level container runtimes</em>。一群大玩家组成了一个开放容器计划（<a target="_blank" rel="noopener" href="https://www.opencontainers.org/">OCI</a>），在<a target="_blank" rel="noopener" href="https://github.com/opencontainers/runtime-spec">OCI运行时规范</a>中对底层运行时进行了标准化。简单地说：低级容器运行时是一种软件，它将包含rootfs的文件夹和描述容器参数（如资源限制、装入点、要启动的进程等）的配置[文件]作为输入，结果运行时启动一个孤立的进程，即容器。</p>
<p>截至2019年，使用最广泛的容器运行时是<a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc">runc</a>。这个项目开始时是Docker的一部分（因此它是用Go编写的），但最终被提取并转换为一个自给自足的CLI工具。runc基本上是OCI运行时规范的参考实现。在我们的旅程中，我们将大量使用runc，这里是一篇<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/implementing-container-runtime-shim/">介绍性文章</a>。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230719380.png" alt="image-20210114230719380"></p>
<p>另一个值得注意的OCI运行时实现是<a target="_blank" rel="noopener" href="https://github.com/containers/crun">crun</a>。它是用C语言编写的，既可以作为可执行文件，也可以用作库。它是由redhat发起的，其他像buildah或podman这样的redhat项目倾向于使用crun而不是runc。</p>
<h2 id="Container-management"><a href="#Container-management" class="headerlink" title="Container management"></a>Container management</h2><p>在命令行中使用runc，我们可以启动任意多个容器。但是如果我们需要自动化这个过程呢？假设我们需要启动数十个容器来跟踪它们的状态。其中一些需要在失败时重新启动，资源需要在终止时释放，镜像必须从仓库中提取，容器间网络需要配置等等。这已经是一个稍微高层次一点的工作了，这是一个<em>container manager</em>的责任。老实说，我不知道这个词是否常用，但我发现用这种方式来组织东西很方便。我将以下项目归类为<em>container managers</em>：<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/journey-from-containerization-to-orchestration-and-beyond/#containerd">containerd</a>、<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/journey-from-containerization-to-orchestration-and-beyond/#cri-o">cri-o</a>、<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/journey-from-containerization-to-orchestration-and-beyond/#dockerd">dockerd</a>和<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/journey-from-containerization-to-orchestration-and-beyond/#podman">podman</a>。</p>
<h4 id="containerd"><a href="#containerd" class="headerlink" title="containerd"></a>containerd</h4><p>与runc一样，我们在这里可以再次看到Docker的遗产——<a target="_blank" rel="noopener" href="https://github.com/containerd/containerd"><em>containerd</em></a>曾经是原始Docker项目的一部分。如今，<em>containerd</em>是另一个独立的软件。它称自己为container runtime，但显然，它与运行时runc不同。不仅<em>containerd</em>和<em>runc</em>的职责不同，而且组织形式也不同。 <em>runc</em>只是一个命令行工具，而containerd是一个长期存在的守护进程。 </p>
<p>Runc的实例不能超过基础容器进程的寿命。通常，它从<code>creat</code>调用开始其生命，然后仅在<code>start</code>时从容器的rootfs <code>exec</code> 指定文件。而 containerd 的寿命 超脱于 基础容器本身。containerd 在一台服务器上，侦听传入的请求以启动，停止或报告容器的状态。并在容器内部使用runc。但是，<em>containerd</em> 不仅仅是容器生命周期管理器。它还负责镜像管理（从仓库中拉取和推入镜像，在本地存储镜像等），跨容器网络管理和其他一些功能。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230727856.png" alt="image-20210114230727856"></p>
<h4 id="cri-o"><a href="#cri-o" class="headerlink" title="cri-o"></a>cri-o</h4><p>另一个 container manager 示例是cri-o。Docker重新架构化衍生了<em>containerd</em>，而cri-o则起源于Kubernetes领域。过去，Kubernetes（ab）使用Docker管理容器。但是，随着rkt的兴起，一些勇敢的人在Kubernetes中增加了对可互换容器运行时的支持，从而允许容器管理由Docker 和/或 rkt完成。但是，这种变化导致在Kubernetes中产生了大量的条件代码，没有人喜欢代码中过多的if。结果，Kubernetes引入了<a target="_blank" rel="noopener" href="https://kubernetes.io/blog/2016/12/container-runtime-interface-cri-in-kubernetes/">Container Runtime Interface (CRI)</a>），从而可以在不对Kubernetes端进行任何代码更改的情况下使用任何符合CRI的高级别的运行时（即容器管理器）。 cri-o是Red Hat对CRI兼容运行时的实现。与<em>containerd</em> 一样，<em>cri-o</em> 也是一个守护程序，该守护程序使用 endpoint 暴露 [gRPC] server，以创建，启动，停止（以及许多其他操作）容器。在幕后，cri-o可以使用任何OCI兼容的 [low-level]  运行时来处理容器，但是默认情况下是runc。 cri-o的主要重点是Kubernetes容器运行时。版本控制与k8s版本控制相同，项目范围是明确定义的，并且代码库预计会更小（截至2019年7月，它约为20 CLOC，比<em>containerd</em>的大约少5倍）</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230736191.png" alt="image-20210114230736191"></p>
<p>关于规范的好处是，满足兼容的插件都可以互换使用。一旦引入了CRI，便出现了一个用于<em>containerd</em>的插件，在 <em>containerd</em> 功能的基础上实现CRI gRPC server。这个想法碰巧是可行的，后来<em>containerd</em>本身获得了原生CRI支持。因此，Kubernetes可以同时使用<em>cri-o</em>和 <em>containerd</em>作为运行时。</p>
<h4 id="dockerd"><a href="#dockerd" class="headerlink" title="dockerd"></a>dockerd</h4><p>这里还有一个守护进程是<a target="_blank" rel="noopener" href="https://github.com/moby/moby/tree/master/cmd/dockerd">dockerd</a>。该守护进程是多方面的。一方面，它公开了用于Docker命令行客户端的API，该API为我们提供了所有这些著名的Docker工作流程（<code>docker pull</code>，<code>docker push</code>，<code>docker run</code>，<code>docker stats</code>等）。但是，由于我们已经知道，这一功能已提取到<em>containerd</em>中，所以dockerd在后台依赖<em>containerd</em>就不足为奇了。但这基本上意味着dockerd只是一个前端适配器，其负责将之前使用的 <em>docker engine</em> API  转换为 <em>containerd</em> API 。</p>
<p>但是，dockerd还提供了<code>compose</code> 和 swap，以解决容器编排问题，包括容器的多机器集群。从Kubernetes可以看出，这个问题很难解决。一个dockerd守护程序承担两个重大职责对我来说听起来并不好。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230743893.png" alt="image-20210114230743893"></p>
<h4 id="podman"><a href="#podman" class="headerlink" title="podman"></a>podman</h4><p>这是Red Hat的又一个项目，目的是提供一个名为<code>libpod</code>的库（不是守护程序）来管理镜像，容器生命周期和pod（容器组）。 <code>podman</code>是在此库之上构建的管理命令行工具。作为low-level容器运行时，该项目照常使用runc。从代码的角度来看，podman和cri-o（都是Red Hat项目）之间有很多共同点。例如，他们俩都在内部大量使用出色的<a target="_blank" rel="noopener" href="https://github.com/containers/storage"><em>storage</em></a>和<a target="_blank" rel="noopener" href="https://github.com/containers/image"><em>image</em></a>库。其正努力在cri-o中直接使用libpod而不是runc。 podman的另一个有趣功能是在日常工作流程中直接替换某些docker命令。该项目声称（当然在某种程度上）兼容 Docker CLI API。</p>
<p>当我们已经有了dockerd，container或cir-o时，为什么要启动这样的项目？守护程序作为容器管理器的问题在于，大多数时候必须使用root特权运行守护程序。由于守护程序是一个整体，即使在系统中没有root权限的情况下可以完成90％的守护程序功能，但剩下的10％仍要求以root用户身份启动守护程序。有了podman，最终就有可能利用Linux用户名称空间创建无根容器。这可能是一件大事，尤其是在广泛的CI或多租户环境中，因为即使非特权Docker容器实际上也离获得系统的根访问权限仅一个内核错误。</p>
<h2 id="Runtime-shims"><a href="#Runtime-shims" class="headerlink" title="Runtime shims"></a>Runtime shims</h2><p>容器可能会长时间运行，而由于崩溃，更新或其他一些不可预见的原因，可能需要重新启动容器管理器，而不会杀死（或失去控制）对受管容器。因此，容器的进程必须完全独立于管理者的进程，同时仍保留一些通信方式。如果您尝试自己实现它，您会发现使用runc作为容器运行时会很快变得复杂。以下列出了需要解决的困难</p>
<p><strong>在容器管理器重启时保持容器的stdio流打开</strong></p>
<p>无论管理器的状态如何，我们都需要在任何给定的时间将容器写入的数据转发到其STDOUT和STDERR进行日志记录。出乎意料的是，runc的设计使其成为一项不平凡的任务，因为runc倾向于通过调用者的stdio流传递到容器。因此，使runc进程独立于其父进程几乎是不可能的。如果我们以分离模式启动runc，然后不幸地终止了父进程，则尝试从STDIN读取或写入STDOUT / STDERR的尝试可能导致SIGPIPE杀死该容器。</p>
<p><strong>跟踪容器exit code</strong></p>
<p>OCI运行时规范将容器的启动分为两个步骤。首先，需要 <code>create</code> 容器（即完全初始化），然后再 <code>start</code> 容器。在容器创建步骤中，runc通过 fork 然后退出前台进程来完成容器进程守护。分离容器会导致缺少容器状态更新。解决此问题的一种方法是使启动runc的进程成为<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/dealing-with-processes-termination-in-Linux/#awaiting-a-grandchild-process-termination"><em>subreaper</em></a>。然后，我们可以教它等待容器的进程终止并将其退出代码报告到预定义的位置（例如，磁盘上的文件）。当然，subreaper 进程需要一直存在直到容器进程结束为止</p>
<p><strong>Synchronize container manager and runc container creation</strong></p>
<p>由于runc守护了容器创建进程，因此我们需要一个辅助通道（例如Unix套接字）将容器的实际启动（或失败）传达回容器管理器</p>
<p><strong>Attaching to a running container</strong></p>
<p>我们需要提供一种从容器中传入和传出一些数据的方法，包括PTY控制的方案。听起来我们需要一个侦听服务器来接受附加连接并执行往返于容器stdio的流传输。同样，该 server 必须是长期的。</p>
<p><code>container runtime shim</code>是一个轻量级守护进程，它启动runc并控制容器进程。shim 的进程与容器的进程紧密绑定，但与容器管理器的进程完全分离。容器和管理器之间的所有通信都是通过 shim 进行的</p>
<h2 id="Container-Network-Interface-CNI"><a href="#Container-Network-Interface-CNI" class="headerlink" title="Container Network Interface (CNI)"></a>Container Network Interface (CNI)</h2><p>由于我们有多个具有重叠职责的 container runtimes （或<em>managers</em>），因此很明显，我们需要将与网络相关的代码提取到一个专用项目中，然后再使用它，否则每个运行时都应该有自己的方式来配置NIC设备，路由，防火墙和其他网络方面。例如，cri-o和containerd都必须创建Linux网络名称空间，并设置Linux <code>bridges</code> 和veth设备才能为Kubernetes Pod创建沙箱。为了解决此问题，引入了<a target="_blank" rel="noopener" href="https://github.com/containernetworking/cni">the Container Network Interface</a>项目。</p>
<p>CNI项目提供了定义CNI插件的<a target="_blank" rel="noopener" href="https://github.com/containernetworking/cni/blob/master/SPEC.md">Container Network Interface Specification</a>。插件是一个可执行文件[sic]，应该由container runtimes （或<em>managers</em>）调用以建立（或释放）网络资源。插件可用于创建网络接口，管理IP地址分配或对系统进行一些自定义配置。 CNI项目与语言无关，并且由于将插件定义为可执行文件，因此可以在以任何编程语言实现的运行时管理系统中使用。但是，对于最流行的用例，CNI项目还提供了一组参考插件实现，作为独立的存储库（称为<a target="_blank" rel="noopener" href="https://github.com/containernetworking/plugins">插件</a>）提供。例如 <a target="_blank" rel="noopener" href="https://github.com/containernetworking/plugins/tree/master/plugins/main/bridge">bridge</a>, <a target="_blank" rel="noopener" href="https://github.com/containernetworking/plugins/tree/master/plugins/main/loopback">loopback</a>, <a target="_blank" rel="noopener" href="https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel">flannel</a>, etc.</p>
<p>一些第三方项目将其与网络相关的功能实现为CNI插件。在这里列举一些最著名的:<a target="_blank" rel="noopener" href="https://github.com/projectcalico/cni-plugin">Project Calico</a> and <a target="_blank" rel="noopener" href="https://github.com/weaveworks/weave">Weave</a>.</p>
<h2 id="Orchestration"><a href="#Orchestration" class="headerlink" title="Orchestration"></a>Orchestration</h2><p>容器的编排是一个非常大的主题。Kubernetis解决了现实中最大的问题。</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230753769.png" alt="image-20210114230753769"></p>
<h1 id="Implementing-Container-Runtime-Shim-runc"><a href="#Implementing-Container-Runtime-Shim-runc" class="headerlink" title="Implementing Container Runtime Shim: runc"></a>Implementing Container Runtime Shim: runc</h1><p>本文翻译于<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/implementing-container-runtime-shim/">Implementing Container Runtime Shim: runc</a></p>
<h2 id="What-is-a-shim"><a href="#What-is-a-shim" class="headerlink" title="What is a shim?"></a>What is a shim?</h2><p><a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/journey-from-containerization-to-orchestration-and-beyond/#runtime-shims">container runtime shim</a>是位于container manager（containerd、cri-o、podman）和container runtime（runc、crun）之间的一个软件，用于解决它们间的集成问题。</p>
<p>找到shim的最简单方法是在运行docker容器的Linux主机上检查进程树：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230801038.png" alt="image-20210114230801038"></p>
<p>一方面，运行时需要shim，以便能够在managers重启动时存活下来。另一方面，shim正在帮助container managers处理rumtime的古怪行为。作为<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/conman-the-container-manager-inception/">container managers实现系列</a>的一部分，我们将尝试创建自己的shim，然后将其与<a target="_blank" rel="noopener" href="https://github.com/iximiuz/conman">conman</a>（一个实验性的container manager）集成。希望在开发过程中，我们能对这个主题有一个深入的了解。</p>
<p>但是，在跳转到shim开发之前，我们需要熟悉所选择的容器运行时组件。<em>conman</em> 使用 <em>runc</em> 作为container runtime。因此，我将从介绍基本的runc用例和它的设计开始这篇文章。然后我将展示从代码中使用runc的简单方法，并解释一些相关的陷阱。本文的最后一部分将概述shim的设计。</p>
<h2 id="使用-runc"><a href="#使用-runc" class="headerlink" title="使用 runc"></a>使用 runc</h2><p>关于什么是容器运行时以及为什么需要容器运行时的详细解释超出了本文的范围。如果您缺乏这方面的知识，请首先<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/journey-from-containerization-to-orchestration-and-beyond/#container-runtimes">阅读本节</a>，然后查看<a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc">runc</a> README file，并尝试runc–help</p>
<p>简单地说，runc是一个用于运行容器化应用程序的命令行工具。如果这句话听起来太离奇了，那么可以把runc看作是一个工具，它可以在一个隔离的环境中生成一个新的普通Linux进程。这种隔离包括一个专用的根文件系统和一个新的进程树，它是通过Linux名称空间和cgroups来实现的。我们将这个新进程称为runc启动了一个<strong>container process</strong>。此进程成为新启动的容器中的第一个进程（即PID=1）。在本文的其余部分中，我们将频繁地提到这个进程。</p>
<p>尽管runc最常用于Docker（通过containerd）或cri-o守护进程（而这两个后台进程通常都位于kubelet后面），但它是一个独立的可执行文件，也就是说，runc绝不是一个库。现在让我们尝试在终端模拟器中使用这个工具：</p>
<blockquote>
<p>注意：runc支持运行由<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/linux-pty-what-powers-docker-attach-functionality/">Linux伪终端</a>控制的容器，但是今天我们将不使用这个功能，并将其留给另一篇文章来考虑</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Prepare some directories.</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir -p container1/rootfs</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> container1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Use docker to create a root filesystem <span class="keyword">for</span> our new container.</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo bash -c <span class="string">&#x27;docker export $(docker create busybox) | tar -C rootfs -xvf -&#x27;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Create a default bundle (i.e. container) config.</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> runc spec</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Change the default <span class="built_in">command</span> (sh) to</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sh -c <span class="string">&#x27;echo Hi, my PID is $$; sleep 10; echo Bye Bye&#x27;</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sed -i <span class="string">&#x27;s/&quot;sh&quot;/&quot;sh&quot;, &quot;-c&quot;, &quot;echo Hi, my PID is $$; sleep 10; echo Bye Bye&quot;/&#x27;</span> config.json</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Do not use pseudoterminal (PTY) to control the container process.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> PTY用例不在本文的讨论范围之内.</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sed -i <span class="string">&#x27;s/&quot;terminal&quot;: true/&quot;terminal&quot;: false/&#x27;</span> config.json</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Review the bundle config (optional).</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> less config.json</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Run the container with ID cont1.</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo runc run cont1</span></span><br></pre></td></tr></table></figure>
<p>如果我们在单独的终端会话中使用<code>ps axfo pid,ppid,command</code>检查相应的进程树，我们会看到类似的情况：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230808787.png" alt="image-20210114230808787"></p>
<p>进程层次结构似乎绝对正常。我们的登录bash会话（PID 9503）fork执行runc进程，它反过来 forked 自己（可能是由于<a target="_blank" rel="noopener" href="http://man7.org/linux/man-pages/man7/pid_namespaces.7.html">PID命名空间实现相关的原因</a>），第二个fork最终在容器化环境中启动sh shell（PID 22437）</p>
<p>现在，让我们来看看输出：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Hi, my PID is 1</span><br><span class="line">Bye Bye</span><br></pre></td></tr></table></figure>
<p>注意，即使从主机系统中我们看到sh进程的PID为22437，我们的小脚本打印出来的<code>Hi, my PID is 1</code>。这是它拥有自己的<code>process ID namespace</code>的完美证明。我们还应该关注这样一个事实：容器的stdout内容刚刚打印到我们的终端，这意味着我们登录的bash shell的<em>stdio streams</em>已经被<a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc/blob/201b06374548b64212f4ceb1529688d435e42899/docs/terminals.md#-pass-through">passed through</a> 到容器，然后被设置为它自己的<em>stdio streams</em>。这是我们需要记住的重要观察。我们可以尝试将进程结构表示如下</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230815470.png" alt="image-20210114230815470"></p>
<p>我们刚刚探讨的运行容器的方法在runc术语中称为<a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc/blob/201b06374548b64212f4ceb1529688d435e42899/docs/terminals.md#foreground"><strong>foreground</strong></a> 。这意味着runc进程始终处于容器进程和启动进程之间（在我们的示例中是bash shell）。runc支持另一种模式，称为<a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc/blob/201b06374548b64212f4ceb1529688d435e42899/docs/terminals.md#detached"><strong>detached</strong></a>。让我们试着使用它：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> from the container1 folder</span></span><br><span class="line">sudo runc run --detach cont1-detached</span><br></pre></td></tr></table></figure>
<p>请注意，runc是如何几乎立即将执行释放回登录shell的。如果我们检查对应的进程树，我们会看到下图：</p>
<p><img src="https://iximiuz.com/implementing-container-runtime-shim/runc-detached-ps-tree.png" alt="img"></p>
<p>似乎runc在生成容器进程之后完全退出了。容器进程被重新分配到主机的PID 1进程。launching process（我们的登录shell）和container process之间没有连接。。。除了passed-through 的 <em>stdio streams</em>！容器进程的输出再次打印到我们的终端，但这次容器产生的行与登录shell提示符交错出现</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo runc run --detach cont1-detached</span></span><br><span class="line">Hi, my PID is 1</span><br><span class="line"><span class="meta">$</span><span class="bash"> Bye Bye</span></span><br></pre></td></tr></table></figure>
<p>我们可以尝试将所涉及的进程及其标准流的相应结构描述如下：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230824948.png" alt="image-20210114230824948"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc/blob/201b06374548b64212f4ceb1529688d435e42899/docs/terminals.md#detached">runc文档</a>就是这样描述detached模式的：</p>
<blockquote>
<p>与 foreground/前台 模式不同，在 detached/分离 模式下，一旦容器启动，就没有长时间运行的前台runc进程。事实上，根本没有长时间运行的runc进程。但是，这意味着在runc为您设置stdio之后，由调用者来处理它。在shell中（即前台模式下），这意味着在容器设置好之后，runc命令将退出，control 将返回到shell</p>
</blockquote>
<blockquote>
<p>可以通过以下方法之一在分离模式下运行runc：</p>
</blockquote>
<blockquote>
<ul>
<li><code>runc run -d</code> … which operates similar to <code>runc run</code> but is detached.</li>
<li><code>runc create</code>后跟<code>runc start</code>，这是由OCI运行时规范定义的标准容器生命周期（<code>runc create</code>完全设置容器，等待<code>runc start</code>开始执行用户代码）</li>
</ul>
</blockquote>
<blockquote>
<p>detached模式的主要用例是针对希望包装 runc 的高级工具。通过在分离模式下运行runc，这些工具可以在不妨碍runc的情况下更好地控制容器的stdio（大多数围绕runc的包装器，如cri-o或containerd都使用分离模式）</p>
</blockquote>
<blockquote>
<p>不幸的是，与前台模式相比，使用分离模式要复杂一些，并且需要更多的关注——主要是因为现在由调用者来处理容器的stdio</p>
</blockquote>
<p>我们必须承认，前台模式有一些明显的缺点，分离模式的设计是为了消除它们。来自<a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc/blob/201b06374548b64212f4ceb1529688d435e42899/docs/terminals.md#foreground">同一个文档</a>：</p>
<blockquote>
<p>前台操作模式的主要缺点是它需要长时间运行的前台runc进程。如果您终止前台的runc进程，那么您将无法再访问容器的stdio（在大多数情况下，这将导致容器由于SIGPIPE或其他错误而异常死亡）。扩展来说，这意味着长时间运行的前台runc进程中的任何bug（例如内存泄漏）或错误的OOM-kill 清扫都可能导致容器被杀死，而与用户无关。此外，在前台模式下，无法像stdio（比如–preserve fds）那样直接将文件描述符传递给容器进程。</p>
</blockquote>
<h2 id="通过代码简单使用runc"><a href="#通过代码简单使用runc" class="headerlink" title="通过代码简单使用runc"></a>通过代码简单使用runc</h2><p>略，这里编写了 shell 和 Golang 代码以使用runc 创建容器，验证了 。结论如下：</p>
<p>这个练习表明，如果我们想保持对容器的stdio流的控制，那么<strong>container process</strong>不能独立于 <strong>launching process</strong>。而且我们知道，由于崩溃、更新或其他原因，容器管理器可以重新启动，这使得直接从容器管理器进程启动runc是不可能的。因此，我们需要一个helper进程与底层容器进程的生命周期一样长，并为其提供服务。由此，出现了<strong>container runtime shim</strong></p>
<h2 id="shim的作用"><a href="#shim的作用" class="headerlink" title="shim的作用"></a>shim的作用</h2><p><code>container runtime shim</code>是一个轻量级守护进程，它启动runc并控制容器进程。shim 的进程与容器的进程紧密绑定，但与容器管理器的进程完全分离。容器和管理器之间的所有通信都是通过 shim 进行的。<a target="_blank" rel="noopener" href="https://github.com/containers/conmon">conmon</a>和containerd <a target="_blank" rel="noopener" href="https://github.com/containerd/containerd/blob/master/runtime/v2/shim.go"><em>runtime shim</em></a>是一个例子。shim 通常负责以下（可能还有其他一些）事情：</p>
<ul>
<li>即使在 容器管理器 重新启动期间也提供容器的stdout和stderr流。这允许容器管理器在任何给定时刻将容器stdout和stderr转发到日志文件。这是<code>docker logs &lt;container&gt;</code>和<code>kubectl logs &lt;pod&gt; -c &lt;container&gt;</code>命令的功能。当要求容器管理器提供一些容器日志时，它可以直接从磁盘上的预定义位置读取它们。例如，<code>kubectl logs</code> 触发以下调用链：<code>kubectl &lt;-- network --&gt; Kubernetes Core API &lt;-- network --&gt; kubelet &lt;-- (CRI gRPC API) --&gt; CRI Runtime Service (cri-o, containerd, docker) &lt;-- read() --&gt; logs on node&#39;s disk</code>.</li>
<li>连接到正在运行的容器。容器管理器通常提供一些方法来将一些数据 流式地进出容器，包括PTY控制的场景。为此，容器的 shim 需要保证 容器的 stdin 被打开。shim可以建立一个接受连接的socket服务器，并在容器的stdio和连接的client 之间执行流式传输。这保证了 <code>kubectl run -i</code>、<code>podman run -i --tty</code>以及著名的PTY控制的交互式Docker用例（如：<code>docker run -it ubuntu:latest bash</code>）</li>
<li>跟踪 容器 exit code。在分离模式下，runc故意通过 fork 然后退出前台进程来对容器进程进行守护。然后容器进程被重新定义父进程，默认情况下是主机的<em>init</em>进程。分离容器会导致缺少容器状态更新。解决这个问题的一种方法是使 shim 成为一个“<a target="_blank" rel="noopener" href="https://iximiuz.com/en/posts/dealing-with-processes-termination-in-Linux/#awaiting-a-grandchild-process-termination"><em>subreaper</em></a>”。这样，容器进程 将被 reparented 到 shim 。然后，shim 可以等待容器的进程终止，并将其退出代码报告给预定义的目标（例如磁盘上的文件）。相应的容器管理器可以稍后提取它</li>
<li>将容器管理器与容器创建状态同步。由于runc守护 容器创建进程，我们需要一个侧通道（例如Unix套接字）将容器的实际启动（或失败）传回容器管理器。runc通过它的stderr报告容器创建错误。由于稍后完全相同的文件描述符可以成为容器进程的<em>stderr</em>，因此shim 需要小心地使用其中的所有数据，直到 runtime 进程终止，并立即将其报告给容器管理器。因此，如果我们在container命令中输入了一个错误，那么在容器创建阶段会向我们报告实际错误：<code>docker run -it ubuntu bahs docker: Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused &quot;exec: \&quot;bahs\&quot;: executable file not found in $PATH&quot;: unknown</code></li>
</ul>
<h2 id="shim-应用概览"><a href="#shim-应用概览" class="headerlink" title="shim 应用概览"></a>shim 应用概览</h2><p>我们已经知道 container runtime shim  必须是一个与容器进程紧密绑定的长活守护进程。其结构如下图所示：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114230836702.png" alt="image-20210114230836702"></p>
<p>shim的主进程是短暂的，它的作用是创建一个新的 shim守护进程。它 fork 实际的shim守护进程，将其PID写入磁盘并立即退出，使shim与 launching process 分离（即容器管理器）。长期存在的shim守护进程 首先 创建一个新会话并将其stdio流从父进程分离（通过将它们重定向到/dev/null）。对于任何类似守护进程的软件，这是一些常见的步骤。然后，它又 fork 了另一个进程，即容器进程 的前身。此 进程 执行带有提供的参数（bundle dir，config.json等）的runc create。 shim守护进程等待容器前身的终止，然后将此操作的状态报告回容器管理器。此时，我们只有一个shim守护程序进程和一个分离的容器进程。但是，shim 是容器进程 的 subreaper。最后，shim守护程序进程可以开始为容器的stdio流提供服务，并等待容器终止。知道容器终止状态后，shim 程序会将其写入磁盘上的预定义位置并退出。</p>
<blockquote>
<p>subreaper：A process can define itself as a subreaper with <code>prctl(PR_SET_CHILD_SUBREAPER)</code>。这样可以保证 容器进程的 父进程退出后（即runc ，上面也叫做 容器进程的前身） 被 shim 接管</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://heavyfish.github.io/2020/11/18/Go/The%20Go%20scheduler-v1.8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/heavyfish.github.io/images/avatar.gif">
      <meta itemprop="name" content="Shenxr">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="速查笔记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/heavyfish.github.io/2020/11/18/Go/The%20Go%20scheduler-v1.8/" class="post-title-link" itemprop="url">The Go scheduler-v1.8</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-18 11:29:33" itemprop="dateCreated datePublished" datetime="2020-11-18T11:29:33+08:00">2020-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-14 22:46:34" itemprop="dateModified" datetime="2021-01-14T22:46:34+08:00">2021-01-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/heavyfish.github.io/categories/Go/" itemprop="url" rel="index"><span itemprop="name">Go</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="1、Go-runtime的调度器"><a href="#1、Go-runtime的调度器" class="headerlink" title="1、Go runtime的调度器"></a>1、Go runtime的调度器</h1><p>在我们研究新的调度程序之前，我们需要了解为什么需要它。当操作系统可以为您安排线程时，为什么要创建用户空间调度程序？</p>
<p>POSIX线程API在很大程度上是对现有Unix进程模型的逻辑扩展，因此，线程可以获得与进程相同的控制。线程有自己的信号掩码，可以分配CPU affinity，可以放入cgroup中，并且可以查询它们使用的资源。所有这些特性都会增加一些控件的开销，而这些特性对于Go程序如何使用goroutine是不需要的，而且当程序中有100000个线程时，这些开销会很快增加。</p>
<p>另一个问题是操作系统无法根据Go模型做出明智的调度决策。例如，Go垃圾收集器要求在垃圾收集时停止所有线程，并且内存必须处于一致状态。这包括等待运行的线程到达一个我们知道内存是一致的时刻。</p>
<p>当您有许多线程在随机时刻调度时，很可能需要等待它们中的许多线程达到一致的状态。Go调度器可以决定只在它知道内存是一致的时刻上调度。这意味着，当我们等待进行垃圾收集时，我们只需要等待正在CPU核心上活动运行的线程。</p>
<h1 id="2、调度中的角色"><a href="#2、调度中的角色" class="headerlink" title="2、调度中的角色"></a>2、调度中的角色</h1><p>有三种常见的线程模型。一种是N:1，其中多个用户空间线程在一个操作系统线程上运行。这样做的优点是可以快速切换上下文，但不能利用多核系统。另一个是1:1，其中一个执行线程与一个操作系统线程匹配。它利用了机器上的所有核心，但是上下文切换很慢，因为它必须通过操作系统进行 trap 。</p>
<p>Go试图通过使用M:N调度器来获得两个世界的最佳效果。它将任意数量的goroutine调度到任意数量的OS线程上。您可以快速切换上下文并利用系统中的所有核心。这种方法的主要缺点是增加了调度器的复杂性。</p>
<p>为了完成调度任务，Go Scheduler使用3个主要实体：</p>
<p><img src="https://morsmachine.dk/our-cast.jpg" alt="img"></p>
<p>三角形代表一个操作系统线程。它是由操作系统管理的执行线程，其工作方式与标准POSIX线程非常相似。在运行时代码中，它被称为M代表machine。</p>
<p>圆代表一个 goroutine。它包括堆栈、指令指针和其他对调度goroutines很重要的信息，就像可能被阻塞的任何通道一样。在运行时代码中，它被称为G。</p>
<p>矩形表示用于调度的上下文。您可以将其视为在单个线程上运行Go代码的调度器的本地化版本。这是让我们从N:1调度器到M:N调度器的重要部分。在运行时代码中，它被称为P表示处理器。稍后再谈这个问题。</p>
<p><img src="https://morsmachine.dk/in-motion.jpg" alt="img"></p>
<p>这里我们看到2个线程（M），每个线程持有一个上下文（P），每个线程运行一个goroutine（G）。为了运行goroutines，线程必须包含上下文。</p>
<p>上下文数在启动时设置为GOMAXPROCS环境变量的值，或通过运行时函数GOMAXPROCS（）设置。通常情况下，在程序执行过程中不会发生变化。上下文的数量是固定的，这意味着在任何时候都只有gomaxproc在运行Go代码。我们可以使用它来调整对单个计算机的Go进程的调用，比如在一台4核的PC上运行4个线程的Go代码。</p>
<p>灰色的goroutine没有运行，但已经准备好进行调度。它们被排列在名为runqueues的列表中。每当goroutine执行go语句时，goroutine就会添加到运行队列的末尾。一旦上下文运行goroutine到一个调度点时，它就会从它的运行队列中弹出一个goroutine，设置堆栈和指令指针，并开始运行goroutine。</p>
<p>为了减少互斥争用，每个上下文都有自己的本地运行队列。以前版本的Go调度程序只有一个全局运行队列，并有一个互斥体来保护它。线程在等待互斥体解锁时常常被阻塞。当你有32个核心的机器，你想要尽可能多的压缩性能时，情况变得非常糟糕。</p>
<p>只要所有上下文都有goroutine要运行，调度器就会在这个稳定状态下继续调度。然而，有几个场景可以改变这一点。</p>
<h1 id="3、syscall-调用"><a href="#3、syscall-调用" class="headerlink" title="3、syscall 调用"></a>3、syscall 调用</h1><p>你现在可能会想，为什么会有上下文呢？我们不能把运行队列放在线程上，去掉上下文吗？我们有上下文的原因是，如果正在运行的线程由于某种原因需要阻塞，我们可以将它们交给其他线程。</p>
<p>我们需要阻塞的一个例子是调用syscall时。由于一个线程不能同时 执行代码 和 在syscall上被阻塞，所以我们需要传递上下文以便它可以继续调度。</p>
<p><img src="https://morsmachine.dk/syscall.jpg" alt="img"></p>
<p>这里我们看到一个线程放弃了它的上下文，以便另一个线程可以运行它。调度程序确保有足够的线程来运行所有上下文。上图中的M1可能只是为了处理这个系统调用而创建的，也可能来自线程缓存。syscalling线程将保留发出syscall的goroutine，因为它在技术上仍然在执行，尽管在操作系统中被阻塞了。</p>
<p>当系统调用返回时，线程必须尝试获取上下文才能运行返回的goroutine。正常的操作模式是从其他线程中窃取上下文。如果它不能窃取一个，它将把goroutine放到一个全局运行队列中，把自己放到线程缓存中，然后进入休眠状态。</p>
<p>全局运行队列是上下文在其本地运行队列用完时从中提取的运行队列。上下文还定期检查全局运行队列中的goroutines。否则，全局运行队列上的goroutine可能会因为饥饿而停止运行。</p>
<p>这种对系统调用的处理就是Go程序运行多个线程的原因，即使GOMAXPROCS是1。运行时使用goroutine来调用syscalls，将线程留在后面。</p>
<h1 id="4、均衡工作"><a href="#4、均衡工作" class="headerlink" title="4、均衡工作"></a>4、均衡工作</h1><p>另一种改变系统稳定状态的方法是当上下文执行完要调度的goroutines时。如果上下文的运行队列上的工作量不平衡，就会发生这种情况。这可能导致上下文在系统中仍有工作要做时耗尽其运行队列。为了继续运行Go代码，上下文可以将goroutine从全局运行队列中取出，但是如果其中没有goroutine，它就必须从其他地方获取它们。</p>
<p><img src="https://morsmachine.dk/steal.jpg" alt="img"></p>
<p>这是另一种情况。当一个上下文用完时，它将尝试从另一个上下文中窃取大约一半的运行队列。这可以确保在每个上下文上总是有工作要做，这反过来又确保所有线程都以其最大容量工作。</p>
<h1 id="5、扩展研究"><a href="#5、扩展研究" class="headerlink" title="5、扩展研究"></a>5、扩展研究</h1><p>调度程序还有很多细节，比如cgo线程、LockOSThread（）函数以及与网络轮询器的集成。这些都不在这篇文章的范围之内，但仍然值得研究。我可能以后再写。在Go运行库中可以找到很多有趣的构造。</p>
<p>原文链接：</p>
<p><a target="_blank" rel="noopener" href="https://morsmachine.dk/go-scheduler">The Go Scheduler</a></p>
<p>扩展资料：</p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/20862617">Golang 的 goroutine 是如何实现的？-知乎</a></p>
<p><a target="_blank" rel="noopener" href="https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html">Scheduling In Go</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://heavyfish.github.io/2020/11/16/Go/%E4%BB%80%E4%B9%88%E6%98%AF%E5%8F%8D%E5%B0%84-%E5%AE%98%E6%96%B9%E7%BF%BB%E8%AF%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/heavyfish.github.io/images/avatar.gif">
      <meta itemprop="name" content="Shenxr">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="速查笔记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/heavyfish.github.io/2020/11/16/Go/%E4%BB%80%E4%B9%88%E6%98%AF%E5%8F%8D%E5%B0%84-%E5%AE%98%E6%96%B9%E7%BF%BB%E8%AF%91/" class="post-title-link" itemprop="url">什么是反射-官网翻译</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-16 21:13:35" itemprop="dateCreated datePublished" datetime="2020-11-16T21:13:35+08:00">2020-11-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-14 22:50:43" itemprop="dateModified" datetime="2021-01-14T22:50:43+08:00">2021-01-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/heavyfish.github.io/categories/Go/" itemprop="url" rel="index"><span itemprop="name">Go</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Types-and-interfaces"><a href="#Types-and-interfaces" class="headerlink" title="Types and interfaces"></a>Types and interfaces</h1><p>反射用于检查自身的结构，属于元程序编程。每个语言的反射机制都是不同的，有的语言没有反射。<strong>go语言的反射机制建立在类型系统之上</strong></p>
<p>Go是静态类型的。每个变量都有一个静态类型，也就是在编译时已知并固定的一种类型：int，float32，*MyType，[] byte等。如果我们声明</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> MyInt <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> i <span class="keyword">int</span></span><br><span class="line"><span class="keyword">var</span> j MyInt</span><br></pre></td></tr></table></figure>
<p>那么i 的类型为int，j 的类型为MyInt。变量i和j具有不同的静态类型，尽管它们具有相同的基础类型，但是如果不进行转换就无法将它们彼此调用。</p>
<p>type 的一个重要类别是接口类型，它表示固定的方法集。接口变量可以存储任何具体的（非接口）值，只要该值实现接口的方法即可。一对著名的示例是io.Reader和io.Writer，它们是io包中的Reader和Writer类型</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Reader is the interface that wraps the basic Read method.</span></span><br><span class="line"><span class="keyword">type</span> Reader <span class="keyword">interface</span> &#123;</span><br><span class="line">    Read(p []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Writer is the interface that wraps the basic Write method.</span></span><br><span class="line"><span class="keyword">type</span> Writer <span class="keyword">interface</span> &#123;</span><br><span class="line">    Write(p []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>任何使用此签名实现Read（或Write）方法的类型都称为io.Reader（或io.Writer）。在此讨论中，这意味着io.Reader类型的变量可以保存 其类型具有Read方法的任何值：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> r io.Reader</span><br><span class="line">r = os.Stdin</span><br><span class="line">r = bufio.NewReader(r)</span><br><span class="line">r = <span class="built_in">new</span>(bytes.Buffer)</span><br><span class="line"><span class="comment">// and so on</span></span><br></pre></td></tr></table></figure>
<p>重要的是要清楚，无论r可能包含什么具体值，r的类型始终是io.Reader：Go是静态类型的，而r的静态类型是io.Reader。</p>
<p>接口类型的一个非常重要的例子是空接口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">interface&#123;&#125;</span><br></pre></td></tr></table></figure>
<p>它表示空方法集，并且由任何值完全满足，因为任何值具有零个或多个方法。</p>
<p>有人说Go的接口是动态类型的，这是不对的。Go接口是静态类型的：接口类型的变量始终具有相同的静态类型，即使在运行时存储在接口变量中的值可能会更改类型，该值也将始终满足接口的要求。</p>
<p>我们需要对所有这些事情都保持精确，因为反射和接口密切相关。</p>
<h1 id="接口的表示"><a href="#接口的表示" class="headerlink" title="接口的表示"></a>接口的表示</h1><p>Russ Cox写了一篇详细的<a target="_blank" rel="noopener" href="https://research.swtch.com/2009/12/go-data-structures-interfaces.html">博客文章</a>，内容涉及Go中接口值的表示。这里没有必要重复完整的故事，但有一些必要的概要。</p>
<p>接口类型的变量存储一对：分配给该变量的具体值以及该值的类型描述符。更准确地说，该值是实现接口的基础具体数据项，而类型则描述该项的完整类型。例如：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> r io.Reader</span><br><span class="line">tty, err := os.OpenFile(<span class="string">&quot;/dev/tty&quot;</span>, os.O_RDWR, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line">r = tty</span><br></pre></td></tr></table></figure>
<p>r  包含（value, type）对，（tty，* os.File）。注意，* os.File类型实现了Read以外的方法；即使接口值仅提供对Read方法的访问，值内部也包含有关该值的所有类型信息。这就是为什么我们可以做这样的事情：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> w io.Writer</span><br><span class="line">w = r.(io.Writer)</span><br></pre></td></tr></table></figure>
<p>此处的表达式是类型断言；它断言的是r中的类型也实现了io.Writer，因此我们可以将其分配给w。分配后，w将包含（tty，* os.File）对。这与在r中持有的对相同。接口的静态类型确定可以使用接口变量调用哪些方法，即使内部的具体值可能具有更大的方法集。</p>
<p>继续，我们可以这样做：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> empty <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">empty = w</span><br></pre></td></tr></table></figure>
<p>并且我们的空接口值empty将再次包含同一对（tty，* os.File）。这很方便：一个空接口可以保存任何值，并包含我们可能需要的有关该值的所有信息。</p>
<p>（我们在这里不需要类型断言，因为静态地知道w可以满足空接口。在将值从Reader移到Writer的示例中，我们需要显式并使用类型断言，因为Writer的方法是而不是Reader的子集。）</p>
<p>一个重要的细节是，<strong>接口内的对始终具有形式（值，具体类型）</strong>，而不能具有形式（值，接口类型）。接口不保存接口值。</p>
<h1 id="反射第一定律：反射从接口值到反射对象"><a href="#反射第一定律：反射从接口值到反射对象" class="headerlink" title="反射第一定律：反射从接口值到反射对象"></a>反射第一定律：反射从接口值到反射对象</h1><p>在底层级别上，<strong>反射只是一种检查存储在接口变量中的 类型和值对 的机制</strong>。首先，我们需要在 <a target="_blank" rel="noopener" href="https://golang.org/pkg/reflect/">package reflect</a>: 中了解两种类型：<a target="_blank" rel="noopener" href="https://golang.org/pkg/reflect/#Type">Type</a> and <a target="_blank" rel="noopener" href="https://golang.org/pkg/reflect/#Value">Value</a>。这两种类型允许访问接口变量的内容，还有两个简单的函数，称为<code>reflect.TypeOf</code>和<code>reflect.ValueOf</code>，从接口值中获取<code>reflect.Type</code>和<code>reflect.Value</code>部分。 （此外，从<code>reflect.Value</code>可以很容易地到达<code>reflect.Type</code>，但是现在让Value和Type概念保持分离。）</p>
<p>让我们从TypeOf开始：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;reflect&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> x <span class="keyword">float64</span> = <span class="number">3.4</span></span><br><span class="line">    fmt.Println(<span class="string">&quot;type:&quot;</span>, reflect.TypeOf(x))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该程序打印</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span>: <span class="keyword">float64</span></span><br></pre></td></tr></table></figure>
<p>您可能想知道为什么接口在这里，因为该程序看起来像在传递float64变量x，而不是接口值给<code>reflect.TypeOf</code>。但是在查看 <a target="_blank" rel="noopener" href="https://golang.org/pkg/reflect/#TypeOf">godoc report</a> 时，reflect.TypeOf的签名包括一个空接口：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TypeOf returns the reflection Type of the value in the interface&#123;&#125;.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TypeOf</span><span class="params">(i <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">Type</span></span></span><br></pre></td></tr></table></figure>
<p>当我们调用<code>reflect.TypeOf（x）</code>时，x首先存储在一个空接口中，然后将其作为参数传递； <code>Reflection.TypeOf</code>解压缩该空接口以恢复类型信息</p>
<p>当然，<code>reflect.ValueOf</code>函数可以恢复值（从这里开始，我们将跳过样板并只关注可执行代码）：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> x <span class="keyword">float64</span> = <span class="number">3.4</span></span><br><span class="line">fmt.Println(<span class="string">&quot;value:&quot;</span>, reflect.ValueOf(x).String())</span><br></pre></td></tr></table></figure>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 打印</span></span><br><span class="line">value: &lt;<span class="keyword">float64</span> Value&gt;</span><br></pre></td></tr></table></figure>
<p>（我们明确地调用String方法，因为默认情况下，fmt包会挖掘到一个<code>reflect.Value</code>以显示其中的具体值。而String方法则不会。）</p>
<p><code>reflect.Type</code>和<code>reflect.Value</code>都有很多方法可以让我们检查和操作它们。一个重要的例子是<code>Value</code>具有<code>Type</code>方法，该方法返回<code>reflect.Value</code>的Type。另一个是Type和Value都具有<code>Kind</code>方法，该方法返回一个常量，指示存储的项目类型：Uint，Float64，Slice等。同样，使用诸如Int和Float之类的Value方法，还可以获取存储在其中的值（如int64和float64）:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> x <span class="keyword">float64</span> = <span class="number">3.4</span></span><br><span class="line">v := reflect.ValueOf(x)</span><br><span class="line">fmt.Println(<span class="string">&quot;type:&quot;</span>, v.Type())</span><br><span class="line">fmt.Println(<span class="string">&quot;kind is float64:&quot;</span>, v.Kind() == reflect.Float64)</span><br><span class="line">fmt.Println(<span class="string">&quot;value:&quot;</span>, v.Float())</span><br></pre></td></tr></table></figure>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 打印</span></span><br><span class="line"><span class="keyword">type</span>: <span class="keyword">float64</span></span><br><span class="line">kind is <span class="keyword">float64</span>: <span class="literal">true</span></span><br><span class="line">value: <span class="number">3.4</span></span><br></pre></td></tr></table></figure>
<p>还有诸如SetInt和SetFloat之类的方法，但要使用它们，我们需要了解settability，这是第三反射定律的主题，下面将进行讨论。</p>
<p>反射库具有几个值得一提的属性。首先，为使API保持简单，Value的“ getter”和“ setter”方法在可以保存该值的最大类型上运行：例如，所有有符号整数的int64。也就是说，Value的Int方法返回一个int64，而SetInt值设置一个int64；可能需要转换为涉及的实际类型：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> x <span class="keyword">uint8</span> = <span class="string">&#x27;x&#x27;</span></span><br><span class="line">v := reflect.ValueOf(x)</span><br><span class="line">fmt.Println(<span class="string">&quot;type:&quot;</span>, v.Type())                            <span class="comment">// uint8.</span></span><br><span class="line">fmt.Println(<span class="string">&quot;kind is uint8: &quot;</span>, v.Kind() == reflect.Uint8) <span class="comment">// true.</span></span><br><span class="line">x = <span class="keyword">uint8</span>(v.Uint())                                       <span class="comment">// v.Uint returns a uint64.</span></span><br></pre></td></tr></table></figure>
<p>第二个属性是<strong>反射对象的<code>kind</code>描述基础类型，而不是静态类型</strong>。如果反射对象包含用户定义的整数类型的值，例如：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> MyInt <span class="keyword">int</span></span><br><span class="line"><span class="keyword">var</span> x MyInt = <span class="number">7</span></span><br><span class="line">v := reflect.ValueOf(x)</span><br></pre></td></tr></table></figure>
<p>v的kind仍然是reflect.Int，即使x的静态类型是MyInt 不是int。换句话说，即使Type可以，Kind也不能将MyInt 和 Int 区别开。</p>
<h1 id="反射第二定律：反射从反射对象到接口值"><a href="#反射第二定律：反射从反射对象到接口值" class="headerlink" title="反射第二定律：反射从反射对象到接口值"></a>反射第二定律：反射从反射对象到接口值</h1><p>像物理反射一样，Go中的反射会生成自己的逆反射。</p>
<p>给定一个reflect.Value，我们可以使用Interface方法恢复接口值；实际上，该方法将类型和值信息打包回接口表示形式并返回结果：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Interface returns v&#x27;s value as an interface&#123;&#125;.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v Value)</span> <span class="title">Interface</span><span class="params">()</span> <span class="title">interface</span></span>&#123;&#125;</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y := v.Interface().(<span class="keyword">float64</span>) <span class="comment">// y will have type float64.</span></span><br><span class="line">fmt.Println(y)</span><br></pre></td></tr></table></figure>
<p>打印反射对象v表示的float64值。</p>
<p>不过，我们可以做得更好。 fmt.Println，fmt.Printf等的参数都作为空接口值传递，然后像在前面的示例中一样，在内部由fmt包解压缩。因此，正确打印reflect.Value的内容所要做的就是将Interface方法的结果传递给格式化的打印例程：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fmt.Println(v.Interface())</span><br></pre></td></tr></table></figure>
<p>（为什么不使用fmt.Println（v）？因为v是reflect.Value；我们想要它包含的具体值。）由于我们的值是float64，因此如果需要，我们甚至可以使用浮点格式：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fmt.Printf(<span class="string">&quot;value is %7.1e\n&quot;</span>, v.Interface())</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印为</span></span><br><span class="line"><span class="number">3.4e+00</span></span><br></pre></td></tr></table></figure>
<p>同样，无需将v.Interface（）的结果类型声明为float64;。空接口值内部具有具体值的类型信息，Printf将对其进行恢复。</p>
<p>简而言之，Interface方法与ValueOf函数相反，但其结果始终是静态类型interface {}。</p>
<p>重申：反射从接口值到反射对象，然后再返回。</p>
<h1 id="反射第三定律：要修改反射对象，value-必须可settable"><a href="#反射第三定律：要修改反射对象，value-必须可settable" class="headerlink" title="反射第三定律：要修改反射对象，value 必须可settable"></a>反射第三定律：要修改反射对象，value 必须可settable</h1><p>这是一些无效的代码，但值得研究。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> x <span class="keyword">float64</span> = <span class="number">3.4</span></span><br><span class="line">v := reflect.ValueOf(x)</span><br><span class="line">v.SetFloat(<span class="number">7.1</span>) <span class="comment">// Error: will panic.</span></span><br></pre></td></tr></table></figure>
<p>如果运行此代码，它将：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">panic</span>: reflect.Value.SetFloat using unaddressable value</span><br></pre></td></tr></table></figure>
<p>问题不在于值7.1不可寻址。是因为 v 是不可设置的。可设置性是反射值的属性，并非所有反射值都具有它。</p>
<p>值的CanSet方法报告值的可设置性：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> x <span class="keyword">float64</span> = <span class="number">3.4</span></span><br><span class="line">v := reflect.ValueOf(x)</span><br><span class="line">fmt.Println(<span class="string">&quot;settability of v:&quot;</span>, v.CanSet())</span><br></pre></td></tr></table></figure>
<p>打印</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">settability of v: <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>在不可设置的值上调用Set方法是错误的。但是什么是可设置性？</p>
<p>可设置性有点像可寻址性，但是更严格。它是反射对象可以修改创建反射对象时的实际存储的属性。可设置性由反射对象是否保留原始条目确定。当我们说</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> x <span class="keyword">float64</span> = <span class="number">3.4</span></span><br><span class="line">v := reflect.ValueOf(x)</span><br></pre></td></tr></table></figure>
<p>我们将x的副本传递给reflect.ValueOf，因此，作为reflect.ValueOf的参数创建的接口值是x的副本，而不是x本身。因此，如果声明</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v.SetFloat(<span class="number">7.1</span>)</span><br></pre></td></tr></table></figure>
<p>被允许成功，即使v看起来是从x创建的，它也不会更新x。相反，它将更新存储在反射值内的x的副本，并且x本身将不受影响。这将造成混乱和无用，因此是非法的，可设置性是避免此问题的属性。</p>
<p>考虑将x传递给函数：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f(x)</span><br></pre></td></tr></table></figure>
<p>我们不希望f能够修改x，因为我们传递了x值的副本，而不是x本身。如果要让f直接修改x，则必须将x的地址（即指向x的指针）传递给函数：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f(&amp;x)</span><br></pre></td></tr></table></figure>
<p>这是直接且熟悉的，并且反射的工作方式相同。<strong>如果要通过反射修改x，则必须为反射库提供指向要修改的值的指针</strong>。</p>
<p>来做吧：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> x <span class="keyword">float64</span> = <span class="number">3.4</span></span><br><span class="line">p := reflect.ValueOf(&amp;x) <span class="comment">// Note: take the address of x.</span></span><br><span class="line">fmt.Println(<span class="string">&quot;type of p:&quot;</span>, p.Type())</span><br><span class="line">fmt.Println(<span class="string">&quot;settability of p:&quot;</span>, p.CanSet())</span><br></pre></td></tr></table></figure>
<p>到目前为止的输出是:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> of p: *<span class="keyword">float64</span></span><br><span class="line">settability of p: <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>反射对象p是不可设置的，但我们不是要设置的p，实际上是*p。为了得到p所指向的内容，我们称为Value的<code>Elem</code>方法，该方法通过指针进行间接操作，并将结果保存在名为v的反射Value中：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">v := p.Elem()</span><br><span class="line">fmt.Println(<span class="string">&quot;settability of v:&quot;</span>, v.CanSet())</span><br></pre></td></tr></table></figure>
<p>现在v是一个可设置的反射对象，如输出所示，</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">settability of v: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>由于它代表x，我们最终可以使用v.SetFloat修改x的值：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">v.SetFloat(<span class="number">7.1</span>)</span><br><span class="line">fmt.Println(v.Interface())</span><br><span class="line">fmt.Println(x)</span><br></pre></td></tr></table></figure>
<p>预期的输出是:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">7.1</span></span><br><span class="line"><span class="number">7.1</span></span><br></pre></td></tr></table></figure>
<p>反射可能很难理解，但是它确实在做语言的工作，尽管通过反射可以掩盖正在发生的事情的类型和值。请记住，<strong>反射值需要某些内容的地址才能修改其表示的内容</strong>。</p>
<h1 id="Struct"><a href="#Struct" class="headerlink" title="Struct"></a>Struct</h1><p>在我们前面的示例中，v本身并不是指针，它只是从一个指针派生的。发生这种情况的常见方式是使用反射来修改结构的字段。只要有了结构的地址，就可以修改其字段。</p>
<p>这是一个分析结构值t的简单示例。我们使用结构的地址创建反射对象，因为稍后将要对其进行修改。然后，将typeOfT 设置为其类型，并使用简单的方法调用对字段进行迭代（有关详细信息，请参见<a target="_blank" rel="noopener" href="https://golang.org/pkg/reflect/">包反射</a>）。请注意，我们从结构类型中提取了字段的名称，但是字段本身是常规的reflect.Value对象。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> T <span class="keyword">struct</span> &#123;</span><br><span class="line">    A <span class="keyword">int</span></span><br><span class="line">    B <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line">t := T&#123;<span class="number">23</span>, <span class="string">&quot;skidoo&quot;</span>&#125;</span><br><span class="line">s := reflect.ValueOf(&amp;t).Elem()</span><br><span class="line">typeOfT := s.Type()</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; s.NumField(); i++ &#123;</span><br><span class="line">    f := s.Field(i)</span><br><span class="line">    fmt.Printf(<span class="string">&quot;%d: %s %s = %v\n&quot;</span>, i,</span><br><span class="line">        typeOfT.Field(i).Name, f.Type(), f.Interface())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该程序的输出是：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: A <span class="keyword">int</span> = <span class="number">23</span></span><br><span class="line"><span class="number">1</span>: B <span class="keyword">string</span> = skidoo</span><br></pre></td></tr></table></figure>
<p>在此处传递的内容还涉及可设置性的另一点：T的字段名是大写的（已导出），因为仅可导出结构的导出字段是可设置的。</p>
<p>因为s包含可设置的反射对象，所以我们可以修改结构的字段。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s.Field(<span class="number">0</span>).SetInt(<span class="number">77</span>)</span><br><span class="line">s.Field(<span class="number">1</span>).SetString(<span class="string">&quot;Sunset Strip&quot;</span>)</span><br><span class="line">fmt.Println(<span class="string">&quot;t is now&quot;</span>, t)</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t is now &#123;<span class="number">77</span> Sunset Strip&#125;</span><br></pre></td></tr></table></figure>
<p>如果我们修改程序，以便从t而不是＆t创建s，则对SetInt和SetString的调用将失败，因为t的字段不可设置。</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>这里重复一下反射定律：</p>
<ul>
<li>反射从接口值到反射对象。</li>
<li>反射从反射对象到接口值。</li>
<li>要修改反射对象，该值必须可设置</li>
</ul>
<p>一旦理解了这些定律，尽管Go中的反射仍然很细微，但它变得更易于使用。这是一个功能强大的工具，除非绝对必要，否则应谨慎使用并避免使用。</p>
<p>我们还没有涉及到更多的反射-在channel上发送和接收，分配内存，使用切片和映射，调用方法和函数-但是这篇文章足够长。我们将在以后的文章中介绍其中一些主题。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://heavyfish.github.io/2020/11/15/Go/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/heavyfish.github.io/images/avatar.gif">
      <meta itemprop="name" content="Shenxr">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="速查笔记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/heavyfish.github.io/2020/11/15/Go/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">Go语言学习笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-15 17:08:57" itemprop="dateCreated datePublished" datetime="2020-11-15T17:08:57+08:00">2020-11-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-12 23:21:25" itemprop="dateModified" datetime="2021-01-12T23:21:25+08:00">2021-01-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/heavyfish.github.io/categories/Golang/" itemprop="url" rel="index"><span itemprop="name">Golang</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="1、编译原理"><a href="#1、编译原理" class="headerlink" title="1、编译原理"></a>1、编译原理</h1><p>Go 语言的应用程序在运行之前需要先编译成二进制，在编译的过程中会经过中间代码生成阶段，Go 语言编译器的中间代码具有静态单赋值（Static Single Assignment、SSA）的特性。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 我们可以使用如下所示的命令将 Go 语言的源代码编译成汇编语言，然后通过汇编语言分析程序具体的执行过程</span></span><br><span class="line">go build -gcflags -S helloworld.go</span><br></pre></td></tr></table></figure>
<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201115171004657.png" alt="image-20201115171004657" style="zoom:50%;" />

<p>然而上述的汇编代码只是 Go 语言编译的结果，如果想要了解 Go 语言更详细的编译过程，我们可以通过SSA去了解。</p>
<h2 id="1-1、预备知识"><a href="#1-1、预备知识" class="headerlink" title="1.1、预备知识"></a>1.1、预备知识</h2><h3 id="1-1-1、抽象语法树"><a href="#1-1-1、抽象语法树" class="headerlink" title="1.1.1、抽象语法树"></a>1.1.1、抽象语法树</h3><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">抽象语法树</a>（AST），是源代码语法的结构的一种抽象表示，它用树状的方式表示编程语言的语法结构<a target="_blank" rel="noopener" href="https://draveness.me/golang/docs/part1-prerequisite/ch02-compile/golang-compile-intro/#fn:1">1</a>。抽象语法树中的每一个节点都表示源代码中的一个元素，每一棵子树都表示一个语法元素，例如一个 if else 语句，我们可以从 <code>2 * 3 + 7</code> 这一表达式中解析出下图所示的抽象语法树。</p>
<img src="https://img.draveness.me/2019-12-20-15768548776645-abstract-syntax-tree.png" alt="abstract-syntax-tree" style="zoom:50%;" />

<p><strong>抽象语法树抹去了源代码中不重要的一些字符</strong> - 空格、分号或者括号等等。<strong>编译器在执行完语法分析之后会输出一个抽象语法树</strong>，这个抽象语法树会<strong>辅助编译器进行语义分析</strong>，我们可以<strong>用它来确定语法正确的程序是否存在一些类型不匹配或不一致</strong>的问题</p>
<h3 id="1-1-2、静态单赋值"><a href="#1-1-2、静态单赋值" class="headerlink" title="1.1.2、静态单赋值"></a>1.1.2、静态单赋值</h3><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Static_single_assignment_form">静态单赋值</a>（Static Single Assignment, SSA）是中间代码的一个特性，如果一个中间代码具有静态单赋值的特性，那么每个变量就只会被赋值一次<a target="_blank" rel="noopener" href="https://draveness.me/golang/docs/part1-prerequisite/ch02-compile/golang-compile-intro/#fn:2">2</a>。在实践中我们通常会用添加下标的方式实现每个变量只能被赋值一次的特性，这里以下面的代码举个例子：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x := <span class="number">1</span></span><br><span class="line">x := <span class="number">2</span></span><br><span class="line">y := x</span><br></pre></td></tr></table></figure>
<p>根据分析，我们其实能够发现上述的代码其实并不需要第一个将 <code>1</code> 赋值给 <code>x</code> 的表达式，也就是 <code>x := 1</code> 这一表达式在上述的代码片段中是没有作用的。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x1 := <span class="number">1</span></span><br><span class="line">x2 := <span class="number">2</span></span><br><span class="line">y1 := x2</span><br></pre></td></tr></table></figure>
<p>当我们使用具有 SSA 特性的中间代码时，就可以非常清晰地发现变量 <code>y1</code> 的值和 <code>x1</code> 是完全没有任何关系的，所以在机器码生成时其实就可以省略第一步，这样就能减少需要执行的指令来优化这一段代码。</p>
<h3 id="1-1-3、指令集"><a href="#1-1-3、指令集" class="headerlink" title="1.1.3、指令集"></a>1.1.3、指令集</h3><p>x86 是目前比较常见的指令集，除了 x86 之外，还有很多其他的指令集，不同的处理器使用了不同的架构和机器语言，所以很多编程语言为了在不同的机器上运行需要将源代码根据架构翻译成不同的机器代码。</p>
<p>复杂指令集计算机（CISC）和精简指令集计算机（RISC）是目前的两种 CPU 区别，它们在设计理念上会有一些不同，从名字我们就能看出来这两种不同的设计有什么区别：</p>
<ul>
<li>复杂指令集通过增加指令的数量减少需要执行的指令数；</li>
<li>精简指令集能使用更少的指令完成目标的计算任务；</li>
</ul>
<h2 id="1-2、编译原理"><a href="#1-2、编译原理" class="headerlink" title="1.2、编译原理"></a>1.2、编译原理</h2><img src="https://img.draveness.me/2019-12-20-15768548776662-complication-process.png" alt="complication-process" style="zoom:50%;" />

<p>图中依次是：词法分析 -》语法分析 -》 语义分析 -》 中间码(IR)生成-》 代码组织-》机器码生成</p>
<p>Go 的编译器在逻辑上可以被分成四个阶段：</p>
<ol>
<li>词法与语法分析</li>
<li>类型检查和 AST 转换（对应语义分析）</li>
<li>通用 SSA 生成</li>
<li>最后的机器代码生成</li>
</ol>
<h3 id="1-2-1、词法与语法分析"><a href="#1-2-1、词法与语法分析" class="headerlink" title="1.2.1、词法与语法分析"></a>1.2.1、词法与语法分析</h3><p>词法分析的作用就是解析源代码文件，它将文件中的字符串序列转换成 Token 序列。语法分析的输入就是词法分析器输出的 Token 序列，这些序列会按照顺序被语法分析器进行解析，转换成有意义的结构体，也就是语法树。</p>
<p>语法解析的结果就是上面介绍过的抽象语法树（AST），每一个 AST 都对应着一个单独的 Go 语言文件，这个抽象语法树中包括当前文件属于的包名、定义的常量、结构体和函数等。</p>
<h3 id="1-2-2、类型检查"><a href="#1-2-2、类型检查" class="headerlink" title="1.2.2、类型检查"></a>1.2.2、类型检查</h3><p>当拿到一组文件的抽象语法树之后，Go 语言的编译器会对语法树中定义和使用的类型进行检查，类型检查分别会按照以下的顺序对不同类型的节点进行验证和处理：</p>
<ol>
<li>常量、类型和函数名及类型；</li>
<li>变量的赋值和初始化；</li>
<li>函数和闭包的主体；</li>
<li>哈希键值对的类型；</li>
<li>导入函数体；</li>
<li>外部的声明；</li>
</ol>
<h3 id="1-2-3、中间代码生成"><a href="#1-2-3、中间代码生成" class="headerlink" title="1.2.3、中间代码生成"></a>1.2.3、中间代码生成</h3><p>在类型检查之后，就会通过一个名为 <code>compileFunctions</code> 的函数开始对整个 Go 语言项目中的全部函数进行编译，这些函数会在一个编译队列中等待几个后端工作协程的消费，这些并发执行的 Goroutine 会将所有函数对应的抽象语法树转换成中间代码。</p>
<img src="https://img.draveness.me/2019-12-20-15768548776685-concurrency-compiling.png" alt="concurrency-compiling" style="zoom:50%;" />

<h3 id="1-2-4、机器码生成"><a href="#1-2-4、机器码生成" class="headerlink" title="1.2.4、机器码生成"></a>1.2.4、机器码生成</h3><p>Go 语言源代码的 <a target="_blank" rel="noopener" href="https://github.com/golang/go/tree/master/src/cmd/compile/internal"><code>src/cmd/compile/internal</code></a> 目录中包含了很多机器码生成相关的包，不同类型的 CPU 分别使用了不同的包生成机器码，其中包括 amd64、arm、arm64、mips、mips64、ppc64、s390x、x86 和 wasm</p>
<h1 id="2、程序结构"><a href="#2、程序结构" class="headerlink" title="2、程序结构"></a>2、程序结构</h1><h2 id="2-1、命名"><a href="#2-1、命名" class="headerlink" title="2.1、命名"></a>2.1、命名</h2><p>Go语言中的所有的命名，都遵循一个简单的命名规则：<strong>一个名字必须以一个字母（Unicode字母）或下划线开头</strong>，后面可以跟任意数量的字母、数字或下划线。<strong>大写字母和小写字母是不同的</strong>：heapSort和Heapsort是两个不同的名字。</p>
<p>Go语言中类似if和switch的关键字有25个；关键字不能用于自定义名字，只能在特定语法结构中使用。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">break      default       func     interface   select</span><br><span class="line">case       defer         go       map         struct</span><br><span class="line">chan       else          goto     package     switch</span><br><span class="line">const      fallthrough   if       range       type</span><br><span class="line">continue   for           import   return      var</span><br></pre></td></tr></table></figure>
<p>此外，还有大约30多个预定义的名字，比如int和true等，主要对应内建的常量、类型和函数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">内建常量: true false iota nil</span><br><span class="line"></span><br><span class="line">内建类型: int int8 int16 int32 int64</span><br><span class="line">          uint uint8 uint16 uint32 uint64 uintptr</span><br><span class="line">          float32 float64 complex128 complex64</span><br><span class="line">          bool byte rune string error</span><br><span class="line"></span><br><span class="line">内建函数: make len cap new append copy close delete</span><br><span class="line">          complex real imag</span><br><span class="line">          panic recover</span><br></pre></td></tr></table></figure>
<p>这些内部预先定义的名字并不是关键字，你可以在定义中重新使用它们。在一些特殊的场景中重新定义它们也是有意义的，但是也要注意避免过度而引起语义混乱。</p>
<p>如果一个名字是在函数内部定义，那么它就只在函数内部有效。如果是在函数外部定义，那么将在当前包的所有文件中都可以访问。名字的开头字母的大小写决定了名字在包外的可见性。<strong>如果一个名字是大写字母开头的</strong>（译注：必须是在函数外部定义的包级名字；包级函数名本身也是包级名字），<strong>那么它将是导出的，也就是说可以被外部的包访问</strong></p>
<h2 id="2-2、变量声明"><a href="#2-2、变量声明" class="headerlink" title="2.2、变量声明"></a>2.2、变量声明</h2><p><strong>var声明变量 与 简短变量声明</strong></p>
<p>var声明语句可以创建一个特定类型的变量，然后给变量附加一个名字，并且设置变量的初始值。简短变量声明，直接使用“名字 := 表达式”</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// var 变量名字 类型 = 表达式</span></span><br><span class="line"><span class="comment">// 名字 := 表达式</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> i <span class="keyword">int8</span> = <span class="number">255</span></span><br><span class="line"><span class="keyword">var</span> f <span class="keyword">float32</span> = <span class="number">16777216</span></span><br><span class="line"><span class="keyword">var</span> x <span class="keyword">complex128</span> = <span class="built_in">complex</span>(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">s := <span class="string">&quot;hello, world&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 数组声明</span></span><br><span class="line"><span class="keyword">var</span> q [<span class="number">3</span>]<span class="keyword">int</span> = [<span class="number">3</span>]<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">q := [...]<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">q := [<span class="number">3</span>]<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 切片声明</span></span><br><span class="line"><span class="keyword">var</span> s []<span class="keyword">int</span> = q[<span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line">s := q[<span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line"><span class="keyword">var</span> s []<span class="keyword">int</span>  <span class="comment">// 这是一个 nil值 切片，等同于 s := []int(nil)</span></span><br><span class="line">s := []<span class="keyword">int</span>&#123;&#125; <span class="comment">// 注意 &#123;&#125;，这是一个空值切片，它的指针和nil值切片不同 ，等同于 s1 := make([]int,0,0)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// map 声明</span></span><br><span class="line">ages := <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span>&#123;</span><br><span class="line">    <span class="string">&quot;alice&quot;</span>:   <span class="number">31</span>,</span><br><span class="line">    <span class="string">&quot;charlie&quot;</span>: <span class="number">34</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ages := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span>)</span><br><span class="line">ages[<span class="string">&quot;alice&quot;</span>] = <span class="number">31</span></span><br><span class="line">ages[<span class="string">&quot;charlie&quot;</span>] = <span class="number">34</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> m <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">bool</span>   <span class="comment">// nil 值map</span></span><br><span class="line">s := <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">bool</span>&#123;&#125;  <span class="comment">// &#123;&#125; 初始化了 map</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// strcut 声明</span></span><br><span class="line"><span class="keyword">type</span> Employee <span class="keyword">struct</span> &#123;</span><br><span class="line">    ID        <span class="keyword">int</span></span><br><span class="line">    Name      <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> S <span class="keyword">struct</span>&#123;&#125;    <span class="comment">// </span></span><br><span class="line"><span class="keyword">type</span> S <span class="keyword">struct</span>&#123;&#125;&#123;&#125;  <span class="comment">// 初始化了 struct</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>各类型没有表达式时的，默认零值。（如 <code>var i int</code>）</p>
<ul>
<li>数值类型变量对应的零值是0</li>
<li>布尔类型变量对应的零值是false</li>
<li>字符串类型对应的零值是空字符串，即 “”</li>
<li>接口或引用类型（包括slice、指针、map、chan和函数）变量对应的零值是nil</li>
<li>数组或结构体等聚合类型对应的零值是每个元素或字段对应该类型的零值</li>
</ul>
<p><strong>常量声明</strong></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 单常量声明</span></span><br><span class="line"><span class="keyword">const</span> pi = <span class="number">3.14159</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">// 批量声明</span></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">    a = <span class="number">1</span></span><br><span class="line">    b     <span class="comment">// 省略初始化表达式则表示使用前面常量的初始化表达式写法，此处代表 b = 1 </span></span><br><span class="line">    c = <span class="number">2</span></span><br><span class="line">    d     <span class="comment">// 代表 d = 2</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// iota 常量生成器，iota 将从0递增</span></span><br><span class="line"><span class="keyword">type</span> Weekday <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">    Sunday Weekday = <span class="literal">iota</span>   <span class="comment">// 代表 Sunday = 1</span></span><br><span class="line">    Monday                  <span class="comment">// 代表 Monday = 2 ，依次类推</span></span><br><span class="line">    Tuesday</span><br><span class="line">    Wednesday</span><br><span class="line">    Thursday</span><br><span class="line">    Friday</span><br><span class="line">    Saturday</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="2-3、赋值"><a href="#2-3、赋值" class="headerlink" title="2.3、赋值"></a>2.3、赋值</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 普通赋值</span></span><br><span class="line">x = <span class="number">1</span>                       <span class="comment">// 命名变量的赋值</span></span><br><span class="line">*p = <span class="literal">true</span>                   <span class="comment">// 通过指针间接赋值，这里的p是指针</span></span><br><span class="line">person.name = <span class="string">&quot;bob&quot;</span>         <span class="comment">// 结构体字段赋值</span></span><br><span class="line">count[x] = count[x] * scale <span class="comment">// 数组、slice或map的元素赋值</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 交换赋值</span></span><br><span class="line"><span class="comment">// 赋值之前，赋值语句右边的所有表达式将会先进行求值，然后再统一更新左边对应变量的值</span></span><br><span class="line">x, y = y, x</span><br><span class="line">a[i], a[j] = a[j], a[i]</span><br><span class="line">i, j, k = <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 接受表达式的多个返回值</span></span><br><span class="line">v, ok = m[key]             <span class="comment">// map lookup</span></span><br><span class="line">v, ok = x.(T)              <span class="comment">// type assertion</span></span><br><span class="line">v, ok = &lt;-ch               <span class="comment">// channel receive</span></span><br></pre></td></tr></table></figure>


<h2 id="2-4、类型"><a href="#2-4、类型" class="headerlink" title="2.4、类型"></a>2.4、类型</h2><p>变量或表达式的类型定义了对应存储值的属性特征，例如数值在内存的存储大小（或者是元素的bit个数），它们在内部是如何表达的，是否支持一些操作符，以及它们自己关联的方法集等。</p>
<p><strong>在任何程序中都会存在一些变量有着相同的内部结构，但是却表示完全不同的概念</strong>。例如，一个int类型的变量可以用来表示一个循环的迭代索引、或者一个时间戳、或者一个文件描述符、或者一个月份；一个float64类型的变量可以用来表示每秒移动几米的速度、或者是不同温度单位下的温度；一个字符串可以用来表示一个密码或者一个颜色的名称。</p>
<p><strong>一个类型声明语句创建了一个新的类型名称，和现有类型具有相同的底层结构</strong>。<strong>但新命名的类型即使底层类型相同也是不兼容的。</strong></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> 类型名字 底层类型</span><br></pre></td></tr></table></figure>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 下面是两种类型，虽然它们底层类型相同，它们的值不能直接进行比较</span></span><br><span class="line"><span class="keyword">type</span> Celsius <span class="keyword">float64</span>    <span class="comment">// 摄氏温度</span></span><br><span class="line"><span class="keyword">type</span> Fahrenheit <span class="keyword">float64</span> <span class="comment">// 华氏温度</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> f1 Celsius = <span class="number">10.0</span></span><br><span class="line"><span class="keyword">var</span> f2 Fahrenheit = <span class="number">10.0</span></span><br><span class="line">c == Celsius(f)      <span class="comment">// 类型转换不会改变值本身，但是会使它们的语义发生变化，因此可比较</span></span><br></pre></td></tr></table></figure>


<h1 id="2、数据结构"><a href="#2、数据结构" class="headerlink" title="2、数据结构"></a>2、数据结构</h1><h2 id="2-1、数组"><a href="#2-1、数组" class="headerlink" title="2.1、数组"></a>2.1、数组</h2><p><strong>数组是由相同类型元素的集合组成的数据结构</strong>，计算机会为数组分配一块连续的内存来保存其中的元素。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始化数组</span></span><br><span class="line">arr1 := [<span class="number">3</span>]<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">arr2 := [...]<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure>
<p>如果数组中元素的个数小于或者等于 4 个，那么所有的变量会直接在栈上初始化，如果数组元素大于 4 个，变量就会在静态存储区初始化然后拷贝到栈上，这些转换后的代码才会继续进入<a target="_blank" rel="noopener" href="https://draveness.me/golang/docs/part1-prerequisite/ch02-compile/golang-ir-ssa/">中间代码生成</a>和<a target="_blank" rel="noopener" href="https://draveness.me/golang/docs/part1-prerequisite/ch02-compile/golang-machinecode/">机器码生成</a>两个阶段，最后生成可以执行的二进制文件。</p>
<h2 id="2-2、切片"><a href="#2-2、切片" class="headerlink" title="2.2、切片"></a>2.2、切片</h2><h3 id="2-2-1、数据结构"><a href="#2-2-1、数据结构" class="headerlink" title="2.2.1、数据结构"></a>2.2.1、数据结构</h3><p>切片就是动态数组，它的长度并不固定，我们可以随意向切片中追加元素，而切片会在容量不足时自动扩容。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[]<span class="keyword">int</span></span><br><span class="line">[]<span class="keyword">interface</span>&#123;&#125;</span><br></pre></td></tr></table></figure>
<p>编译期间的切片是 <code>Slice</code> 类型的，但是在运行时切片由如下的 <code>SliceHeader</code> 结构体表示，其中 <code>Data</code> 字段是指向数组的指针，<code>Len</code> 表示当前切片的长度，而 <code>Cap</code> 表示当前切片的容量，也就是 <code>Data</code> 数组的大小：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> SliceHeader <span class="keyword">struct</span> &#123;</span><br><span class="line">	Data <span class="keyword">uintptr</span></span><br><span class="line">	Len  <span class="keyword">int</span></span><br><span class="line">	Cap  <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>Data</code> 作为一个指针指向的数组是一片连续的内存空间，这片内存空间可以用于存储切片中保存的全部元素，数组中的元素只是逻辑上的概念，底层存储其实都是连续的，所以我们可以将切片理解成一片连续的内存空间加上长度与容量的标识。</p>
<img src="https://img.draveness.me/2019-02-20-golang-slice-struct.png" alt="golang-slice-struct" style="zoom:50%;" />

<p>切片与数组的关系非常密切，切片引入了一个抽象层，提供了对数组中部分片段的引用，作为数组的引用，我们可以在运行区间可以修改它的长度，如果底层的数组长度不足就会触发扩容机制，切片中的数组就会发生变化</p>
<h3 id="2-2-2、初始化"><a href="#2-2-2、初始化" class="headerlink" title="2.2.2、初始化"></a>2.2.2、初始化</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通过下标的方式获得数组或者切片的一部分</span></span><br><span class="line">arr[<span class="number">0</span>:<span class="number">3</span>] or slice[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用字面量初始化新的切片</span></span><br><span class="line">slice := []<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用关键字 make 创建切片</span></span><br><span class="line">slice := <span class="built_in">make</span>([]<span class="keyword">int</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>使用下标初始化切片不会造成原始数组或者切片中数据的拷贝，它只会创建一个指向原始数组的切片值，所以修改新切片的数据也会修改原始切片。</p>
<h3 id="2-2-3、追加和扩容"><a href="#2-2-3、追加和扩容" class="headerlink" title="2.2.3、追加和扩容"></a>2.2.3、追加和扩容</h3><p>在 Go 语言中我们会使用 <code>append</code> 关键字向切片追加元素，根据返回值是否会覆盖原变量，会分别进入两种流程。</p>
<ul>
<li><p>如果 <code>append</code> 返回的『新切片』不需要赋值回原有的变量：</p>
<p>我们会先对切片结构体进行解构获取它的数组指针、大小和容量，如果在追加元素后切片的大小大于容量，那么就会调用 <a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/440f7d64048cd94cba669e16fe92137ce6b84073/src/runtime/slice.go#L76-L191"><code>runtime.growslice</code></a> 对切片进行扩容并将新的元素依次加入切片</p>
</li>
<li><p>如果 <code>append</code> 后的切片会覆盖原切片，即 <code>slice = append(slice, 1, 2, 3)</code>：</p>
<p>和是否覆盖原变量的逻辑其实差不多，最大的区别在于最后的结果是不是赋值回原有的变量</p>
</li>
</ul>
<img src="https://img.draveness.me/2020-03-12-15839729948451-golang-slice-append.png" alt="golang-slice-append" style="zoom:50%;" />

<p>当切片的容量不足时就会调用 <a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/440f7d64048cd94cba669e16fe92137ce6b84073/src/runtime/slice.go#L76"><code>runtime.growslice</code></a> 函数为切片扩容，扩容就是为切片分配一块新的内存空间并将原切片的元素全部拷贝过去：</p>
<p>在分配内存空间之前需要先确定新的切片容量，Go 语言根据切片的当前容量选择不同的策略进行扩容：</p>
<ol>
<li>如果期望容量大于当前容量的两倍就会使用期望容量；</li>
<li>如果当前切片的长度小于 1024 就会将容量翻倍；</li>
<li>如果当前切片的长度大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量；</li>
</ol>
<p>这里只是确定切片的大致容量，接下来还需要根据切片中元素的大小对它们进行对齐</p>
<h3 id="2-3-4、拷贝切片"><a href="#2-3-4、拷贝切片" class="headerlink" title="2.3.4、拷贝切片"></a>2.3.4、拷贝切片</h3><p>当我们使用 <code>copy(a, b)</code> 的形式对切片进行拷贝时，不论<code>copy</code> 是否是在运行时调用的，都会通过 <code>memmove</code> 将整块内存中的内容拷贝到目标的内存区域中：</p>
<img src="https://img.draveness.me/2019-02-20-golang-slice-copy.png" alt="golang-slice-copy" style="zoom:50%;" />

<h2 id="2-3、哈希表"><a href="#2-3、哈希表" class="headerlink" title="2.3、哈希表"></a>2.3、哈希表</h2><p>哈希表是除了数组之外，最常见的数据结构，几乎所有的语言都会有数组和哈希表这两种集合元素，<strong>有的语言将数组实现成列表，有的语言将哈希表称作结构体或者字典</strong>，但是它们是两种设计集合元素的思路，<strong>数组用于表示元素的序列，而哈希表示的是键值对之间映射关系，只是不同语言的叫法和实现稍微有些不同</strong></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 字面量定义</span></span><br><span class="line">hash := <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span>&#123;</span><br><span class="line">	<span class="string">&quot;1&quot;</span>: <span class="number">2</span>,</span><br><span class="line">	<span class="string">&quot;3&quot;</span>: <span class="number">4</span>,</span><br><span class="line">	<span class="string">&quot;5&quot;</span>: <span class="number">6</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-4、字符串"><a href="#2-4、字符串" class="headerlink" title="2.4、字符串"></a>2.4、字符串</h2><p>字符串虽然在 Go 语言中是基本类型 <code>string</code>，但是它实际上是由字符组成的数组，是一片连续的内存空间。</p>
<p>Go 语言中的字符串其实是一个只读的字节数组：</p>
<img src="https://img.draveness.me/2019-12-31-15777265631608-in-memory-string.png" alt="in-memory-string" style="zoom:50%;" />

<p>只读只意味着字符串会分配到只读的内存空间并且这块内存不会被修改，但是在运行时我们其实还是可以将这段内存拷贝到堆或者栈上，将变量的类型转换成 <code>[]byte</code> 之后就可以进行，修改后通过类型转换就可以变回 <code>string</code>，Go 语言只是不支持直接修改 <code>string</code> 类型变量的内存空间。</p>
<h3 id="2-4-1、数据结构"><a href="#2-4-1、数据结构" class="headerlink" title="2.4.1、数据结构"></a>2.4.1、数据结构</h3><p>每一个字符串在运行时都会使用如下的 <code>StringHeader</code> 结构体表示：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> StringHeader <span class="keyword">struct</span> &#123;</span><br><span class="line">	Data <span class="keyword">uintptr</span></span><br><span class="line">	Len  <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>与切片的结构体相比，字符串少了一个表示容量的 <code>Cap</code> 字段，因为字符串作为只读的类型，我们并不会直接向字符串直接追加元素改变其本身的内存空间，所有在字符串上执行的写入操作实际都是通过拷贝实现的。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 声明字符串，双引号 与 反引号</span></span><br><span class="line">str1 := <span class="string">&quot;this is a string&quot;</span></span><br><span class="line">str2 := <span class="string">`this is another </span></span><br><span class="line"><span class="string">string`</span></span><br></pre></td></tr></table></figure>
<h3 id="2-4-2、拼接"><a href="#2-4-2、拼接" class="headerlink" title="2.4.2、拼接"></a>2.4.2、拼接</h3><p>Go 语言拼接字符串会使用 <code>+</code> 符号，在正常情况下，运行时会调用 <code>copy</code> 将输入的多个字符串拷贝到目标字符串所在的内存空间中，新的字符串是一片新的内存空间，与原来的字符串也没有任何关联，一旦需要拼接的字符串非常大，拷贝带来的性能损失就是无法忽略的。</p>
<img src="https://img.draveness.me/2019-12-31-15777265631620-string-concat-and-copy.png" alt="string-concat-and-copy" style="zoom:50%;" />

<h1 id="3、语言基础"><a href="#3、语言基础" class="headerlink" title="3、语言基础"></a>3、语言基础</h1><h2 id="3-1、函数调用"><a href="#3-1、函数调用" class="headerlink" title="3.1、函数调用"></a>3.1、函数调用</h2><p>我们先来介绍一下传值和传引用两者的区别：</p>
<ul>
<li>传值：函数调用时会对参数进行拷贝，被调用方和调用方两者持有不相关的两份数据；</li>
<li>传引用：函数调用时会传递参数的指针，被调用方和调用方两者持有相同的数据，任意一方做出的修改都会影响另一方。</li>
</ul>
<p>不同语言会选择不同的方式传递参数，Go 语言选择了传值的方式，<strong>无论是传递基本类型、结构体还是指针，都会对传递的参数进行拷贝</strong>。</p>
<p>将指针作为参数传入某一个函数时，在函数内部会对指针进行复制，也就是会同时出现两个指针指向原有的内存空间，所以 Go 语言中『传指针』也是传值。</p>
<p>Go 通过栈传递函数的参数和返回值，在调用函数之前会在栈上为返回值分配合适的内存空间，随后将入参从右到左按顺序压栈并拷贝参数，返回值会被存储到调用方预留好的栈空间上，我们可以简单总结出以下几条规则：</p>
<ol>
<li>通过堆栈传递参数，入栈的顺序是从右到左，而参数的计算是从左到右；</li>
<li>函数返回值通过堆栈传递并由调用者预先分配内存空间；</li>
<li>调用函数时都是传值，接收方会对入参进行复制再计算；</li>
</ol>
<h2 id="3-2、接口"><a href="#3-2、接口" class="headerlink" title="3.2、接口"></a>3.2、接口</h2><p>接口的本质就是引入一个新的中间层，调用方可以通过接口与具体实现分离，解除上下游的耦合，上层的模块不再需要依赖下层的具体模块，只需要依赖一个约定好的接口。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义了 error 接口</span></span><br><span class="line"><span class="keyword">type</span> error <span class="keyword">interface</span> &#123;</span><br><span class="line">	Error() <span class="keyword">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201116171037227.png" alt="image-20201116171037227" style="zoom:50%;" />

<h3 id="3-2-1、reciver-中的-普通类型-和-指针类型"><a href="#3-2-1、reciver-中的-普通类型-和-指针类型" class="headerlink" title="3.2.1、reciver 中的 普通类型 和 指针类型"></a>3.2.1、reciver 中的 普通类型 和 指针类型</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如下，绑定到 struct 的方法，可以接受 原始变量 做reciver，也可接受 指针 做revicer </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Cat <span class="keyword">struct</span> &#123;&#125;</span><br><span class="line"><span class="keyword">type</span> Duck <span class="keyword">interface</span> &#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c  Cat)</span> <span class="title">Quack</span></span> &#123;&#125;  <span class="comment">// 使用结构体实现接口</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cat)</span> <span class="title">Quack</span></span> &#123;&#125;  <span class="comment">// 使用结构体指针实现接口</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> d Duck = Cat&#123;&#125;      <span class="comment">// 使用结构体初始化变量</span></span><br><span class="line"><span class="keyword">var</span> d Duck = &amp;Cat&#123;&#125;     <span class="comment">// 使用结构体指针初始化变量</span></span><br></pre></td></tr></table></figure>
<p>实现接口的类型和初始化返回的类型两个维度组成了四种情况，这四种情况并不都能通过编译器的检查：</p>
<table>
<thead>
<tr>
<th></th>
<th>结构体实现接口</th>
<th>结构体指针实现接口</th>
</tr>
</thead>
<tbody><tr>
<td>结构体初始化变量</td>
<td>通过</td>
<td><strong>不通过</strong></td>
</tr>
<tr>
<td>结构体指针初始化变量</td>
<td>通过</td>
<td>通过</td>
</tr>
</tbody></table>
<p>想要搞清楚这个问题，首先要知道 Go 语言在<a target="_blank" rel="noopener" href="https://draveness.me/golang/docs/part2-foundation/ch04-basic/golang-function-call/">传递参数</a>时都是<strong>传值</strong>的</p>
<img src="https://img.draveness.me/golang-interface-method-receiver.png" alt="golang-interface-method-receive" style="zoom:50%;" />

<p>如上图所示，无论上述代码中初始化的变量 <code>c</code> 是 <code>Cat&#123;&#125;</code> 还是 <code>&amp;Cat&#123;&#125;</code>，使用 <code>c.Quack()</code> 调用方法时都会发生值拷贝：</p>
<ul>
<li>如图 左侧，对于 <code>&amp;Cat&#123;&#125;</code> 来说，这意味着拷贝一个新的 <code>&amp;Cat&#123;&#125;</code> 指针，这个指针与原来的指针指向一个相同并且唯一的结构体，所以编译器可以隐式的对变量解引用（dereference）获取指针指向的结构体；</li>
<li>如图 右侧，对于 <code>Cat&#123;&#125;</code> 来说，这意味着 <code>Quack</code> 方法会接受一个全新的 <code>Cat&#123;&#125;</code>，因为方法的参数是 <code>*Cat</code>，编译器不会无中生有创建一个新的指针；即使编译器可以创建新指针，这个指针指向的也不是最初调用该方法的结构体；</li>
</ul>
<blockquote>
<p>注意：对于方法而言（不涉及到接口时），不管你的method的receiver是指针类型还是非指针类型，都是可以通过指针/非指针类型进行调用的，编译器会帮你做类型转换。</p>
</blockquote>
<h3 id="3-2-2、类型断言"><a href="#3-2-2、类型断言" class="headerlink" title="3.2.2、类型断言"></a>3.2.2、类型断言</h3><p>类型断言（Type Assertion）是一个使用在接口值上的操作，用于检查接口类型变量所持有的值是否实现了期望的接口或者具体的类型。</p>
<p>在Go语言中类型断言的语法格式如下：</p>
<p>value, ok := x.(T)</p>
<p>其中，x 表示一个接口的类型，T 表示一个具体的类型（也可为接口类型）。</p>
<p>该断言表达式会返回 x 的值（也就是 value）和一个布尔值（也就是 ok），可根据该布尔值判断 x 是否为 T 类型：</p>
<ul>
<li>如果 T 是具体某个类型，类型断言会检查 x 的动态类型是否等于具体类型 T。如果检查成功，类型断言返回的结果是 x 的动态值，其类型是 T。</li>
<li>如果 T 是接口类型，类型断言会检查 x 的动态类型是否满足 T。如果检查成功，x 的动态值不会被提取，返回值是一个类型为 T 的接口值。</li>
<li>无论 T 是什么类型，如果 x 是 nil 接口值，类型断言都会失败。</li>
</ul>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> x <span class="keyword">interface</span>&#123;&#125;=<span class="number">7</span>  <span class="comment">//x的动态类型为int,值为7</span></span><br><span class="line">i:=x.(<span class="keyword">int</span>)           <span class="comment">// i的类型为int ,值为7</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> I <span class="keyword">interface</span> &#123;m()&#125;</span><br><span class="line"><span class="keyword">var</span> y I</span><br><span class="line"></span><br><span class="line">s:=y.(<span class="keyword">string</span>)      <span class="comment">//非法: string 没有实现接口 I (missing method m)</span></span><br><span class="line">r:=y.(io.Reader)   <span class="comment">//y如果实现了接口io.Reader和I的情况下，  r的类型则为io.Reader</span></span><br></pre></td></tr></table></figure>
<p>类型断言还可以配合 switch 使用，实现比较类型的效果。</p>
<p><code>type switch</code>它用于检测的是值<code>x</code>的类型<code>T</code>是否匹配某个类型.</p>
<p>格式如下，类似类型断言，但是括号内的不是某个具体的类型，而是单词<code>type</code>:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span> x.(<span class="keyword">type</span>)&#123;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span> i := x.(<span class="keyword">type</span>) &#123;</span><br><span class="line"><span class="keyword">case</span> <span class="literal">nil</span>:</span><br><span class="line">  printString(<span class="string">&quot;x is nil&quot;</span>) <span class="comment">// i的类型是 x的类型 (interface&#123;&#125;)</span></span><br><span class="line"><span class="keyword">case</span> <span class="keyword">int</span>:</span><br><span class="line">  printInt(i) <span class="comment">// i的类型 int</span></span><br><span class="line"><span class="keyword">case</span> <span class="keyword">float64</span>:</span><br><span class="line">  printFloat64(i) <span class="comment">// i的类型是 float64</span></span><br><span class="line"><span class="keyword">case</span> <span class="function"><span class="keyword">func</span><span class="params">(<span class="keyword">int</span>)</span> <span class="title">float64</span>:</span></span><br><span class="line">  printFunction(i) <span class="comment">// i的类型是 func(int) float64</span></span><br><span class="line"><span class="keyword">case</span> <span class="keyword">bool</span>, <span class="keyword">string</span>:</span><br><span class="line">  printString(<span class="string">&quot;type is bool or string&quot;</span>) <span class="comment">// i的类型是 x (interface&#123;&#125;)</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">  printString(<span class="string">&quot;don&#x27;t know the type&quot;</span>) <span class="comment">// i的类型是 x的类型 (interface&#123;&#125;)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-3、反射"><a href="#3-3、反射" class="headerlink" title="3.3、反射"></a>3.3、反射</h2><h1 id="4、Goroutines-和-Channels"><a href="#4、Goroutines-和-Channels" class="headerlink" title="4、Goroutines 和 Channels"></a>4、Goroutines 和 Channels</h1><h2 id="4-1、goroutine"><a href="#4-1、goroutine" class="headerlink" title="4.1、goroutine"></a>4.1、goroutine</h2><p>当一个程序启动时，其主函数即在一个单独的goroutine中运行，我们叫它main goroutine。新的goroutine会用go语句来创建。在语法上，go语句是一个普通的函数或方法调用前加上关键字go。go语句会使其语句中的函数在一个新创建的goroutine中运行。而go语句本身会迅速地完成。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">f()    <span class="comment">// call f(); wait for it to return</span></span><br><span class="line"><span class="keyword">go</span> f() <span class="comment">// create a new goroutine that calls f(); don&#x27;t wait</span></span><br></pre></td></tr></table></figure>


<h2 id="4-2、channel"><a href="#4-2、channel" class="headerlink" title="4.2、channel"></a>4.2、channel</h2><h3 id="创建channel"><a href="#创建channel" class="headerlink" title="创建channel"></a>创建channel</h3><p>如果说goroutine是Go语言程序的并发体的话，那么channels则是它们之间的通信机制。一个channel是一个通信机制，它可以让一个goroutine通过它给另一个goroutine发送值信息。每个channel都有一个特殊的类型，也就是channels可发送数据的类型。一个可以发送int类型数据的channel一般写为chan int。</p>
<p>使用内置的make函数，我们可以创建一个channel：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>) <span class="comment">// ch has type &#x27;chan int&#x27;</span></span><br><span class="line">ch = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)    <span class="comment">// unbuffered channel</span></span><br><span class="line">ch = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">0</span>) <span class="comment">// unbuffered channel</span></span><br><span class="line">ch = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">3</span>) <span class="comment">// buffered channel with capacity 3</span></span><br></pre></td></tr></table></figure>
<p>和map类似，<strong>channel也对应一个make创建的底层数据结构的引用。当我们复制一个channel或用于函数参数传递时，我们只是拷贝了一个channel引用</strong>，因此调用者和被调用者将引用同一个channel对象。和其它的引用类型一样，channel的零值也是nil。</p>
<p>两个相同类型的channel可以使用==运算符比较。如果两个channel引用的是相同的对象，那么比较的结果为真。一个channel也可以和nil进行比较。</p>
<p>一个channel有发送和接受两个主要操作，都是通信行为。一个发送语句将一个值从一个goroutine通过channel发送到另一个执行接收操作的goroutine。发送和接收两个操作都使用<code>&lt;-</code>运算符：</p>
<ul>
<li>在发送语句中，<code>&lt;-</code>运算符分割channel和要发送的值</li>
<li>在接收语句中，<code>&lt;-</code>运算符写在channel对象之前。一个不使用接收结果的接收操作也是合法的。</li>
</ul>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ch &lt;- x  <span class="comment">// a send statement</span></span><br><span class="line">x = &lt;-ch <span class="comment">// a receive expression in an assignment statement</span></span><br><span class="line">&lt;-ch     <span class="comment">// a receive statement; result is discarded</span></span><br></pre></td></tr></table></figure>
<h3 id="buffer"><a href="#buffer" class="headerlink" title="buffer"></a>buffer</h3><p>channel可以带buffer：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make(chan int, 2)</span><br></pre></td></tr></table></figure>
<p>表示创建一个length为2的管道，注意这里的length表示数量，而非具体的内存容积，比如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make(chan string, 2)</span><br></pre></td></tr></table></figure>
<ul>
<li>表示可以容纳2个string的内容，比如”abcdefg”和”h”这样2个string，而不是指只能存”a”和”b”。</li>
<li>当不设置length时候即为buffer=0</li>
</ul>
<p>说明：</p>
<ul>
<li>往chan发送数据时候，若buffer没满的时候，则发送数据即刻成功，不会被阻塞。当buffer满了就会被阻塞</li>
<li>从chan接受数据时候，若buffer是空的则会被阻塞，当buffer不是空的时候则即刻完成，不会被阻塞</li>
</ul>
<h3 id="Close"><a href="#Close" class="headerlink" title="Close"></a>Close</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">close</span>(ch)</span><br></pre></td></tr></table></figure>
<p>有且只有发送者可以关闭管道，接收者不能关闭管道</p>
<p>接收者可以通过<code>v, ok := &lt;-ch</code>这种方式来测试管道是否关闭，若ok为false则表示管道已关闭</p>
<p>关闭channe后l，随后对基于该channel的任何发送操作都将导致panic异常。对一个已经被close过的channel进行接收操作依然可以接受到之前已经成功发送的数据；如果channel中已经没有数据的话将产生一个零值的数据。</p>
<h3 id="select-case"><a href="#select-case" class="headerlink" title="select-case"></a>select-case</h3><p>select和case的组合可以使哪个管道就绪（对端已阻塞），就读取该管道数据并执行相应case的代码块。</p>
<p>官网译: select 会阻塞，直到条件分支中的某个可以继续执行，这时就会执行那个条件分支。当多个都准备好的时候，会随机选择一个。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">receive</span><span class="params">(ch1, ch2, ch3, quit <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">2</span>; i++ &#123;</span><br><span class="line">        fmt.Printf(<span class="string">&quot;receive %d from ch1\n&quot;</span>, &lt;-ch1)</span><br><span class="line">        fmt.Printf(<span class="string">&quot;receive %d from ch2\n&quot;</span>, &lt;-ch2)</span><br><span class="line">        fmt.Printf(<span class="string">&quot;receive %d from ch3\n&quot;</span>, &lt;-ch3)</span><br><span class="line">    &#125;</span><br><span class="line">    quit &lt;- <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">send</span><span class="params">(ch1, ch2, ch3, quit <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">        <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> ch1 &lt;- i:</span><br><span class="line">            fmt.Printf(<span class="string">&quot;send %d to ch1\n&quot;</span>, i)</span><br><span class="line">        <span class="keyword">case</span> ch2 &lt;- i:</span><br><span class="line">            fmt.Printf(<span class="string">&quot;send %d to ch2\n&quot;</span>, i)</span><br><span class="line">        <span class="keyword">case</span> ch3 &lt;- i:</span><br><span class="line">            fmt.Printf(<span class="string">&quot;send %d to ch3\n&quot;</span>, i)</span><br><span class="line">        <span class="keyword">case</span> &lt;-quit:</span><br><span class="line">            fmt.Println(<span class="string">&quot;quit&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    ch1 := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">    ch2 := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">    ch3 := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">    quit := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">    <span class="keyword">go</span> receive(ch1, ch2, ch3, quit)</span><br><span class="line">    send(ch1, ch2, ch3, quit)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="只读只写channel"><a href="#只读只写channel" class="headerlink" title="只读只写channel"></a>只读只写channel</h3><p>channel支持3种类型（通过%T看到的）：</p>
<ul>
<li>读写类型：<code>chan int</code></li>
<li>只读类型：<code>&lt;-chan int</code>，叫做receive-only</li>
<li>只写类型：<code>chan&lt;- int</code>，叫做send-only</li>
</ul>
<p>通过函数参数传递时候，若原来是读写，则可以转成只读或只写，但如果已经是只读或只写，则只能保持类型，无法转为其他类型（比如原来是只读，则只能是只读，无法转成只写，也无法转为读写），例子如下：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">send</span><span class="params">(c <span class="keyword">chan</span>&lt;- <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">    fmt.Printf(<span class="string">&quot;send: %T\n&quot;</span>, c)</span><br><span class="line">    c &lt;- <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">recv</span><span class="params">(c &lt;-<span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">    fmt.Printf(<span class="string">&quot;recv: %T\n&quot;</span>, c)</span><br><span class="line">    fmt.Println(&lt;-c)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">    fmt.Printf(<span class="string">&quot;%T\n&quot;</span>, c)</span><br><span class="line">    <span class="keyword">go</span> send(c)</span><br><span class="line">    <span class="keyword">go</span> recv(c)</span><br><span class="line">    time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="5、基于共享变量的并发（sync）"><a href="#5、基于共享变量的并发（sync）" class="headerlink" title="5、基于共享变量的并发（sync）"></a>5、基于共享变量的并发（sync）</h1><h2 id="5-1、竞争条件"><a href="#5-1、竞争条件" class="headerlink" title="5.1、竞争条件"></a>5.1、竞争条件</h2><p>竞争条件指的是程序在多个goroutine交叉执行操作时，没有给出正确的结果。数据竞争会在两个以上的goroutine并发访问相同的变量且至少其中一个为写操作时发生。有三种方式可以避免数据竞争：</p>
<ol>
<li>不对变量进行更新操作，只是读取</li>
<li>避免从多个goroutine访问变量，其它的goroutine使用一个channel来发送请求给指定的goroutine来查询更新变量。这也就是Go的口头禅“不要使用共享数据来通信；使用通信来共享数据”。</li>
<li>通过“互斥”，保证同一个时刻最多只有一个goroutine在访问变量</li>
</ol>
<h2 id="5-2、互斥锁（Mutex）"><a href="#5-2、互斥锁（Mutex）" class="headerlink" title="5.2、互斥锁（Mutex）"></a>5.2、互斥锁（Mutex）</h2><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>用于主动控制Mutex类型的变量或者将Mutex类型作为struct的元素的变量在同一时间只被一个routine访问（即执行Lock()方法的代码块），这个Mutex带有2个方法：Lock()和Unlock()。互斥锁不区分读和写，即无论是print打印还是写操作都是互斥的</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&quot;sync&quot;</span></span><br><span class="line"><span class="keyword">var</span> mutex sync.Mutex</span><br><span class="line">mutex.Lock()</span><br><span class="line">mutex.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> SafeCounter <span class="keyword">struct</span> &#123;</span><br><span class="line">    v   <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span></span><br><span class="line">    mux sync.Mutex</span><br><span class="line">&#125;</span><br><span class="line">c := SafeCounter&#123;v: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span>)&#125;</span><br><span class="line">c.mux.Lock()</span><br><span class="line">c.mux.Unlock()</span><br></pre></td></tr></table></figure>
<h3 id="互斥锁在共同使用时才生效"><a href="#互斥锁在共同使用时才生效" class="headerlink" title="互斥锁在共同使用时才生效"></a>互斥锁在共同使用时才生效</h3><p>互斥锁的使用是主动控制互斥锁，需要大家一起用才会生效。比如即使一个routine里用了Lock()，但在另一个routine可以不理会这个锁就能访问这个struct，只需要不调用Lock()就行。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;sync&quot;</span></span><br><span class="line">    <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> SafeCounter <span class="keyword">struct</span> &#123;</span><br><span class="line">    v   <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span></span><br><span class="line">    mux sync.Mutex</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *SafeCounter)</span> <span class="title">Inc</span><span class="params">(key <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">    c.mux.Lock()</span><br><span class="line">    fmt.Printf(<span class="string">&quot;goroutine start sleep 3s\n&quot;</span>)</span><br><span class="line">    time.Sleep(<span class="number">3</span> * time.Second)</span><br><span class="line">    <span class="comment">// 虽然有锁，但这个++后执行</span></span><br><span class="line">    c.v[key]++</span><br><span class="line">    c.mux.Unlock()</span><br><span class="line">    fmt.Printf(<span class="string">&quot;goroutine stop sleep 3s\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    c := SafeCounter&#123;v: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span>)&#125;</span><br><span class="line">    <span class="keyword">go</span> c.Inc(<span class="string">&quot;somekey&quot;</span>)</span><br><span class="line"></span><br><span class="line">    fmt.Printf(<span class="string">&quot;main start sleep 1s\n&quot;</span>)</span><br><span class="line">    time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">    fmt.Printf(<span class="string">&quot;main stop sleep 1s\n&quot;</span>)</span><br><span class="line">    <span class="comment">// 这个 ++ 先执行</span></span><br><span class="line">    c.v[<span class="string">&quot;somekey&quot;</span>]++</span><br><span class="line">    fmt.Println(c.v[<span class="string">&quot;somekey&quot;</span>])</span><br><span class="line"></span><br><span class="line">    fmt.Printf(<span class="string">&quot;main start sleep 3s\n&quot;</span>)</span><br><span class="line">    time.Sleep(<span class="number">3</span> * time.Second)</span><br><span class="line">    fmt.Printf(<span class="string">&quot;main stop sleep 3s\n&quot;</span>)</span><br><span class="line">    fmt.Println(c.v[<span class="string">&quot;somekey&quot;</span>])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>打印结果为：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">main start sleep <span class="number">1</span>s</span><br><span class="line">goroutine start sleep <span class="number">3</span>s</span><br><span class="line">main stop sleep <span class="number">1</span>s</span><br><span class="line"><span class="number">1</span></span><br><span class="line">main start sleep <span class="number">3</span>s</span><br><span class="line">goroutine stop sleep <span class="number">3</span>s</span><br><span class="line">main stop sleep <span class="number">3</span>s</span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>上述例子说明了：Lock只是一种人为的互斥，是一种协议，并不是强制</p>
<h3 id="已经锁定的Mutex与特定的goroutine无关联"><a href="#已经锁定的Mutex与特定的goroutine无关联" class="headerlink" title="已经锁定的Mutex与特定的goroutine无关联"></a><strong>已经锁定的Mutex与特定的goroutine无关联</strong></h3><p>已经锁定的Mutex并不与特定的goroutine相关联，这样可以利用一个goroutine对其加锁，再利用其他goroutine对其解锁</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;sync&quot;</span></span><br><span class="line">    <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> MyStruct <span class="keyword">struct</span> &#123;</span><br><span class="line">    v   <span class="keyword">int</span></span><br><span class="line">    mux sync.Mutex</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *MyStruct)</span> <span class="title">Lock</span><span class="params">()</span></span> &#123;</span><br><span class="line">    s.mux.Lock()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *MyStruct)</span> <span class="title">Unlock</span><span class="params">()</span></span> &#123;</span><br><span class="line">    s.mux.Unlock()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    s := MyStruct&#123;v: <span class="number">0</span>&#125;</span><br><span class="line">    s.v = <span class="number">1</span></span><br><span class="line">    fmt.Printf(<span class="string">&quot;%+v\n&quot;</span>, s)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">go</span> s.Lock()</span><br><span class="line">    time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">    fmt.Printf(<span class="string">&quot;%+v\n&quot;</span>, s)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">go</span> s.Unlock()</span><br><span class="line">    time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">    fmt.Printf(<span class="string">&quot;%+v\n&quot;</span>, s)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="5-3、读写锁（RWMutex）"><a href="#5-3、读写锁（RWMutex）" class="headerlink" title="5.3、读写锁（RWMutex）"></a>5.3、读写锁（RWMutex）</h2><p>读写锁是针对于读写操作的互斥锁。它与普通的互斥锁最大的不同就是，它可以分别针对读操作和写操作进行锁定和解锁操作。读写锁遵循的访问控制规则与互斥锁有所不同。在读写锁管辖的范围内，它允许任意个读操作的同时进行。但是，在同一时刻，它只允许有一个写操作在进行。并且，在某一个写操作被进行的过程中，读操作的进行也是不被允许的。也就是说，读写锁控制下的多个写操作之间都是互斥的，并且写操作与读操作之间也都是互斥的。但是，多个读操作之间却不存在互斥关系。</p>
<p>换句话说:</p>
<ol>
<li>同时只能有一个 goroutine 能够获得写锁定。</li>
<li>同时可以有任意多个 gorouinte 获得读锁定。</li>
<li>同时只能存在写锁定或读锁定（读和写互斥）。</li>
</ol>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rw *RWMutex)</span> <span class="title">Lock</span>       //写锁定</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rw *RWMutex)</span> <span class="title">Unlock</span>     //写解锁</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rw *RWMutex)</span> <span class="title">RLock</span>      //读锁定</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rw *RWMutex)</span> <span class="title">RUnlock</span>    //读解锁</span></span><br></pre></td></tr></table></figure>
<p>Mutex和RWMutex都实现了Locker接口。该接口如下：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Locker <span class="keyword">interface</span> &#123;</span><br><span class="line">    Lock()</span><br><span class="line">    Unlock()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>写锁的优先级比读锁高，读锁和写锁不会无限饥饿。参见<a target="_blank" rel="noopener" href="https://fivezh.github.io/2019/04/09/sync_mutex_translation/">sync.RWMutex - 解决并发读写问题</a></p>
<h2 id="5-4、WaitGroup"><a href="#5-4、WaitGroup" class="headerlink" title="5.4、WaitGroup"></a>5.4、WaitGroup</h2><p>WaitGroup 用于等待一组 goroutine 结束，用法很简单。它有三个方法：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(wg *WaitGroup)</span> <span class="title">Add</span><span class="params">(delta <span class="keyword">int</span>)</span></span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(wg *WaitGroup)</span> <span class="title">Done</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(wg *WaitGroup)</span> <span class="title">Wait</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li>Add 用来添加 goroutine 的个数</li>
<li>Done 执行一次数量减 1</li>
<li>Wait 用来等待结束</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import (</span><br><span class="line">    &quot;fmt&quot;</span><br><span class="line">    &quot;sync&quot;</span><br><span class="line">    &quot;time&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">    var wg sync.WaitGroup</span><br><span class="line">    fmt.Printf(&quot;init:             %+v\n&quot;, wg)</span><br><span class="line"></span><br><span class="line">    for i :&#x3D; 1; i &lt; 10; i++ &#123;</span><br><span class="line">        &#x2F;&#x2F; 计数加 1</span><br><span class="line">        wg.Add(1)</span><br><span class="line">        go func(i int) &#123;</span><br><span class="line">            fmt.Printf(&quot;goroutine%d start: %+v\n&quot;, i, wg)</span><br><span class="line">            time.Sleep(11 * time.Second)</span><br><span class="line">            &#x2F;&#x2F; 计数减 1</span><br><span class="line">            wg.Done()</span><br><span class="line">            fmt.Printf(&quot;goroutine%d end:   %+v\n&quot;, i, wg)</span><br><span class="line">        &#125;(i)</span><br><span class="line">        time.Sleep(time.Second)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 等待执行结束</span><br><span class="line">    wg.Wait()</span><br><span class="line">    fmt.Printf(&quot;over:             %+v\n&quot;, wg)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">init:             &#123;noCopy:&#123;&#125; state1:[0 0 0 0 0 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine1 start: &#123;noCopy:&#123;&#125; state1:[0 0 0 0 1 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine2 start: &#123;noCopy:&#123;&#125; state1:[0 0 0 0 2 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine3 start: &#123;noCopy:&#123;&#125; state1:[0 0 0 0 3 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine4 start: &#123;noCopy:&#123;&#125; state1:[0 0 0 0 4 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine5 start: &#123;noCopy:&#123;&#125; state1:[0 0 0 0 5 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine6 start: &#123;noCopy:&#123;&#125; state1:[0 0 0 0 6 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine7 start: &#123;noCopy:&#123;&#125; state1:[0 0 0 0 7 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine8 start: &#123;noCopy:&#123;&#125; state1:[0 0 0 0 8 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine9 start: &#123;noCopy:&#123;&#125; state1:[0 0 0 0 9 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine1 end:   &#123;noCopy:&#123;&#125; state1:[1 0 0 0 8 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine2 end:   &#123;noCopy:&#123;&#125; state1:[1 0 0 0 7 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine3 end:   &#123;noCopy:&#123;&#125; state1:[1 0 0 0 6 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine4 end:   &#123;noCopy:&#123;&#125; state1:[1 0 0 0 5 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine5 end:   &#123;noCopy:&#123;&#125; state1:[1 0 0 0 4 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine6 end:   &#123;noCopy:&#123;&#125; state1:[1 0 0 0 3 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine7 end:   &#123;noCopy:&#123;&#125; state1:[1 0 0 0 2 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine8 end:   &#123;noCopy:&#123;&#125; state1:[1 0 0 0 1 0 0 0 0 0 0 0] sema:0&#125;</span><br><span class="line">goroutine9 end:   &#123;noCopy:&#123;&#125; state1:[0 0 0 0 0 0 0 0 0 0 0 0] sema:1&#125;</span><br><span class="line">over:             &#123;noCopy:&#123;&#125; state1:[0 0 0 0 0 0 0 0 0 0 0 0] sema:0&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>wg.Add() 方法一定要在 goroutine 开始前执行</p>
</blockquote>
<h2 id="5-5、条件变量（Cond）"><a href="#5-5、条件变量（Cond）" class="headerlink" title="5.5、条件变量（Cond）"></a>5.5、条件变量（Cond）</h2><p>与互斥量不同，条件变量的作用并不是保证在同一时刻仅有一个线程访问某一个共享数据，而是在对应的共享数据的状态发生变化时，通知其他因此而被阻塞的线程。条件变量总是与互斥量组合使用。互斥量为共享数据的访问提供互斥支持，而条件变量可以就共享数据的状态的变化向相关线程发出通知。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lock := <span class="built_in">new</span>(sync.Mutex)</span><br><span class="line">cond := sync.NewCond(lock)</span><br></pre></td></tr></table></figure>
<p>也可以写成一行</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cond := sync.NewCond(<span class="built_in">new</span>(sync.Mutex))</span><br></pre></td></tr></table></figure>
<p>方法：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 每个Cond都有一个关联的Locker L（通常是*Mutex或*RWMutex），在更改条件和调用Wait方法时必须保持该锁</span></span><br><span class="line">cond.L.Lock()</span><br><span class="line">cond.L.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="comment">//Wait以原子方式解锁c.L并挂起调用goroutine的执行。在稍后恢复执行时，在返回之前等待locks c.L。与其他系统不同，wait 不能返回，除非被 Broadcast或 signal唤醒。</span></span><br><span class="line">cond.Wait()</span><br><span class="line"></span><br><span class="line">cond.Signal() <span class="comment">//唤醒一个等待c的goroutine（如果有）。</span></span><br><span class="line">cond.Broadcast() <span class="comment">//广播唤醒所有等待c的goroutine。</span></span><br></pre></td></tr></table></figure>


<h2 id="5-6、临时对象池"><a href="#5-6、临时对象池" class="headerlink" title="5.6、临时对象池"></a>5.6、临时对象池</h2><p><code>sync.Pool</code> 是 sync 包下的一个组件，可以作为保存临时取还对象的一个“池子”。个人觉得它的名字有一定的误导性，因为 Pool 里装的对象可以被无通知地被回收，可能 <code>sync.Cache</code> 是一个更合适的名字。</p>
<p>对于很多需要重复分配、回收内存的地方，<code>sync.Pool</code> 是一个很好的选择。频繁地分配、回收内存会给 GC 带来一定的负担，严重的时候会引起 CPU 的毛刺，而 <code>sync.Pool</code> 可以将暂时不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力，提升系统的性能。</p>
<p>参见文档：</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/qcrao-2018/p/12736031.html">深度解密 Go 语言之 sync.Pool</a></p>
<p><a target="_blank" rel="noopener" href="https://cyent.github.io/golang/goroutine/sync_pool/">临时对象池(Pool)</a></p>
<h1 id="6、包"><a href="#6、包" class="headerlink" title="6、包"></a>6、包</h1><p>见此篇文章：<a target="_blank" rel="noopener" href="http://c.biancheng.net/view/5394.html">Go语言包的基本概念</a></p>
<h1 id="摘抄文档"><a href="#摘抄文档" class="headerlink" title="摘抄文档"></a>摘抄文档</h1><ol>
<li><a target="_blank" rel="noopener" href="https://fivezh.github.io/2020/03/09/golang-nil/">理解Golang中的 nil</a></li>
<li><a target="_blank" rel="noopener" href="https://books.studygolang.com/gopl-zh/">Go语言圣经（中文版）</a></li>
<li><a target="_blank" rel="noopener" href="https://cyent.github.io/golang/">Go语言学习 - cyent笔记</a></li>
<li><a target="_blank" rel="noopener" href="https://draveness.me/golang/">Go 语言设计与实现</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://heavyfish.github.io/2020/11/09/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BAKubernetes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/heavyfish.github.io/images/avatar.gif">
      <meta itemprop="name" content="Shenxr">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="速查笔记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/heavyfish.github.io/2020/11/09/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BAKubernetes/" class="post-title-link" itemprop="url">手动搭建Kubernetes</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-09 14:25:14" itemprop="dateCreated datePublished" datetime="2020-11-09T14:25:14+08:00">2020-11-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-14 22:40:37" itemprop="dateModified" datetime="2021-01-14T22:40:37+08:00">2021-01-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/heavyfish.github.io/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="参考文件"><a href="#参考文件" class="headerlink" title="参考文件"></a>参考文件</h1><p><a target="_blank" rel="noopener" href="https://blog.z0ukun.com/?p=2391">手动搭建Kubernetes-v1.16.8高可用集群（完结）</a>（基于此文档编辑修改）</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/">kube-apiserver config</a>官网中文</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/">kube-apiserver config</a>官网英文</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/reference/kubectl/kubectl/">kubectl config 官网中文</a></p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-controller-manager/">kube-controller-manager</a>官网中文</p>
<h1 id="1、组件版本说明（参考）"><a href="#1、组件版本说明（参考）" class="headerlink" title="1、组件版本说明（参考）"></a>1、组件版本说明（参考）</h1><table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>组件</strong></th>
<th><strong>版本</strong></th>
<th><strong>备注</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>kubernetes</td>
<td>v1.16.8</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>etcd</td>
<td>v3.3.20</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>docker</td>
<td>v18.09.6</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>flannel</td>
<td>v0.11.0</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>coredns</td>
<td>v1.6.7</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>dashboard</td>
<td>v2.0.0-rc4</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>k8s-prometheus-adapter</td>
<td>v0.5.0</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>prometheus-operator</td>
<td>v0.38.0</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>prometheus</td>
<td>v2.15.2</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>elasticsearch、kibana</td>
<td>v7.2.0</td>
<td></td>
</tr>
<tr>
<td>11</td>
<td>cni-plugins</td>
<td>v0.8.5</td>
<td></td>
</tr>
<tr>
<td>12</td>
<td>metrics-server</td>
<td>v0.3.6</td>
<td></td>
</tr>
<tr>
<td>13</td>
<td>weave</td>
<td>v1.13.0</td>
<td></td>
</tr>
<tr>
<td>14</td>
<td>kubeapps</td>
<td>v1.8.2</td>
<td></td>
</tr>
<tr>
<td>15</td>
<td>helm</td>
<td>v3.1.0</td>
<td></td>
</tr>
<tr>
<td>16</td>
<td>grafana</td>
<td>v1.13.0</td>
<td></td>
</tr>
<tr>
<td>17</td>
<td>traefik</td>
<td>v2.1</td>
<td></td>
</tr>
</tbody></table>
<p><strong>主要配置策略</strong></p>
<p>kube-apiserver：</p>
<ul>
<li>使用节点本地 nginx 4 层透明代理实现高可用；</li>
<li>关闭非安全端口 8080 和匿名访问；</li>
<li>在安全端口 6443 接收 https 请求；</li>
<li>严格的认证和授权策略 (x509、token、RBAC)；</li>
<li>开启 bootstrap token 认证，支持 kubelet TLS bootstrapping；</li>
<li>使用 https 访问 kubelet、etcd，加密通信；</li>
</ul>
<p>kube-controller-manager：</p>
<ul>
<li>3 节点高可用；</li>
<li>关闭非安全端口，在安全端口 10252 接收 https 请求；</li>
<li>使用 kubeconfig 访问 apiserver 的安全端口；</li>
<li>自动 approve kubelet 证书签名请求 (CSR)，证书过期后自动轮转；</li>
<li>各 controller 使用自己的 ServiceAccount 访问 apiserver；</li>
</ul>
<p>kube-scheduler：</p>
<ul>
<li>3 节点高可用；</li>
<li>使用 kubeconfig 访问 apiserver 的安全端口；</li>
</ul>
<p>kubelet：</p>
<ul>
<li>使用 kubeadm 动态创建 bootstrap token，而不是在 apiserver 中静态配置；</li>
<li>使用 TLS bootstrap 机制自动生成 client 和 server 证书，过期后自动轮转；</li>
<li>在 KubeletConfiguration 类型的 JSON 文件配置主要参数；</li>
<li>关闭只读端口，在安全端口 10250 接收 https 请求，对请求进行认证和授权，拒绝匿名访问和非授权访问；</li>
<li>使用 kubeconfig 访问 apiserver 的安全端口；</li>
</ul>
<p>kube-proxy：</p>
<ul>
<li>使用 kubeconfig 访问 apiserver 的安全端口；</li>
<li>在 KubeProxyConfiguration 类型的 JSON 文件配置主要参数；</li>
<li>使用 ipvs 代理模式；</li>
</ul>
<p>集群插件：</p>
<ul>
<li>DNS：使用功能、性能更好的 coredns；</li>
<li>Dashboard：支持登录认证；</li>
<li>Metric：metrics-server，使用 https 访问 kubelet 安全端口；</li>
<li>Log：Elasticsearch、Fluend、Kibana；</li>
<li>Registry 镜像库：docker-registry、harbor；</li>
</ul>
<h1 id="2、系统初始化"><a href="#2、系统初始化" class="headerlink" title="2、系统初始化"></a>2、系统初始化</h1><p><strong>集群规划</strong></p>
<ul>
<li>NFS Server：   172.16.200.10</li>
<li>Kubernetes-01：172.16.200.11</li>
<li>Kubernetes-02：172.16.200.12</li>
<li>Kubernetes-03：172.16.200.13</li>
</ul>
<p>这里我们准备4台主机，NFS Server作为NFS后端存储、部署NFS服务提供存储能力。另外三台机器混合部署etcd、master集群和woker集群。</p>
<p>注：如果没有特殊说明，本小节所有操作需要在所有节点上执行本文档的初始化操作。</p>
<p><strong>配置主机名</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 可以将下面的节点名称替换为自己的主机名称</span><br><span class="line">hostnamectl set-hostname NFS Server</span><br><span class="line">hostnamectl set-hostname Kubernetes-01</span><br><span class="line">hostnamectl set-hostname Kubernetes-02</span><br><span class="line">hostnamectl set-hostname Kubernetes-03</span><br></pre></td></tr></table></figure>


<p>如果 DNS 不支持主机名称解析，还需要在每台机器的 /etc/hosts 文件中添加主机名和 IP 的对应关系：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; &#x2F;etc&#x2F;hosts &lt;&lt;EOF</span><br><span class="line">172.16.200.10  NFS Server</span><br><span class="line">172.16.200.11  Kubernetes-01</span><br><span class="line">172.16.200.12  Kubernetes-02</span><br><span class="line">172.16.200.13  Kubernetes-03 </span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>


<p><strong>添加节点SSH互信</strong></p>
<p>本操作只需要在 Kubernetes-01 节点上进行，设置 root 账户可以无密码登录所有节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa </span><br><span class="line">ssh-copy-id root@Kubernetes-01</span><br><span class="line">ssh-copy-id root@Kubernetes-02</span><br><span class="line">ssh-copy-id root@Kubernetes-03</span><br><span class="line">ssh-copy-id root@NFS Server</span><br></pre></td></tr></table></figure>
<p><strong>更新PATH变量</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo &#39;PATH&#x3D;&#x2F;opt&#x2F;k8s&#x2F;bin:$PATH&#39; &gt;&gt;&#x2F;root&#x2F;.bashrc</span><br><span class="line">source &#x2F;root&#x2F;.bashrc</span><br></pre></td></tr></table></figure>
<p>注：/opt/k8s/bin 目录保存本文档下载安装的程序。</p>
<p><strong>安装依赖包</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release</span><br><span class="line">yum install -y chrony conntrack ipvsadm ipset jq iptables curl sysstat libseccomp wget socat git</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">conntrack:操作netfilter连接跟踪表并保持高可用</span></span><br><span class="line"><span class="meta">#</span><span class="bash">ipvsadm：管理Linux Virtual Server 的工具</span></span><br><span class="line"><span class="meta">#</span><span class="bash">ipset：Manage Linux IP sets</span></span><br><span class="line"><span class="meta">#</span><span class="bash">jq：Command-line JSON processor</span></span><br><span class="line"><span class="meta">#</span><span class="bash">sysstat：Linux性能监视工具的集合</span></span><br><span class="line"><span class="meta">#</span><span class="bash">libseccomp：增强的 seccomp 库,而Secure Computing Mode (seccomp) 是一种内核特性，它允许您从容器中过滤对内核的系统调用</span></span><br><span class="line"><span class="meta">#</span><span class="bash">socat：Socat 是 Linux 下的一个多功能的网络工具,可以看做是 Netcat 的加强版。</span></span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html/container_security_guide/linux_capabilities_and_seccomp">LINUX CAPABILITIES AND SECCOMP</a></p>
<p><a target="_blank" rel="noopener" href="https://www.hi-linux.com/posts/61543.html">Socat 入门教程</a></p>
<p>注：本文档的 kube-proxy 使用 ipvs 模式，ipvsadm 为 ipvs 的管理工具； etcd 集群各机器需要时间同步，chrony 用于系统时间同步。</p>
<p><strong>关闭防火墙</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">iptables -F &amp;&amp; iptables -X &amp;&amp; iptables -F -t nat &amp;&amp; iptables -X -t nat</span><br><span class="line">iptables -P FORWARD ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">-F:刷新选中的链(如果没有给定链，则刷新表中的所有链)。这相当于逐一删除所有规则</span></span><br><span class="line"><span class="meta">#</span><span class="bash">-X:删除指定的可选用户定义链。必须没有对链的引用。如果存在引用规则，则必须在删除链之前删除或替换引用规则。链必须是空的，即不包含任何规则。如果没有给出参数，它将尝试删除表中的所有非内建链</span></span><br><span class="line"><span class="meta">#</span><span class="bash">-t:此选项指定命令应该操作的数据包匹配表</span></span><br><span class="line"><span class="meta">#</span><span class="bash">-P:将链的策略设置为给定的规则。只有内置(非用户定义)链可以拥有策略，而且内置链和用户定义链都不能是策略目标</span></span><br></pre></td></tr></table></figure>
<p>注：关闭防火墙，清理防火墙规则，设置默认转发策略。</p>
<p> <strong>关闭swap分区</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br><span class="line">sed -i &#39;&#x2F; swap &#x2F; s&#x2F;^\(.*\)$&#x2F;#\1&#x2F;g&#39; &#x2F;etc&#x2F;fstab</span><br></pre></td></tr></table></figure>
<p>注：关闭 swap 分区，否则kubelet 会启动失败(可以设置 kubelet 启动参数 –fail-swap-on 为 false 关闭 swap 检查)。</p>
<p><strong>关闭SELinux</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i &#39;s&#x2F;^SELINUX&#x3D;.*&#x2F;SELINUX&#x3D;disabled&#x2F;&#39; &#x2F;etc&#x2F;selinux&#x2F;config</span><br></pre></td></tr></table></figure>
<p>注：关闭 SELinux，否则 kubelet 挂载目录时可能报错 Permission denied。</p>
<p><strong>优化内核参数</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kubernetes.conf &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 1 表示 二层的网桥在转发包时也会被iptables的FORWARD规则所过滤</span></span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables=1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 1 表示 开启Linux系统的路由转发功能</span></span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭</span></span><br><span class="line">net.ipv4.tcp_tw_recycle=0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 增加内核内部的ARP缓存大小</span></span><br><span class="line">net.ipv4.neigh.default.gc_thresh1=1024</span><br><span class="line">net.ipv4.neigh.default.gc_thresh2=2048</span><br><span class="line">net.ipv4.neigh.default.gc_thresh3=4096</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 不使用SWAP分区</span></span><br><span class="line">vm.swappiness=0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 1 表示 内核允许分配所有的物理内存，而不管当前的内存状态如何</span></span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 0：内存不足时，启动 OOM killer</span></span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 表示每一个real user ID可创建的inotify instatnces的数量上限，默认128</span></span><br><span class="line">fs.inotify.max_user_instances=8192</span><br><span class="line"><span class="meta">#</span><span class="bash"> 表示同一用户同时可以添加的watch数目（watch一般是针对目录，决定了同时同一用户可以监控的目录数量）</span></span><br><span class="line">fs.inotify.max_user_watches=1048576</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置Linux内核将分配的最大文件句柄数量。通常可设置为 total_Mem(M)/4 * 256</span></span><br><span class="line">fs.file-max=52706963</span><br><span class="line"><span class="meta">#</span><span class="bash"> nr_open是单个进程可分配的最大文件数</span></span><br><span class="line">fs.nr_open=52706963</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 禁用ipv6</span></span><br><span class="line">net.ipv6.conf.all.disable_ipv6=1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 最大跟踪连接数</span></span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line">EOF</span><br><span class="line">cp kubernetes.conf  /etc/sysctl.d/kubernetes.conf</span><br><span class="line">sysctl -p /etc/sysctl.d/kubernetes.conf</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/94413312">关于gc_thresh可能出现的问题</a></p>
<p>inotify API提供了一种监视文件系统事件的机制。Inotify可以用于监视单个文件，也可以用于监视目录。当一个目录被监视时，inotify将返回目录本身和目录内文件的事件。<code>yum install inotify-tools</code> ，安装inotify的工具。</p>
<p>注：关闭 tcp_tw_recycle，否则与 NAT 冲突，可能导致服务不通。</p>
<p><strong>配置系统时区</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timedatectl set-timezone Asia&#x2F;Shanghai</span><br></pre></td></tr></table></figure>


<p><strong>配置时钟同步</strong></p>
<p>查看同步状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timedatectl status</span><br></pre></td></tr></table></figure>
<p>如果正确、输出信息如下（这里配的时候忘记截图了、后面补的截图）：</p>
<p>注：System clock synchronized: yes，表示时钟已同步； NTP service: active，表示开启了时钟同步服务。</p>
<p><strong>写入硬件时钟</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 将当前的 UTC 时间写入硬件时钟</span></span><br><span class="line">timedatectl set-local-rtc 0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启依赖于系统时间的服务</span></span><br><span class="line">systemctl restart rsyslog </span><br><span class="line">systemctl restart crond</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">rsyslog：centos7的默认日志系统，用于在ip网络中转发日志信息</span></span><br><span class="line"><span class="meta">#</span><span class="bash">crond：定时任务的守护进程</span></span><br></pre></td></tr></table></figure>


<p><strong>关闭无关服务</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop postfix &amp;&amp; systemctl disable postfix</span><br></pre></td></tr></table></figure>


<p><strong>创建配置目录</strong></p>
<p>创建接下来要使用的相关安装目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p &#x2F;opt&#x2F;k8s&#x2F;&#123;bin,work&#125; &#x2F;etc&#x2F;&#123;kubernetes,etcd&#125;&#x2F;cert</span><br></pre></td></tr></table></figure>


<p><strong>分发集群配置参数</strong></p>
<p>后续使用的环境变量都定义在文件 environment.sh 中，请根据自己的机器、网络情况修改：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/usr/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 生成 EncryptionConfig 所需的加密 key</span></span><br><span class="line">export ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 集群各机器 IP 数组</span></span><br><span class="line">export NODE_IPS=(172.16.200.11 172.16.200.12 172.16.200.13)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 集群各 IP 对应的主机名数组</span></span><br><span class="line">export NODE_NAMES=(Kubernetes-01 Kubernetes-02 Kubernetes-03)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> etcd 集群服务地址列表</span></span><br><span class="line">export ETCD_ENDPOINTS=&quot;https://172.16.200.11:2379,https://172.16.200.12:2379,https://172.16.200.13:2379&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> etcd 集群间通信的 IP 和端口</span></span><br><span class="line">export ETCD_NODES=&quot;Kubernetes-01=https://172.16.200.11:2380,Kubernetes-02=https://172.16.200.12:2380,Kubernetes-03=https://172.16.200.13:2380&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> kube-apiserver 的反向代理(kube-nginx)地址端口</span></span><br><span class="line">export KUBE_APISERVER=&quot;https://127.0.0.1:8443&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 节点间互联网络接口名称</span></span><br><span class="line">export IFACE=&quot;ens160&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> etcd 数据目录</span></span><br><span class="line">export ETCD_DATA_DIR=&quot;/data/k8s/etcd/data&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> etcd WAL 目录，建议是 SSD 磁盘分区，或者和 ETCD_DATA_DIR 不同的磁盘分区</span></span><br><span class="line">export ETCD_WAL_DIR=&quot;/data/k8s/etcd/wal&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> k8s 各组件数据目录</span></span><br><span class="line">export K8S_DIR=&quot;/data/k8s/k8s&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># DOCKER_DIR 和 CONTAINERD_DIR 二选一</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> docker 数据目录</span></span><br><span class="line">export DOCKER_DIR=&quot;/data/k8s/docker&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> containerd 数据目录</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">export</span> CONTAINERD_DIR=<span class="string">&quot;/data/k8s/containerd&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 以下参数一般不需要修改</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> TLS Bootstrapping 使用的 Token，可以使用命令</span> </span><br><span class="line"><span class="meta">#</span><span class="bash"> head -c 16 /dev/urandom | od -An -t x | tr -d <span class="string">&#x27; &#x27;</span> 生成</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> od：以八进制和其他格式转储文件，-A:输出格式偏移，n表示None，-t：输出格式，x表示16进制</span></span><br><span class="line"></span><br><span class="line">BOOTSTRAP_TOKEN=&quot;41f7e4ba8b7be874fcff18bf5cf41a7c&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 最好使用 当前未用的网段 来定义服务网段和 Pod 网段</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 服务网段，部署前路由不可达，部署后集群内路由可达(kube-proxy 保证)</span></span><br><span class="line">SERVICE_CIDR=&quot;10.254.0.0/16&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Pod 网段，建议 /16 段地址，部署前路由不可达，部署后集群内路由可达(flanneld 保证)</span></span><br><span class="line">CLUSTER_CIDR=&quot;172.30.0.0/16&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置flanneld的FLANNEL_ETCD_PREFIX文件目录</span></span><br><span class="line">export FLANNEL_ETCD_PREFIX=&quot;/kubernetes/network&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 服务端口范围 (NodePort Range)</span></span><br><span class="line">export NODE_PORT_RANGE=&quot;30000-32767&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubernetes 服务 IP (一般是 SERVICE_CIDR 中第一个IP)</span></span><br><span class="line">export CLUSTER_KUBERNETES_SVC_IP=&quot;10.254.0.1&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 集群 DNS 服务 IP (从 SERVICE_CIDR 中预分配)</span></span><br><span class="line">export CLUSTER_DNS_SVC_IP=&quot;10.254.0.2&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 集群 DNS 域名（末尾不带点号）</span></span><br><span class="line">export CLUSTER_DNS_DOMAIN=&quot;cluster.local&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将二进制目录 /opt/k8s/bin 加到 PATH 中</span></span><br><span class="line">export PATH=/opt/k8s/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>注：因为我采用了flannel网络、所以这里我在原文的基础之上添加了export FLANNEL_ETCD_PREFIX=”/kubernetes/network”变量、禁止了containerd 数据目录。</p>
<p>把上面的 environment.sh 文件修改完成之后保存到 /opt/k8s/bin/ 目录下面，然后拷贝到所有节点（修改完上面的文件之后再执行下面的操作）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp environment.sh root@$&#123;node_ip&#125;:&#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;*&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223500350.png" alt="image-20210114223500350"></p>
<p><strong>内核升级</strong></p>
<p>CentOS 7.x 系统自带的 3.10.x 内核存在一些 Bugs，导致运行的 Docker、Kubernetes 不稳定，例如：</p>
<ul>
<li>高版本的 docker(1.13 以后) 启用了 3.10 kernel 实验支持的 kernel memory account 功能(无法关闭)，当节点压力大如频繁启动和停止容器时会导致 cgroup memory leak；</li>
<li>网络设备引用计数泄漏，会导致类似于报错：”kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1”;</li>
</ul>
<p>解决方案如下：</p>
<ul>
<li>升级内核到 4.4.X 以上；</li>
<li>或者，手动编译内核，disable CONFIG_MEMCG_KMEM 特性；</li>
<li>或者，安装修复了该问题的 Docker 18.09.1 及以上的版本。但由于 kubelet 也会设置 kmem（它 vendor 了 runc），所以需要重新编译 kubelet 并指定 GOFLAGS=”-tags=nokmem”；</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone --branch v1.14.1 --single-branch --depth 1 https://github.com/kubernetes/kubernetes</span><br><span class="line">cd kubernetes</span><br><span class="line">KUBE_GIT_VERSION=v1.14.1 ./build/run.sh make kubelet GOFLAGS=&quot;-tags=nokmem&quot;</span><br></pre></td></tr></table></figure>


<p>这里采用升级内核的解决办法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装完成后检查 /boot/grub2/grub.cfg 中对应内核 menuentry 中是否包含 initrd16 配置，如果没有，再安装一次！</span></span><br><span class="line">yum --enablerepo=elrepo-kernel install -y kernel-lt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置开机从新内核启动</span></span><br><span class="line">grub2-set-default 0</span><br></pre></td></tr></table></figure>


<p>执行完上面所有的操作之后我们就可以重启所有主机了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sync</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure>


<p>本小节参考文档：</p>
<ul>
<li>系统内核相关参数参考：<a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://docs.openshift.com/enterprise/3.2/admin_guide/overcommit.html">https://docs.openshift.com/enterprise/3.2/admin_guide/overcommit.html</a></li>
<li>3.10.x 内核 kmem bugs 相关的讨论和解决办法：<ul>
<li><a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://github.com/kubernetes/kubernetes/issues/61937">https://github.com/kubernetes/kubernetes/issues/61937</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://support.mesosphere.com/s/article/Critical-Issue-KMEM-MSPH-2018-0006">https://support.mesosphere.com/s/article/Critical-Issue-KMEM-MSPH-2018-0006</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://pingcap.com/blog/try-to-fix-two-linux-kernel-bugs-while-testing-tidb-operator-in-k8s/">https://pingcap.com/blog/try-to-fix-two-linux-kernel-bugs-while-testing-tidb-operator-in-k8s/</a></li>
</ul>
</li>
</ul>
<h1 id="3、创建CA证书和秘钥"><a href="#3、创建CA证书和秘钥" class="headerlink" title="3、创建CA证书和秘钥"></a>3、创建CA证书和秘钥</h1><p>为确保安全，kubernetes 系统各组件需要使用 x509 证书对通信进行加密和认证。 CA (Certificate Authority) 是自签名的根证书，用来签名后续创建的其它证书。 CA 证书是集群所有节点共享的，只需要创建一次，后续用它签名其它所有证书。 本小节使用 CloudFlare 的 PKI 工具集 cfssl 创建所有证书。</p>
<p>注：如果没有特殊指明，本小节所有操作均在 <strong>Kubernetes-01</strong> 节点上执行。</p>
<p><strong>安装 cfssl 工具集</strong></p>
<p>cfssl github项目地址：<a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://github.com/cloudflare/cfssl">https://github.com/cloudflare/cfssl</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /opt/k8s/cert &amp;&amp; cd /opt/k8s/work</span><br><span class="line"></span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssl_1.4.1_linux_amd64</span><br><span class="line">mv cfssl_1.4.1_linux_amd64 /opt/k8s/bin/cfssl</span><br><span class="line"></span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssljson_1.4.1_linux_amd64</span><br><span class="line">mv cfssljson_1.4.1_linux_amd64 /opt/k8s/bin/cfssljson</span><br><span class="line"></span><br><span class="line">wget https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssl-certinfo_1.4.1_linux_amd64</span><br><span class="line">mv cfssl-certinfo_1.4.1_linux_amd64 /opt/k8s/bin/cfssl-certinfo</span><br><span class="line"></span><br><span class="line">chmod +x /opt/k8s/bin/*</span><br><span class="line">export PATH=/opt/k8s/bin:$PAT</span><br><span class="line">echo &quot;alias cfssl=&#x27;cfssl_linux-amd64&#x27;&quot; &gt;&gt; ~/.bashrc</span><br><span class="line">echo &quot;alias cfssljson=&#x27;cfssljson_linux-amd64&#x27;&quot; &gt;&gt; ~/.bashrc</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><strong>创建配置文件</strong></p>
<p>CA 配置文件用于配置根证书的使用场景 (profile) 和具体参数 (usage，过期时间、服务端认证、客户端认证、加密等)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line"></span><br><span class="line">cat &gt; ca-config.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">        &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>signing：表示该证书可用于签名其它证书（生成的 ca.pem 证书中 CA=TRUE）；</li>
<li>server auth：表示 client 可以用该该证书对 server 提供的证书进行验证；</li>
<li>client auth：表示 server 可以用该该证书对 client 提供的证书进行验证；</li>
<li>“expiry”: “876000h”：证书有效期设置为 100 年；</li>
</ul>
<p><strong>创建证书签名请求文件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cat &gt; ca-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes-ca&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;z0ukun&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;ca&quot;: &#123;</span><br><span class="line">    &quot;expiry&quot;: &quot;876000h&quot;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li><p>CN：Common Name：kube-apiserver 从证书中提取该字段作为请求的用户名 (User Name)，浏览器使用该字段验证网站是否合法；</p>
</li>
<li><p>O：Organization：kube-apiserver 从证书中提取该字段作为请求用户所属的组 (Group)；</p>
</li>
<li><p>kube-apiserver 将提取的 User、Group 作为 RBAC 授权的用户标识；</p>
</li>
<li><pre><code>    &quot;C&quot;: &quot;&lt;country&gt;&quot;,
    &quot;ST&quot;: &quot;&lt;state&gt;&quot;,
    &quot;L&quot;: &quot;&lt;city&gt;&quot;,
    &quot;O&quot;: &quot;&lt;organization&gt;&quot;,
    &quot;OU&quot;: &quot;&lt;organization unit&gt;&quot;
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">注：不同证书 csr 文件的 CN、C、ST、L、O、OU 组合必须不同，否则可能出现 PEER&#39;S CERTIFICATE HAS AN INVALID SIGNATURE 错误；后续创建证书的 csr 文件时，CN 都不相同（C、ST、L、O、OU 相同），以达到区分的目的。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**生成 CA 密钥（&#96;ca-key.pem&#96;）和证书（&#96;ca.pem&#96;）**</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;shell</span><br><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca</span><br><span class="line">ls ca*</span><br><span class="line"></span><br><span class="line"># 查看证书</span><br><span class="line">openssl x509 -noout -text -in ca.pem</span><br><span class="line"># 查看私钥</span><br><span class="line">openssl rsa -noout -text -in ca-key.pem</span><br></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
<p><strong>分发证书文件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p &#x2F;etc&#x2F;kubernetes&#x2F;cert&quot;</span><br><span class="line">    scp ca*.pem ca-config.json root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;kubernetes&#x2F;cert</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<h1 id="4、部署Kubectl工具"><a href="#4、部署Kubectl工具" class="headerlink" title="4、部署Kubectl工具"></a>4、部署Kubectl工具</h1><p>注：本小节介绍安装和配置 kubernetes 命令行管理工具 kubectl 的步骤。本小节只需要部署一次，生成的 kubeconfig 文件是通用的，可以拷贝到需要执行 kubectl 命令的机器的 ~/.kube/config 位置。</p>
<p>注：如果没有特殊指明，本小节所有操作均在 <strong>Kubernetes-01</strong> 节点上执行。</p>
<p><strong>下载Kubectl二进制文件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line"></span><br><span class="line"># 自行解决翻墙下载问题</span><br><span class="line">wget https:&#x2F;&#x2F;dl.k8s.io&#x2F;v1.16.8&#x2F;kubernetes-client-linux-amd64.tar.gz </span><br><span class="line">tar -xzvf kubernetes-client-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>


<p>分发到所有使用 kubectl 工具的节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kubernetes&#x2F;client&#x2F;bin&#x2F;kubectl root@$&#123;node_ip&#125;:&#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;*&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建admin证书和私钥</strong></p>
<p>kubectl 使用 https 协议与 kube-apiserver 进行安全通信，kube-apiserver 对 kubectl 请求包含的证书进行认证和授权。kubectl 后续用于集群管理，所以这里创建具有<strong>最高权限</strong>的 admin 证书。</p>
<p>创建证书签名请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cat &gt; admin-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;z0ukun&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>O: system:masters：kube-apiserver 收到使用该证书的客户端请求后，为请求添加组（Group）认证标识 system:masters；</li>
<li>预定义的 ClusterRoleBinding cluster-admin 将 Group system:masters 与 Role cluster-admin 绑定，该 Role 授予操作集群所需的最高权限；</li>
<li>该证书只会被 kubectl 当做 client 证书使用，所以 hosts 字段为空。</li>
</ul>
<p><strong>生成证书和私钥：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cfssl gencert -ca&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca.pem \</span><br><span class="line">  -ca-key&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-key.pem \</span><br><span class="line">  -config&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-config.json \</span><br><span class="line">  -profile&#x3D;kubernetes admin-csr.json | cfssljson -bare admin</span><br><span class="line">ls admin*</span><br></pre></td></tr></table></figure>
<p>注：忽略警告消息： [WARNING] This certificate lacks a “hosts” field。</p>
<p><strong>创建 kubeconfig 文件</strong></p>
<p>kubectl 使用 kubeconfig 文件访问 apiserver，该文件包含 kube-apiserver 的地址和认证信息（CA 证书和客户端证书）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line"></span><br><span class="line"># 设置集群参数</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;https:&#x2F;&#x2F;$&#123;NODE_IPS[0]&#125;:6443 \</span><br><span class="line">  --kubeconfig&#x3D;kubectl.kubeconfig</span><br><span class="line"></span><br><span class="line"># 设置客户端认证参数</span><br><span class="line">kubectl config set-credentials admin \</span><br><span class="line">  --client-certificate&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;admin.pem \</span><br><span class="line">  --client-key&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;admin-key.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --kubeconfig&#x3D;kubectl.kubeconfig</span><br><span class="line"></span><br><span class="line"># 设置上下文参数</span><br><span class="line">kubectl config set-context kubernetes \</span><br><span class="line">  --cluster&#x3D;kubernetes \</span><br><span class="line">  --user&#x3D;admin \</span><br><span class="line">  --kubeconfig&#x3D;kubectl.kubeconfig</span><br><span class="line"></span><br><span class="line"># 设置默认上下文</span><br><span class="line">kubectl config use-context kubernetes --kubeconfig&#x3D;kubectl.kubeconfig</span><br></pre></td></tr></table></figure>
<ul>
<li>–certificate-authority：验证 kube-apiserver 证书的根证书；</li>
<li>–client-certificate、–client-key：刚生成的 admin 证书和私钥，与 kube-apiserver https 通信时使用；</li>
<li>–embed-certs=true：将 ca.pem 和 admin.pem 证书内容嵌入到生成的 kubectl.kubeconfig 文件中(否则，写入的是证书文件路径，后续拷贝 kubeconfig 到其它机器时，还需要单独拷贝证书文件，不方便。)；</li>
<li>–server：指定 kube-apiserver 的地址，这里指向第一个节点上的服务。</li>
</ul>
<p><strong>分发 kubeconfig 文件</strong></p>
<p>分发到所有使用 kubectl 命令的节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p ~&#x2F;.kube&quot;</span><br><span class="line">    scp kubectl.kubeconfig root@$&#123;node_ip&#125;:~&#x2F;.kube&#x2F;config</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<h1 id="5、部署Etcd集群"><a href="#5、部署Etcd集群" class="headerlink" title="5、部署Etcd集群"></a>5、部署Etcd集群</h1><p>etcd 是基于 Raft 的分布式 KV 存储系统，由 CoreOS 开发，常用于服务发现、共享配置以及并发控制（如 leader 选举、分布式锁等）；kubernetes 使用 etcd 集群持久化存储所有 API 对象、运行数据。</p>
<p>本小节介绍如何部署一个三节点高可用 etcd 集群的步骤：</p>
<ul>
<li>下载和分发 etcd 二进制文件；</li>
<li>创建 etcd 集群各节点的 x509 证书，用于加密客户端(如 etcdctl) 与 etcd 集群、etcd 集群之间的通信；</li>
<li>创建 etcd 的 systemd unit 文件，配置服务参数；</li>
<li>检查集群工作状态；</li>
</ul>
<p>etcd 集群节点名称和 IP 如下：</p>
<ul>
<li>Kubernetes-01：172.16.200.11</li>
<li>Kubernetes-02：172.16.200.12</li>
<li>Kubernetes-03：172.16.200.13</li>
</ul>
<p>注：如果没有特殊指明，本小节所有操作<strong>均在 Kubernetes-01 节点上执行</strong>；需要特别注意 flanneld 与本小节安装的 etcd v3.4.x 不兼容，如果要安装 flanneld（如果网络使用 calio 则不需要修改），则需要将 etcd <strong>降级到 v3.3.x 版本</strong>。</p>
<p><strong>下载etcd二进制文件</strong></p>
<p>etcd下载地址：<a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://github.com/etcd-io/etcd/releases">https://github.com/etcd-io/etcd/releases</a></p>
<p>这里我们为了兼容Flannel网络插件、安装etcd v3.3.20版本。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;coreos&#x2F;etcd&#x2F;releases&#x2F;download&#x2F;v3.3.20&#x2F;etcd-v3.3.20-linux-amd64.tar.gz</span><br><span class="line">tar -xvf etcd-v3.3.20-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>


<p><strong>分发二进制文件到集群所有节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp &#x2F;opt&#x2F;k8s&#x2F;work&#x2F;etcd-v3.3.20-linux-amd64&#x2F;etcd* root@$&#123;node_ip&#125;:&#x2F;opt&#x2F;k8s&#x2F;bin</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;*&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建etcd证书和私钥</strong></p>
<p>创建证书签名请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cat &gt; etcd-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;172.16.200.11&quot;,</span><br><span class="line">    &quot;172.16.200.12&quot;,</span><br><span class="line">    &quot;172.16.200.13&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;z0ukun&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>hosts：指定授权使用该证书的 etcd 节点 IP 列表，需要将 etcd 集群所有节点 IP 都列在其中。</li>
</ul>
<p><strong>生成证书和私钥：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cfssl gencert -ca&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca.pem \</span><br><span class="line">    -ca-key&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-key.pem \</span><br><span class="line">    -config&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-config.json \</span><br><span class="line">    -profile&#x3D;kubernetes etcd-csr.json | cfssljson -bare etcd</span><br><span class="line">ls etcd*pem</span><br></pre></td></tr></table></figure>


<p><strong>分发生成的证书和私钥到各 etcd 节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p &#x2F;etc&#x2F;etcd&#x2F;cert&quot;</span><br><span class="line">    scp etcd*.pem root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;etcd&#x2F;cert&#x2F;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建etcd的systemd unit模板文件</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; etcd.service.template &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line">Documentation=https://github.com/coreos</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">WorkingDirectory=$&#123;ETCD_DATA_DIR&#125;</span><br><span class="line">ExecStart=/opt/k8s/bin/etcd \\</span><br><span class="line">  --data-dir=$&#123;ETCD_DATA_DIR&#125; \\ # 数据目录</span><br><span class="line">  --wal-dir=$&#123;ETCD_WAL_DIR&#125; \\   # 预写日志目录</span><br><span class="line">  --name=##NODE_NAME## \\        # 节点名，这个名字和主机名没关系，可以和主机名不一样</span><br><span class="line">  --cert-file=/etc/etcd/cert/etcd.pem \\    # 公钥，client端连接用</span><br><span class="line">  --key-file=/etc/etcd/cert/etcd-key.pem \\ # 私钥，client端连接用</span><br><span class="line">  --trusted-ca-file=/etc/kubernetes/cert/ca.pem \\  # 可信的CA证书（公钥），client端连接用</span><br><span class="line">  --peer-cert-file=/etc/etcd/cert/etcd.pem \\    # 公钥，etcd节点间用</span><br><span class="line">  --peer-key-file=/etc/etcd/cert/etcd-key.pem \\ # 私钥，etcd节点间用</span><br><span class="line">  --peer-trusted-ca-file=/etc/kubernetes/cert/ca.pem \\ # 可信的CA证书（公钥），etcd节点间用</span><br><span class="line">  --peer-client-cert-auth \\</span><br><span class="line">  --client-cert-auth \\</span><br><span class="line">  --listen-peer-urls=https://##NODE_IP##:2380 \\</span><br><span class="line">  --initial-advertise-peer-urls=https://##NODE_IP##:2380 \\</span><br><span class="line">  --listen-client-urls=https://##NODE_IP##:2379,http://127.0.0.1:2379 \\</span><br><span class="line">  --advertise-client-urls=https://##NODE_IP##:2379 \\</span><br><span class="line">  --initial-cluster-token=etcd-cluster-0 \\</span><br><span class="line">  --initial-cluster=$&#123;ETCD_NODES&#125; \\</span><br><span class="line">  --initial-cluster-state=new \\</span><br><span class="line">  --auto-compaction-mode=periodic \\</span><br><span class="line">  --auto-compaction-retention=1 \\ # 历史数据多长时间压缩一次，1表示1个小时</span><br><span class="line">  --max-request-bytes=33554432 \\  # etcd Raft消息最大字节数，ETCD默认该值为1.5M，官方推荐10M</span><br><span class="line">  --quota-backend-bytes=6442450944 \\ # ETCDdb数据大小，默认是２G,当数据达到２G的时候就不允许写入，必须对历史数据进行压缩才能继续写入，官方推荐8G</span><br><span class="line">  --heartbeat-interval=250 \\ # 心跳间隔时间 (单位 毫秒)，默认: &quot;100&quot;</span><br><span class="line">  --election-timeout=2000     # 选举超时时间(单位 毫秒)，默认: &quot;1000&quot;</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223529225.png" alt="image-20210114223529225"></p>
<ul>
<li>WorkingDirectory、–data-dir：指定工作目录和数据目录为 ${ETCD_DATA_DIR}，需在启动服务前创建这个目录；</li>
<li>–wal-dir：指定 wal 目录，为了提高性能，一般使用 SSD 或者和 –data-dir 不同的磁盘；</li>
<li>–name：指定节点名称，当 –initial-cluster-state 值为 new 时，–name 的参数值必须位于 –initial-cluster 列表中；</li>
<li>–cert-file、–key-file：etcd server 与 client 通信时使用的证书和私钥；</li>
<li>–trusted-ca-file：签名 client 证书的 CA 证书，用于验证 client 证书；</li>
<li>–peer-cert-file、–peer-key-file：etcd 与 peer 通信使用的证书和私钥；</li>
<li>–peer-trusted-ca-file：签名 peer 证书的 CA 证书，用于验证 peer 证书。</li>
</ul>
<p><strong>为各节点创建和分发 etcd systemd unit 文件</strong></p>
<p>替换模板文件中的变量，为各节点创建 systemd unit 文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for (( i&#x3D;0; i &lt; 3; i++ ))</span><br><span class="line">  do</span><br><span class="line">    sed -e &quot;s&#x2F;##NODE_NAME##&#x2F;$&#123;NODE_NAMES[i]&#125;&#x2F;&quot; -e &quot;s&#x2F;##NODE_IP##&#x2F;$&#123;NODE_IPS[i]&#125;&#x2F;&quot; etcd.service.template &gt; etcd-$&#123;NODE_IPS[i]&#125;.service </span><br><span class="line">  done</span><br><span class="line"></span><br><span class="line">ls *.service</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223535568.png" alt="image-20210114223535568"></p>
<ul>
<li>NODE_NAMES 和 NODE_IPS 为相同长度的 bash 数组，分别为节点名称和对应的 IP。</li>
</ul>
<p><strong>分发生成的 systemd unit 文件：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp etcd-$&#123;node_ip&#125;.service root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;etcd.service</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>启动etcd服务</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p $&#123;ETCD_DATA_DIR&#125; $&#123;ETCD_WAL_DIR&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable etcd &amp;&amp; systemctl restart etcd &quot; &amp;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<ul>
<li>切记必须先创建 etcd 数据目录和工作目录;</li>
<li>etcd 进程首次启动时会等待其它节点的 etcd 加入集群，命令 systemctl start etcd 会卡住一段时间，为正常现象。</li>
</ul>
<p><strong>检查启动结果</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status etcd|grep Active&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<p>注：确保状态为 active (running)，否则可以通过 journalctl -u etcd 查看日志，确认原因。</p>
<p><strong>验证服务状态</strong></p>
<p>部署完 etcd 集群后，在任一 etcd 节点上执行如下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;etcdctl \</span><br><span class="line">    --endpoints&#x3D;https:&#x2F;&#x2F;$&#123;node_ip&#125;:2379 \</span><br><span class="line">    --ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;ca.pem \</span><br><span class="line">    --cert-file&#x3D;&#x2F;etc&#x2F;etcd&#x2F;cert&#x2F;etcd.pem \</span><br><span class="line">    --key-file&#x3D;&#x2F;etc&#x2F;etcd&#x2F;cert&#x2F;etcd-key.pem cluster-health</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<ul>
<li>3.4.X 版本的 etcd/etcdctl 默认启用了 V3 API，所以执行 etcdctl 命令时不需要再指定环境变量 ETCDCTL_API=3；</li>
<li>从 K8S 1.13 开始，不再支持 v2 版本的 etcd。</li>
</ul>
<p>预期输出：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223542034.png" alt="image-20210114223542034"></p>
<p>输出均为 healthy 时表示集群服务正常。</p>
<p><strong>查看当前的leader</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">etcdctl --endpoints=https://192.168.10.20:2379 --ca-file=/etc/kubernetes/cert/ca.pem --cert-file=/etc/etcd/cert/etcd.pem --key-file=/etc/etcd/cert/etcd-key.pem member list</span><br></pre></td></tr></table></figure>
<p>输出信息如下：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223548228.png" alt="image-20210114223548228"></p>
<h1 id="6、部署Master集群"><a href="#6、部署Master集群" class="headerlink" title="6、部署Master集群"></a>6、部署Master集群</h1><p>kubernetes master 节点运行如下组件：</p>
<ul>
<li>kube-apiserver</li>
<li>kube-scheduler</li>
<li>kube-controller-manager</li>
</ul>
<p>kube-apiserver、kube-scheduler 和 kube-controller-manager 均以多实例模式运行：</p>
<ul>
<li>kube-scheduler 和 kube-controller-manager 会自动选举产生一个 leader 实例，其它实例处于阻塞模式，当 leader 挂了后，重新选举产生新的 leader，从而保证服务可用性；</li>
<li>kube-apiserver 是无状态的，可以通过 kube-nginx 进行代理访问，从而保证服务可用性；</li>
</ul>
<p>注：如果没有特殊指明，本小节所有操作均在 <strong>Kubernetes-01</strong> 节点上执行。</p>
<p><strong>下载最新版本二进制文件</strong></p>
<p>Kubernetes v1.16.8下载地址：<a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://github.com/kubernetes/kubernetes/tree/v1.16.8">https://github.com/kubernetes/kubernetes/tree/v1.16.8</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 自行解决翻墙问题</span></span><br><span class="line">wget https://dl.k8s.io/v1.16.8/kubernetes-server-linux-amd64.tar.gz  </span><br><span class="line">tar -xzvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">cd kubernetes</span><br><span class="line">tar -xzvf  kubernetes-src.tar.gz</span><br></pre></td></tr></table></figure>


<p><strong>将二进制文件拷贝到所有 master 节点：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kubernetes/server/bin/&#123;apiextensions-apiserver,kube-apiserver,kube-controller-manager,kube-proxy,kube-scheduler,kubeadm,kubectl,kubelet,mounter&#125; root@$&#123;node_ip&#125;:/opt/k8s/bin/</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x /opt/k8s/bin/*&quot;</span><br><span class="line">  done </span><br></pre></td></tr></table></figure>
<h2 id="6-1、APIServer集群"><a href="#6-1、APIServer集群" class="headerlink" title="6.1、APIServer集群"></a>6.1、APIServer集群</h2><p>注：本小节讲解部署一个三实例 kube-apiserver 集群的步骤。如果没有特殊指明，本小节所有操作<strong>均在Kubernetes-01 节点上执行</strong>。</p>
<p><strong>创建 kubernetes-master 证书和私钥</strong></p>
<p>创建证书签名请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">cat &gt; kubernetes-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes-master&quot;,</span><br><span class="line">  &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;172.16.200.11&quot;,</span><br><span class="line">    &quot;172.16.200.12&quot;,</span><br><span class="line">    &quot;172.16.200.13&quot;,</span><br><span class="line">    &quot;$&#123;CLUSTER_KUBERNETES_SVC_IP&#125;&quot;,</span><br><span class="line">    &quot;kubernetes&quot;,</span><br><span class="line">    &quot;kubernetes.default&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc.cluster&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc.cluster.local.&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc.$&#123;CLUSTER_DNS_DOMAIN&#125;.&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;z0ukun&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223602205.png" alt="image-20210114223602205"></p>
<ul>
<li>hosts 字段指定授权使用该证书的 <strong>IP 和域名列表</strong>，这里列出了 master 节点 IP、kubernetes 服务的 IP 和域名；</li>
</ul>
<p><strong>生成证书和私钥：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca.pem \</span><br><span class="line">  -ca-key&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-key.pem \</span><br><span class="line">  -config&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-config.json \</span><br><span class="line">  -profile&#x3D;kubernetes kubernetes-csr.json | cfssljson -bare kubernetes</span><br><span class="line">ls kubernetes*pem</span><br></pre></td></tr></table></figure>


<p><strong>将生成的证书和私钥文件拷贝到所有 master 节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p &#x2F;etc&#x2F;kubernetes&#x2F;cert&quot;</span><br><span class="line">    scp kubernetes*.pem root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建加密配置文件</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; encryption-config.yaml &lt;&lt;EOF</span><br><span class="line">kind: EncryptionConfig</span><br><span class="line">apiVersion: v1</span><br><span class="line">resources:</span><br><span class="line">  - resources:</span><br><span class="line">      - secrets</span><br><span class="line">    providers:</span><br><span class="line">      - aescbc:</span><br><span class="line">          keys:</span><br><span class="line">            - name: key1</span><br><span class="line">              secret: $&#123;ENCRYPTION_KEY&#125;</span><br><span class="line">      - identity: &#123;&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>


<p><strong>将加密配置文件拷贝到所有 master 节点的 /etc/kubernetes 目录下：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp encryption-config.yaml root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;kubernetes&#x2F;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建审计策略文件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">cat &gt; audit-policy.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: audit.k8s.io&#x2F;v1beta1</span><br><span class="line">kind: Policy</span><br><span class="line">rules:</span><br><span class="line">  # The following requests were manually identified as high-volume and low-risk, so drop them.</span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - endpoints</span><br><span class="line">          - services</span><br><span class="line">          - services&#x2F;status</span><br><span class="line">    users:</span><br><span class="line">      - &#39;system:kube-proxy&#39;</span><br><span class="line">    verbs:</span><br><span class="line">      - watch</span><br><span class="line"></span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - nodes</span><br><span class="line">          - nodes&#x2F;status</span><br><span class="line">    userGroups:</span><br><span class="line">      - &#39;system:nodes&#39;</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line"></span><br><span class="line">  - level: None</span><br><span class="line">    namespaces:</span><br><span class="line">      - kube-system</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - endpoints</span><br><span class="line">    users:</span><br><span class="line">      - &#39;system:kube-controller-manager&#39;</span><br><span class="line">      - &#39;system:kube-scheduler&#39;</span><br><span class="line">      - &#39;system:serviceaccount:kube-system:endpoint-controller&#39;</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - update</span><br><span class="line"></span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - namespaces</span><br><span class="line">          - namespaces&#x2F;status</span><br><span class="line">          - namespaces&#x2F;finalize</span><br><span class="line">    users:</span><br><span class="line">      - &#39;system:apiserver&#39;</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line"></span><br><span class="line">  # Don&#39;t log HPA fetching metrics.</span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">      - group: metrics.k8s.io</span><br><span class="line">    users:</span><br><span class="line">      - &#39;system:kube-controller-manager&#39;</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line"></span><br><span class="line">  # Don&#39;t log these read-only URLs.</span><br><span class="line">  - level: None</span><br><span class="line">    nonResourceURLs:</span><br><span class="line">      - &#39;&#x2F;healthz*&#39;</span><br><span class="line">      - &#x2F;version</span><br><span class="line">      - &#39;&#x2F;swagger*&#39;</span><br><span class="line"></span><br><span class="line">  # Don&#39;t log events requests.</span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - events</span><br><span class="line"></span><br><span class="line">  # node and pod status calls from nodes are high-volume and can be large, don&#39;t log responses</span><br><span class="line">  # for expected updates from nodes</span><br><span class="line">  - level: Request</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - nodes&#x2F;status</span><br><span class="line">          - pods&#x2F;status</span><br><span class="line">    users:</span><br><span class="line">      - kubelet</span><br><span class="line">      - &#39;system:node-problem-detector&#39;</span><br><span class="line">      - &#39;system:serviceaccount:kube-system:node-problem-detector&#39;</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">      - patch</span><br><span class="line"></span><br><span class="line">  - level: Request</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - nodes&#x2F;status</span><br><span class="line">          - pods&#x2F;status</span><br><span class="line">    userGroups:</span><br><span class="line">      - &#39;system:nodes&#39;</span><br><span class="line">    verbs:</span><br><span class="line">      - update</span><br><span class="line">      - patch</span><br><span class="line"></span><br><span class="line">  # deletecollection calls can be large, don&#39;t log responses for expected namespace deletions</span><br><span class="line">  - level: Request</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    users:</span><br><span class="line">      - &#39;system:serviceaccount:kube-system:namespace-controller&#39;</span><br><span class="line">    verbs:</span><br><span class="line">      - deletecollection</span><br><span class="line"></span><br><span class="line">  # Secrets, ConfigMaps, and TokenReviews can contain sensitive &amp; binary data,</span><br><span class="line">  # so only log at the Metadata level.</span><br><span class="line">  - level: Metadata</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">        resources:</span><br><span class="line">          - secrets</span><br><span class="line">          - configmaps</span><br><span class="line">      - group: authentication.k8s.io</span><br><span class="line">        resources:</span><br><span class="line">          - tokenreviews</span><br><span class="line">  # Get repsonses can be large; skip them.</span><br><span class="line">  - level: Request</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">      - group: admissionregistration.k8s.io</span><br><span class="line">      - group: apiextensions.k8s.io</span><br><span class="line">      - group: apiregistration.k8s.io</span><br><span class="line">      - group: apps</span><br><span class="line">      - group: authentication.k8s.io</span><br><span class="line">      - group: authorization.k8s.io</span><br><span class="line">      - group: autoscaling</span><br><span class="line">      - group: batch</span><br><span class="line">      - group: certificates.k8s.io</span><br><span class="line">      - group: extensions</span><br><span class="line">      - group: metrics.k8s.io</span><br><span class="line">      - group: networking.k8s.io</span><br><span class="line">      - group: policy</span><br><span class="line">      - group: rbac.authorization.k8s.io</span><br><span class="line">      - group: scheduling.k8s.io</span><br><span class="line">      - group: settings.k8s.io</span><br><span class="line">      - group: storage.k8s.io</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line"></span><br><span class="line">  # Default level for known APIs</span><br><span class="line">  - level: RequestResponse</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">    resources:</span><br><span class="line">      - group: &quot;&quot;</span><br><span class="line">      - group: admissionregistration.k8s.io</span><br><span class="line">      - group: apiextensions.k8s.io</span><br><span class="line">      - group: apiregistration.k8s.io</span><br><span class="line">      - group: apps</span><br><span class="line">      - group: authentication.k8s.io</span><br><span class="line">      - group: authorization.k8s.io</span><br><span class="line">      - group: autoscaling</span><br><span class="line">      - group: batch</span><br><span class="line">      - group: certificates.k8s.io</span><br><span class="line">      - group: extensions</span><br><span class="line">      - group: metrics.k8s.io</span><br><span class="line">      - group: networking.k8s.io</span><br><span class="line">      - group: policy</span><br><span class="line">      - group: rbac.authorization.k8s.io</span><br><span class="line">      - group: scheduling.k8s.io</span><br><span class="line">      - group: settings.k8s.io</span><br><span class="line">      - group: storage.k8s.io</span><br><span class="line">      </span><br><span class="line">  # Default level for all other requests.</span><br><span class="line">  - level: Metadata</span><br><span class="line">    omitStages:</span><br><span class="line">      - RequestReceived</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>


<p><strong>分发审计策略文件：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp audit-policy.yaml root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;kubernetes&#x2F;audit-policy.yaml</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建后续访问 metrics-server 或 kube-prometheus 使用的证书</strong></p>
<p>创建证书签名请求:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">cat &gt; proxy-client-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;aggregator&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;z0ukun&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>CN 名称需要位于 kube-apiserver 的 –requestheader-allowed-names 参数中，否则后续访问 metrics 时会提示权限不足，在配置 kube-apiserver  的 systems unit 文件时，注意这点</li>
</ul>
<p><strong>生成证书和私钥：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;ca.pem \</span><br><span class="line">  -ca-key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;ca-key.pem  \</span><br><span class="line">  -config&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;ca-config.json  \</span><br><span class="line">  -profile&#x3D;kubernetes proxy-client-csr.json | cfssljson -bare proxy-client</span><br><span class="line">ls proxy-client*.pem</span><br></pre></td></tr></table></figure>


<p><strong>将生成的证书和私钥文件拷贝到所有 master 节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp proxy-client*.pem root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建 kube-apiserver systemd unit 模板文件</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; kube-apiserver.service.template &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=$&#123;K8S_DIR&#125;/kube-apiserver</span><br><span class="line">ExecStart=/opt/k8s/bin/kube-apiserver \\</span><br><span class="line">  --advertise-address=##NODE_IP## \\ </span><br><span class="line">  --default-not-ready-toleration-seconds=360 \\</span><br><span class="line">  --default-unreachable-toleration-seconds=360 \\</span><br><span class="line">  --feature-gates=DynamicAuditing=true \\</span><br><span class="line">  --max-mutating-requests-inflight=2000 \\</span><br><span class="line">  --max-requests-inflight=4000 \\</span><br><span class="line">  --default-watch-cache-size=200 \\</span><br><span class="line">  --delete-collection-workers=2 \\</span><br><span class="line">  --encryption-provider-config=/etc/kubernetes/encryption-config.yaml \\</span><br><span class="line">  --etcd-cafile=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --etcd-certfile=/etc/kubernetes/cert/kubernetes.pem \\</span><br><span class="line">  --etcd-keyfile=/etc/kubernetes/cert/kubernetes-key.pem \\</span><br><span class="line">  --etcd-servers=$&#123;ETCD_ENDPOINTS&#125; \\</span><br><span class="line">  --bind-address=##NODE_IP## \\</span><br><span class="line">  --secure-port=6443 \\</span><br><span class="line">  --tls-cert-file=/etc/kubernetes/cert/kubernetes.pem \\</span><br><span class="line">  --tls-private-key-file=/etc/kubernetes/cert/kubernetes-key.pem \\</span><br><span class="line">  --insecure-port=0 \\</span><br><span class="line">  --audit-dynamic-configuration \\</span><br><span class="line">  --audit-log-maxage=15 \\</span><br><span class="line">  --audit-log-maxbackup=3 \\</span><br><span class="line">  --audit-log-maxsize=100 \\</span><br><span class="line">  --audit-log-truncate-enabled \\</span><br><span class="line">  --audit-log-path=$&#123;K8S_DIR&#125;/kube-apiserver/audit.log \\</span><br><span class="line">  --audit-policy-file=/etc/kubernetes/audit-policy.yaml \\</span><br><span class="line">  --profiling \\</span><br><span class="line">  --anonymous-auth=false \\</span><br><span class="line">  --client-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --enable-bootstrap-token-auth \\</span><br><span class="line">  --requestheader-allowed-names=&quot;aggregator&quot; \\</span><br><span class="line">  --requestheader-client-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --requestheader-extra-headers-prefix=&quot;X-Remote-Extra-&quot; \\</span><br><span class="line">  --requestheader-group-headers=X-Remote-Group \\</span><br><span class="line">  --requestheader-username-headers=X-Remote-User \\</span><br><span class="line">  --service-account-key-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --authorization-mode=Node,RBAC \\</span><br><span class="line">  --runtime-config=api/all=true \\</span><br><span class="line">  --enable-admission-plugins=NodeRestriction \\</span><br><span class="line">  --allow-privileged=true \\</span><br><span class="line">  --apiserver-count=3 \\</span><br><span class="line">  --event-ttl=168h \\</span><br><span class="line">  --kubelet-certificate-authority=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --kubelet-client-certificate=/etc/kubernetes/cert/kubernetes.pem \\</span><br><span class="line">  --kubelet-client-key=/etc/kubernetes/cert/kubernetes-key.pem \\</span><br><span class="line">  --kubelet-https=true \\</span><br><span class="line">  --kubelet-timeout=10s \\</span><br><span class="line">  --proxy-client-cert-file=/etc/kubernetes/cert/proxy-client.pem \\</span><br><span class="line">  --proxy-client-key-file=/etc/kubernetes/cert/proxy-client-key.pem \\</span><br><span class="line">  --service-cluster-ip-range=$&#123;SERVICE_CIDR&#125; \\</span><br><span class="line">  --service-node-port-range=$&#123;NODE_PORT_RANGE&#125; \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">--advertise-address：向集群成员通知 apiserver 消息的 IP 地址。这个地址必须能够被集群中其他成员访问。如果 IP 地址为空，将会使用 --bind-address，如果未指定 --bind-address，将会使用主机的默认接口地址。</span><br><span class="line"></span><br><span class="line">--default-not-ready-toleration-seconds：表示 `notReady` 状态的容忍度秒数：默认情况下，`NoExecute` 被添加到尚未具有此容忍度的每个 Pod 中。</span><br><span class="line"></span><br><span class="line">--default-unreachable-toleration-seconds：表示 `unreachable` 状态的容忍度秒数：默认情况下，`NoExecute` 被添加到尚未具有此容忍度的每个 Pod 中。</span><br><span class="line"></span><br><span class="line">--feature-gates：一个描述 alpha/experimental 特性开关的键值对列表</span><br><span class="line"></span><br><span class="line">--max-mutating-requests-inflight：在给定时间内进行中可变请求的最大数量。当超过该值时，服务将拒绝所有请求。0 值表示没有限制。（默认值 200）</span><br><span class="line"></span><br><span class="line">--max-requests-inflight：在给定时间内进行中不可变请求的最大数量。当超过该值时，服务将拒绝所有请求。0 值表示没有限制。（默认值 400）</span><br><span class="line"></span><br><span class="line">--default-watch-cache-size：默认监视缓存大小。如果为零，则对未设置默认监视大小的资源禁用监视缓存。</span><br><span class="line"></span><br><span class="line">--delete-collection-workers：用于 DeleteCollection 调用的工作者数量。这被用于加速 namespace 的清理。( 默认值 1)</span><br><span class="line"></span><br><span class="line">--encryption-provider-config：包含用于在etcd中存储secret 的encryption providers的配置文件</span><br><span class="line"></span><br><span class="line">--etcd-*：访问 etcd 的证书和 etcd 服务器地址；</span><br><span class="line"></span><br><span class="line">--bind-address： https 监听的 IP，不能为 127.0.0.1，否则外界不能访问它的安全端口 6443；</span><br><span class="line"></span><br><span class="line">--secret-port：https 监听端口；</span><br><span class="line"></span><br><span class="line">--tls-*-file：指定 apiserver 使用的证书、私钥和 CA 文件；</span><br><span class="line"></span><br><span class="line">--insecure-port=0：关闭监听 http 非安全端口(8080)；</span><br><span class="line"></span><br><span class="line">--audit-dynamic-configuration：启用动态审计配置</span><br><span class="line"></span><br><span class="line">--audit-*：配置审计策略和审计日志文件相关的参数；</span><br><span class="line"></span><br><span class="line">--profiling：在 web 接口 host:port/debug/pprof/ 上启用 profiling。（默认值 true）</span><br><span class="line"> </span><br><span class="line">-anonymous-auth：启用到 API server 的安全端口的匿名请求。未被其他认证方法拒绝的请求被当做匿名请求。匿名请求的用户名为 system:anonymous，用户组名为 system:unauthenticated。（默认值 true）</span><br><span class="line"></span><br><span class="line">--client-ca-file：验证客户端请求证书的根证书文件</span><br><span class="line"></span><br><span class="line">--enable-bootstrap-token-auth：启用 kubelet bootstrap 的 token 认证；</span><br><span class="line"></span><br><span class="line">--requestheader-allowed-names：使用 --requestheader-username-headers 指定的，允许在头部提供用户名的客户端证书通用名称列表。如果为空，任何通过 --requestheader-client-ca-file 中 authorities 验证的客户端证书都是被允许的。</span><br><span class="line"></span><br><span class="line">--requestheader-*：kube-apiserver 的 aggregator layer 相关的配置参数，proxy-client &amp; HPA 需要使用；</span><br><span class="line"></span><br><span class="line">--service-account-key-file：签名 ServiceAccount Token 的公钥文件，kube-controller-manager 的 --service-account-private-key-file 指定私钥文件，两者配对使用；</span><br><span class="line"></span><br><span class="line">--authorization-mode：在安全端口上进行权限验证的插件的顺序列表。以逗号分隔的列表，包括：AlwaysAllow,AlwaysDeny,ABAC,Webhook,RBAC,Node.（默认值 &quot;AlwaysAllow&quot;）</span><br><span class="line"></span><br><span class="line">--runtime-config=api/all=true： 启用所有版本的 APIs，如 autoscaling/v2alpha1；</span><br><span class="line"></span><br><span class="line">--enable-admission-plugins：启用一些默认关闭的 plugins；</span><br><span class="line"></span><br><span class="line">--allow-privileged：运行执行 privileged 权限的容器；</span><br><span class="line"></span><br><span class="line">--apiserver-count=3：指定 apiserver 实例的数量；</span><br><span class="line"></span><br><span class="line">--event-ttl：指定 events 的保存时间；</span><br><span class="line"></span><br><span class="line">--kubelet-*：如果指定，则使用 https 访问 kubelet APIs；需要为证书对应的用户(上面 kubernetes*.pem 证书的用户为 kubernetes) 用户定义 RBAC 规则，否则访问 kubelet API 时提示未授权；</span><br><span class="line"></span><br><span class="line">--proxy-client-*：apiserver 访问 metrics-server 使用的证书；</span><br><span class="line"></span><br><span class="line">--service-cluster-ip-range： 指定 Service Cluster IP 地址段；</span><br><span class="line"></span><br><span class="line">--service-node-port-range： 指定 NodePort 的端口范围；</span><br><span class="line"></span><br><span class="line">--logtostderr：日志输出到 stderr 而不是文件中</span><br><span class="line"></span><br><span class="line">--v=2：指定输出日志的日志详细级别</span><br></pre></td></tr></table></figure>
<p>注：如果 kube-apiserver 机器没有运行 kube-proxy，则还需要添加 –enable-aggregator-routing=true 参数；</p>
<p>关于 –requestheader-XXX 相关参数，参考：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://github.com/kubernetes-incubator/apiserver-builder/blob/master/docs/concepts/auth.md">https://github.com/kubernetes-incubator/apiserver-builder/blob/master/docs/concepts/auth.md</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://docs.bitnami.com/kubernetes/how-to/configure-autoscaling-custom-metrics/">https://docs.bitnami.com/kubernetes/how-to/configure-autoscaling-custom-metrics/</a></li>
</ul>
<p>注： –requestheader-client-ca-file 指定的 CA 证书，必须具有 client auth and server auth； 如果 –requestheader-allowed-names 不为空,且 –proxy-client-cert-file 证书的 CN 名称不在 allowed-names 中，则后续查看 node 或 pods 的 metrics 失败</p>
<p><strong>为各节点创建和分发 kube-apiserver systemd unit 文件</strong></p>
<p>替换模板文件中的变量，为各节点生成 systemd unit 文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for (( i&#x3D;0; i &lt; 3; i++ ))</span><br><span class="line">  do</span><br><span class="line">    sed -e &quot;s&#x2F;##NODE_NAME##&#x2F;$&#123;NODE_NAMES[i]&#125;&#x2F;&quot; -e &quot;s&#x2F;##NODE_IP##&#x2F;$&#123;NODE_IPS[i]&#125;&#x2F;&quot; kube-apiserver.service.template &gt; kube-apiserver-$&#123;NODE_IPS[i]&#125;.service </span><br><span class="line">  done</span><br><span class="line">ls kube-apiserver*.service</span><br></pre></td></tr></table></figure>
<ul>
<li>NODE_NAMES 和 NODE_IPS 为相同长度的 bash 数组，分别为节点名称和对应的 IP；</li>
</ul>
<p><strong>分发生成的 systemd unit 文件：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-apiserver-$&#123;node_ip&#125;.service root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;kube-apiserver.service</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>启动 kube-apiserver 服务</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p $&#123;K8S_DIR&#125;&#x2F;kube-apiserver&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kube-apiserver &amp;&amp; systemctl restart kube-apiserver&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>检查 kube-apiserver 运行状态</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status kube-apiserver |grep &#39;Active:&#39;&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>检查集群状态</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 查看集群信息</span><br><span class="line">kubectl cluster-info</span><br><span class="line"></span><br><span class="line"># 查看所有的命令空间</span><br><span class="line">kubectl get all --all-namespaces</span><br><span class="line"></span><br><span class="line"># 查看组件状态</span><br><span class="line">kubectl get componentstatuses</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223615014.png" alt="image-20210114223615014"></p>
<p>注：原作者说：<strong>Kubernetes 1.16.8 存在 Bugs 导致返回结果一直为 <unknown>，但 kubectl get cs -o yaml 可以返回正确结果</strong>。</p>
<p>我查阅了相关资料发现、正确的解释如下：在k8s.io/kubernetes/pkg/registry/core/componentstatus/rest.go中，没有实现rest.TableConvertor接口，所以componentStatuses的handler的RequestScope中的TableConvertor字段就为空，最终导致了问题。详细流程和问题点大家可以参考下面的文章</p>
<p><strong>如果希望打印和原来类似的内容，目前只有通过下面的模板来打印：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get cs -o&#x3D;go-template&#x3D;&#39;&#123;&#123;printf &quot;|NAME|STATUS|MESSAGE|\n&quot;&#125;&#125;&#123;&#123;range .items&#125;&#125;&#123;&#123;$name :&#x3D; .metadata.name&#125;&#125;&#123;&#123;range .conditions&#125;&#125;&#123;&#123;printf &quot;|%s|%s|%s|\n&quot; $name .status .message&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#39;</span><br></pre></td></tr></table></figure>
<p>参考文章：<a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://zhongpan.tech/2019/10/30/018-output-change-kubectl-get-cs/">https://zhongpan.tech/2019/10/30/018-output-change-kubectl-get-cs/</a></p>
<p>Github Issue：<a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://github.com/kubernetes/kubernetes/issues/83024">https://github.com/kubernetes/kubernetes/issues/83024</a></p>
<p><strong>检查 kube-apiserver 监听的端口</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo netstat -lnpt|grep kube</span><br></pre></td></tr></table></figure>
<ul>
<li>6443: 接收 https 请求的安全端口，对所有请求做认证和授权；</li>
<li>由于关闭了非安全端口，故没有监听 8080；</li>
</ul>
<h2 id="6-2、Controller-Manager集群"><a href="#6-2、Controller-Manager集群" class="headerlink" title="6.2、Controller-Manager集群"></a>6.2、Controller-Manager集群</h2><p>本小节介绍部署高可用 kube-controller-manager 集群的步骤。该集群包含 3 个节点，启动后将通过竞争选举机制产生一个 leader 节点，其它节点为阻塞状态。当 leader 节点不可用时，阻塞的节点将再次进行选举产生新的 leader 节点，从而保证服务的可用性。</p>
<p>为保证通信安全，本文档先生成 x509 证书和私钥，kube-controller-manager 在如下两种情况下使用该证书：</p>
<ol>
<li>与 kube-apiserver 的安全端口通信;</li>
<li>在<strong>安全端口</strong>(https，10252) 输出 prometheus 格式的 metrics；</li>
</ol>
<p>注：如果没有特殊指明，本小节的所有操作均在 <strong>Kubernetes-01</strong> 节点上执行。</p>
<p><strong>创建 kube-controller-manager 证书和私钥</strong></p>
<p>创建证书签名请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cat &gt; kube-controller-manager-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">      &quot;127.0.0.1&quot;,</span><br><span class="line">      &quot;172.16.200.11&quot;,</span><br><span class="line">      &quot;172.16.200.12&quot;,</span><br><span class="line">      &quot;172.16.200.13&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">        &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">        &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">        &quot;O&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">        &quot;OU&quot;: &quot;z0ukun&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>hosts 列表包含<strong>所有</strong> kube-controller-manager 节点 IP；</li>
<li>CN 和 O 均为 system:kube-controller-manager，kubernetes 内置的 ClusterRoleBindings system:kube-controller-manager 赋予 kube-controller-manager 工作所需的权限。</li>
</ul>
<p><strong>生成证书和私钥：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cfssl gencert -ca&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca.pem \</span><br><span class="line">  -ca-key&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-key.pem \</span><br><span class="line">  -config&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-config.json \</span><br><span class="line">  -profile&#x3D;kubernetes kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager</span><br><span class="line">ls kube-controller-manager*pem</span><br></pre></td></tr></table></figure>


<p><strong>将生成的证书和私钥分发到所有 master 节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-controller-manager*.pem root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建和分发 kubeconfig 文件</strong></p>
<p>kube-controller-manager 使用 kubeconfig 文件访问 apiserver，该文件提供了 apiserver 地址、嵌入的 CA 证书和 kube-controller-manager 证书等信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;&quot;https:&#x2F;&#x2F;##NODE_IP##:6443&quot; \</span><br><span class="line">  --kubeconfig&#x3D;kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager \</span><br><span class="line">  --client-certificate&#x3D;kube-controller-manager.pem \</span><br><span class="line">  --client-key&#x3D;kube-controller-manager-key.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --kubeconfig&#x3D;kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-controller-manager \</span><br><span class="line">  --cluster&#x3D;kubernetes \</span><br><span class="line">  --user&#x3D;system:kube-controller-manager \</span><br><span class="line">  --kubeconfig&#x3D;kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-controller-manager --kubeconfig&#x3D;kube-controller-manager.kubeconfig</span><br></pre></td></tr></table></figure>
<ul>
<li>kube-controller-manager 与 kube-apiserver 混布，故直接通过<strong>节点 IP</strong> 访问 kube-apiserver。</li>
</ul>
<p><strong>分发 kubeconfig 到所有 master 节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    sed -e &quot;s&#x2F;##NODE_IP##&#x2F;$&#123;node_ip&#125;&#x2F;&quot; kube-controller-manager.kubeconfig &gt; kube-controller-manager-$&#123;node_ip&#125;.kubeconfig</span><br><span class="line">    scp kube-controller-manager-$&#123;node_ip&#125;.kubeconfig root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;kubernetes&#x2F;kube-controller-manager.kubeconfig</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建 kube-controller-manager systemd unit 模板文件</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/k8s/work</span><br><span class="line">source /opt/k8s/bin/environment.sh</span><br><span class="line">cat &gt; kube-controller-manager.service.template &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=$&#123;K8S_DIR&#125;/kube-controller-manager</span><br><span class="line">ExecStart=/opt/k8s/bin/kube-controller-manager \\</span><br><span class="line">  --profiling \\</span><br><span class="line">  --cluster-name=kubernetes \\</span><br><span class="line">  --controllers=*,bootstrapsigner,tokencleaner \\</span><br><span class="line">  --kube-api-qps=1000 \\</span><br><span class="line">  --kube-api-burst=2000 \\</span><br><span class="line">  --leader-elect \\</span><br><span class="line">  --use-service-account-credentials\\</span><br><span class="line">  --concurrent-service-syncs=2 \\</span><br><span class="line">  --bind-address=##NODE_IP## \\</span><br><span class="line">  --secure-port=10252 \\</span><br><span class="line">  --tls-cert-file=/etc/kubernetes/cert/kube-controller-manager.pem \\</span><br><span class="line">  --tls-private-key-file=/etc/kubernetes/cert/kube-controller-manager-key.pem \\</span><br><span class="line">  --port=0 \\</span><br><span class="line">  --authentication-kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\</span><br><span class="line">  --client-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --requestheader-allowed-names=&quot;aggregator&quot; \\</span><br><span class="line">  --requestheader-client-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --requestheader-extra-headers-prefix=&quot;X-Remote-Extra-&quot; \\</span><br><span class="line">  --requestheader-group-headers=X-Remote-Group \\</span><br><span class="line">  --requestheader-username-headers=X-Remote-User \\</span><br><span class="line">  --authorization-kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\</span><br><span class="line">  --cluster-signing-cert-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --cluster-signing-key-file=/etc/kubernetes/cert/ca-key.pem \\</span><br><span class="line">  --experimental-cluster-signing-duration=876000h \\</span><br><span class="line">  --horizontal-pod-autoscaler-sync-period=10s \\</span><br><span class="line">  --concurrent-deployment-syncs=10 \\</span><br><span class="line">  --concurrent-gc-syncs=30 \\</span><br><span class="line">  --node-cidr-mask-size=24 \\</span><br><span class="line">  --service-cluster-ip-range=$&#123;SERVICE_CIDR&#125; \\</span><br><span class="line">  --pod-eviction-timeout=6m \\</span><br><span class="line">  --terminated-pod-gc-threshold=10000 \\</span><br><span class="line">  --root-ca-file=/etc/kubernetes/cert/ca.pem \\</span><br><span class="line">  --service-account-private-key-file=/etc/kubernetes/cert/ca-key.pem \\</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">--profiling：通过位于 host:port/debug/pprof/ 的 Web 接口启用性能分析</span><br><span class="line"></span><br><span class="line">--cluster-name：默认值：&quot;kubernetes&quot;，集群实例的前缀</span><br><span class="line"></span><br><span class="line">--controllers：要启用的控制器列表。* 表示启用所有默认启用的控制器；foo 启用名为 foo 的控制器；-foo 表示禁用名为 foo 的控制器。</span><br><span class="line"></span><br><span class="line">--kube-api-qps：与 API 服务器通信时每秒请求数（QPS）限制</span><br><span class="line"></span><br><span class="line">--kube-api-burst：与 Kubernetes API 服务器通信时突发峰值请求个数上限</span><br><span class="line"></span><br><span class="line">--leader-elect：在执行主循环之前，启动领导选举（Leader Election）客户端，并尝试获得领导者身份。在运行多副本组件时启用此标志有助于提高可用性。</span><br><span class="line"></span><br><span class="line">--use-service-account-credentials：当此标志为 true 时，为每个控制器单独使用服务账号凭据</span><br><span class="line"></span><br><span class="line">--concurrent-service-syncs：可以并发同步的 Service 对象个数。数值越大，服务管理的响应速度越快，不过对 CPU （和网络）的占用也越高。</span><br><span class="line"> </span><br><span class="line">--bind-address：针对 --secure-port 端口上请求执行监听操作的 IP 地址。所对应的网络接口必须从集群中其它位置可访问（含命令行及 Web 客户端）。如果此值为空或者设定为非特定地址（0.0.0.0 或 ::），意味着所有网络接口都在监听范围。</span><br><span class="line"></span><br><span class="line">--secure-port：在此端口上提供 HTTPS 身份认证和鉴权操作。若此标志值为0，则不提供 HTTPS 服务。</span><br><span class="line"></span><br><span class="line">--tls-*-file：包含 HTTPS 所用的默认 X509 证书的文件</span><br><span class="line"></span><br><span class="line">--port：用于服务不安全，未经身份验证的访问的端口。设置为0禁用。 （默认值为10252）</span><br><span class="line"></span><br><span class="line">--authentication-kubeconfig：kube-controller-manager 使用它连接 apiserver，对 client 的请求进行认证和授权。kube-controller-manager 不再使用 --tls-ca-file 对请求 https metrics 的 Client 证书进行校验。如果没有配置这两个 kubeconfig 参数，则 client 连接 kube-controller-manager https 端口的请求会被拒绝(提示权限不足)</span><br><span class="line"></span><br><span class="line">--cluster-signing-*-file：签名 TLS Bootstrap 创建的证书；</span><br><span class="line"></span><br><span class="line">--experimental-cluster-signing-duration：所签署的证书的有效期时长。</span><br><span class="line"></span><br><span class="line">--horizontal-pod-autoscaler-sync-period：水平 Pod 扩缩器对 Pods 数目执行同步操作的周期</span><br><span class="line"></span><br><span class="line">--concurrent-deployment-syncs：可以并发同步的 Deployment 对象个数。数值越大意味着对 Deployment 的响应越及时，同时也意味着更大的 CPU（和网络带宽）压力。</span><br><span class="line"></span><br><span class="line">--concurrent-gc-syncs：可以并发同步的垃圾收集工作线程个数</span><br><span class="line"></span><br><span class="line">--node-cidr-mask-size：集群中节点 CIDR 的掩码长度。对 IPv4 而言默认为 24；对 IPv6 而言默认为 64</span><br><span class="line"></span><br><span class="line">--service-cluster-ip-range：集群中 Service 对象的 CIDR 范围。要求 --allocate-node-cidrs 标志为 true</span><br><span class="line"></span><br><span class="line">--pod-eviction-timeout：在失效的节点上删除 Pods 时为其预留的宽限期</span><br><span class="line"></span><br><span class="line"> --terminated-pod-gc-threshold：在已终止 Pods 垃圾收集器删除已终止 Pods 之前，可以保留的已删除 Pods 的个数上限。若此值小于等于 0，则相当于禁止垃圾回收已终止的 Pods。</span><br><span class="line"></span><br><span class="line">--root-ca-file：放置到容器 ServiceAccount 中的 CA 证书，用来对 kube-apiserver 的证书进行校验；</span><br><span class="line"></span><br><span class="line">--service-account-private-key-file：签名 ServiceAccount 中 Token 的私钥文件，必须和 kube-apiserver 的 --service-account-key-file 指定的公钥文件配对使用；</span><br></pre></td></tr></table></figure>


<p><strong>为各节点创建和分发 kube-controller-mananger systemd unit 文件</strong></p>
<p>替换模板文件中的变量，为各节点创建 systemd unit 文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for (( i&#x3D;0; i &lt; 3; i++ ))</span><br><span class="line">  do</span><br><span class="line">    sed -e &quot;s&#x2F;##NODE_NAME##&#x2F;$&#123;NODE_NAMES[i]&#125;&#x2F;&quot; -e &quot;s&#x2F;##NODE_IP##&#x2F;$&#123;NODE_IPS[i]&#125;&#x2F;&quot; kube-controller-manager.service.template &gt; kube-controller-manager-$&#123;NODE_IPS[i]&#125;.service </span><br><span class="line">  done</span><br><span class="line"></span><br><span class="line">ls kube-controller-manager*.service</span><br></pre></td></tr></table></figure>


<p><strong>分发到所有 master 节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-controller-manager-$&#123;node_ip&#125;.service root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;kube-controller-manager.service</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>启动 kube-controller-manager 服务</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p $&#123;K8S_DIR&#125;&#x2F;kube-controller-manager&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kube-controller-manager &amp;&amp; systemctl restart kube-controller-manager&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>检查服务运行状态</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status kube-controller-manager|grep Active&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p>kube-controller-manager 监听 10252 端口，接收 https 请求：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223626361.png" alt="image-20210114223626361"></p>
<p><strong>查看输出的 metrics</strong></p>
<p>下面的命令在 kube-controller-manager 节点上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s --cacert &#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca.pem --cert &#x2F;opt&#x2F;k8s&#x2F;work&#x2F;admin.pem --key &#x2F;opt&#x2F;k8s&#x2F;work&#x2F;admin-key.pem https:&#x2F;&#x2F;$(hostname -I | awk &#39;&#123;print $1&#125;&#39;):10252&#x2F;metrics |head</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223634689.png" alt="image-20210114223634689"></p>
<p><strong>查看当前的 leader</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get endpoints kube-controller-manager --namespace&#x3D;kube-system  -o yaml</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223640108.png" alt="image-20210114223640108">可见，当前的 leader 为 Kubernetes-01 节点。</p>
<p><strong>测试 kube-controller-manager 集群的高可用</strong></p>
<p>停掉一个或两个节点的 kube-controller-manager 服务，观察其它节点的日志，看是否获取了 leader 权限。</p>
<ul>
<li>关于 controller 权限和 use-service-account-credentials 参数：<a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://github.com/kubernetes/kubernetes/issues/48208">https://github.com/kubernetes/kubernetes/issues/48208</a></li>
<li>kubelet 认证和授权：<a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubelet-authorization">https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubelet-authorization</a></li>
</ul>
<h2 id="6-3、Scheduler集群"><a href="#6-3、Scheduler集群" class="headerlink" title="6.3、Scheduler集群"></a>6.3、Scheduler集群</h2><p>本小节介绍部署高可用 kube-scheduler 集群的步骤。该集群包含 3 个节点，启动后将通过竞争选举机制产生一个 leader 节点，其它节点为阻塞状态。当 leader 节点不可用后，剩余节点将再次进行选举产生新的 leader 节点，从而保证服务的可用性。为保证通信安全，本文档先生成 x509 证书和私钥，kube-scheduler 在如下两种情况下使用该证书：</p>
<ul>
<li>与 kube-apiserver 的安全端口通信;</li>
<li>在<strong>安全端口</strong>(https，10251) 输出 prometheus 格式的 metrics；</li>
</ul>
<p>注：如果没有特殊指明，本小节的所有操作<strong>均在 Kubernetes-01 节点上执行</strong>。</p>
<p><strong>创建 kube-scheduler 证书和私钥</strong></p>
<p>创建证书签名请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cat &gt; kube-scheduler-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">      &quot;127.0.0.1&quot;,</span><br><span class="line">      &quot;172.16.200.11&quot;,</span><br><span class="line">      &quot;172.16.200.12&quot;,</span><br><span class="line">      &quot;172.16.200.13&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">        &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">        &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">        &quot;O&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">        &quot;OU&quot;: &quot;z0ukun&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>hosts 列表包含<strong>所有</strong> kube-scheduler 节点 IP；</li>
<li>CN 和 O 均为 system:kube-scheduler，kubernetes 内置的 ClusterRoleBindings system:kube-scheduler 将赋予 kube-scheduler 工作所需的权限；</li>
</ul>
<p><strong>生成证书和私钥：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cfssl gencert -ca&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca.pem \</span><br><span class="line">  -ca-key&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-key.pem \</span><br><span class="line">  -config&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-config.json \</span><br><span class="line">  -profile&#x3D;kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler</span><br><span class="line"></span><br><span class="line">ls kube-scheduler*pem</span><br></pre></td></tr></table></figure>


<p><strong>将生成的证书和私钥分发到所有 master 节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-scheduler*.pem root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建和分发 kubeconfig 文件</strong></p>
<p>kube-scheduler 使用 kubeconfig 文件访问 apiserver，该文件提供了 apiserver 地址、嵌入的 CA 证书和 kube-scheduler 证书：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --server&#x3D;&quot;https:&#x2F;&#x2F;##NODE_IP##:6443&quot; \</span><br><span class="line">  --kubeconfig&#x3D;kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-scheduler \</span><br><span class="line">  --client-certificate&#x3D;kube-scheduler.pem \</span><br><span class="line">  --client-key&#x3D;kube-scheduler-key.pem \</span><br><span class="line">  --embed-certs&#x3D;true \</span><br><span class="line">  --kubeconfig&#x3D;kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-scheduler \</span><br><span class="line">  --cluster&#x3D;kubernetes \</span><br><span class="line">  --user&#x3D;system:kube-scheduler \</span><br><span class="line">  --kubeconfig&#x3D;kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-scheduler --kubeconfig&#x3D;kube-scheduler.kubeconfig</span><br></pre></td></tr></table></figure>


<p><strong>分发 kubeconfig 到所有 master 节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    sed -e &quot;s&#x2F;##NODE_IP##&#x2F;$&#123;node_ip&#125;&#x2F;&quot; kube-scheduler.kubeconfig &gt; kube-scheduler-$&#123;node_ip&#125;.kubeconfig</span><br><span class="line">    scp kube-scheduler-$&#123;node_ip&#125;.kubeconfig root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;kubernetes&#x2F;kube-scheduler.kubeconfig</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建 kube-scheduler 配置文件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cat &gt;kube-scheduler.yaml.template &lt;&lt;EOF</span><br><span class="line">apiVersion: kubescheduler.config.k8s.io&#x2F;v1alpha1</span><br><span class="line">kind: KubeSchedulerConfiguration</span><br><span class="line">bindTimeoutSeconds: 600</span><br><span class="line">clientConnection:</span><br><span class="line">  burst: 200</span><br><span class="line">  kubeconfig: &quot;&#x2F;etc&#x2F;kubernetes&#x2F;kube-scheduler.kubeconfig&quot;</span><br><span class="line">  qps: 100</span><br><span class="line">enableContentionProfiling: false</span><br><span class="line">enableProfiling: true</span><br><span class="line">hardPodAffinitySymmetricWeight: 1</span><br><span class="line">healthzBindAddress: ##NODE_IP##:10251</span><br><span class="line">leaderElection:</span><br><span class="line">  leaderElect: true</span><br><span class="line">metricsBindAddress: ##NODE_IP##:10251</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>–kubeconfig：指定 kubeconfig 文件路径，kube-scheduler 使用它连接和验证 kube-apiserver；</li>
<li>–leader-elect=true：集群运行模式，启用选举功能；被选为 leader 的节点负责处理工作，其它节点为阻塞状态；</li>
</ul>
<p><strong>替换模板文件中的变量：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for (( i&#x3D;0; i &lt; 3; i++ ))</span><br><span class="line">  do</span><br><span class="line">    sed -e &quot;s&#x2F;##NODE_NAME##&#x2F;$&#123;NODE_NAMES[i]&#125;&#x2F;&quot; -e &quot;s&#x2F;##NODE_IP##&#x2F;$&#123;NODE_IPS[i]&#125;&#x2F;&quot; kube-scheduler.yaml.template &gt; kube-scheduler-$&#123;NODE_IPS[i]&#125;.yaml</span><br><span class="line">  done</span><br><span class="line"></span><br><span class="line">ls kube-scheduler*.yaml</span><br></pre></td></tr></table></figure>
<ul>
<li>NODE_NAMES 和 NODE_IPS 为相同长度的 bash 数组，分别为节点名称和对应的 IP；</li>
</ul>
<p><strong>分发 kube-scheduler 配置文件到所有 master 节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-scheduler-$&#123;node_ip&#125;.yaml root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;kubernetes&#x2F;kube-scheduler.yaml</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<ul>
<li>重命名为 kube-scheduler.yaml;</li>
</ul>
<p><strong>创建 kube-scheduler systemd unit 模板文件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">cat &gt; kube-scheduler.service.template &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Kubernetes Scheduler</span><br><span class="line">Documentation&#x3D;https:&#x2F;&#x2F;github.com&#x2F;GoogleCloudPlatform&#x2F;kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory&#x3D;$&#123;K8S_DIR&#125;&#x2F;kube-scheduler</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;kube-scheduler \\</span><br><span class="line">  --config&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;kube-scheduler.yaml \\</span><br><span class="line">  --bind-address&#x3D;##NODE_IP## \\</span><br><span class="line">  --secure-port&#x3D;10259 \\</span><br><span class="line">  --port&#x3D;0 \\</span><br><span class="line">  --tls-cert-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;kube-scheduler.pem \\</span><br><span class="line">  --tls-private-key-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;kube-scheduler-key.pem \\</span><br><span class="line">  --authentication-kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;kube-scheduler.kubeconfig \\</span><br><span class="line">  --client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;ca.pem \\</span><br><span class="line">  --requestheader-allowed-names&#x3D;&quot;&quot; \\</span><br><span class="line">  --requestheader-client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;ca.pem \\</span><br><span class="line">  --requestheader-extra-headers-prefix&#x3D;&quot;X-Remote-Extra-&quot; \\</span><br><span class="line">  --requestheader-group-headers&#x3D;X-Remote-Group \\</span><br><span class="line">  --requestheader-username-headers&#x3D;X-Remote-User \\</span><br><span class="line">  --authorization-kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;kube-scheduler.kubeconfig \\</span><br><span class="line">  --logtostderr&#x3D;true \\</span><br><span class="line">  --v&#x3D;2</span><br><span class="line">Restart&#x3D;always</span><br><span class="line">RestartSec&#x3D;5</span><br><span class="line">StartLimitInterval&#x3D;0</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>


<p><strong>为各节点创建和分发 kube-scheduler systemd unit 文件</strong></p>
<p>替换模板文件中的变量，为各节点创建 systemd unit 文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for (( i&#x3D;0; i &lt; 3; i++ ))</span><br><span class="line">  do</span><br><span class="line">    sed -e &quot;s&#x2F;##NODE_NAME##&#x2F;$&#123;NODE_NAMES[i]&#125;&#x2F;&quot; -e &quot;s&#x2F;##NODE_IP##&#x2F;$&#123;NODE_IPS[i]&#125;&#x2F;&quot; kube-scheduler.service.template &gt; kube-scheduler-$&#123;NODE_IPS[i]&#125;.service </span><br><span class="line">  done</span><br><span class="line"></span><br><span class="line">ls kube-scheduler*.service</span><br></pre></td></tr></table></figure>


<p><strong>分发 systemd unit 文件到所有 master 节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp kube-scheduler-$&#123;node_ip&#125;.service root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;kube-scheduler.service</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>启动 kube-scheduler 服务</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p $&#123;K8S_DIR&#125;&#x2F;kube-scheduler&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable kube-scheduler &amp;&amp; systemctl restart kube-scheduler&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>检查服务运行状态</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status kube-scheduler|grep Active&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>查看输出的 metrics</strong></p>
<p>注：以下命令在 kube-scheduler 节点上执行。</p>
<p>kube-scheduler 监听 10251 和 10259 端口：</p>
<ul>
<li>10251：接收 http 请求，非安全端口，不需要认证授权；</li>
<li>10259：接收 https 请求，安全端口，需要认证授权；</li>
</ul>
<p>两个接口都对外提供 /metrics 和 /healthz 的访问。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s http:&#x2F;&#x2F;192.168.10.20:10251&#x2F;metrics |head</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223651605.png" alt="image-20210114223651605"> </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s --cacert /opt/k8s/work/ca.pem --cert /opt/k8s/work/admin.pem --key /opt/k8s/work/admin-key.pem https://192.168.10.20:10259/metrics |head</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223656926.png" alt="image-20210114223656926"></p>
<p><strong>查看当前的 leader</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get endpoints kube-scheduler --namespace&#x3D;kube-system  -o yaml</span><br></pre></td></tr></table></figure>


<p><strong>测试 kube-scheduler 集群的高可用</strong></p>
<p>随便找一个或两个 master 节点，停掉 kube-scheduler 服务，看其它节点是否获取了 leader 权限。</p>
<h1 id="7、部署Flannel网络"><a href="#7、部署Flannel网络" class="headerlink" title="7、部署Flannel网络"></a>7、部署Flannel网络</h1><p>注：切记在开始部署Worker集群之前、我们需要先去部署Flannel网络和Docker。</p>
<p>kubernetes 要求集群内各节点(包括 master 节点)能通过 Pod 网段互联互通。flannel 使用 vxlan 技术为各节点创建一个可以互通的 Pod 网络，使用的端口为 UDP 8472（需要开放该端口，如公有云 AWS 等）。</p>
<p>flanneld 第一次启动时，从 etcd 获取配置的 Pod 网段信息，为本节点分配一个未使用的地址段，然后创建 flannedl.1 网络接口（也可能是其它名称，如 flannel1 等）。 flannel 将分配给自己的 Pod 网段信息写入 /run/flannel/docker 文件，docker 后续使用这个文件中的环境变量设置 docker0 网桥，从而从这个地址段为本节点的所有 Pod 容器分配 IP。</p>
<ul>
<li>flanneld 与本文档部署的 etcd v3.4.x 不兼容，需要将 etcd 降级到 v3.3.x；</li>
<li>flanneld 与 docker 结合使用；</li>
</ul>
<p><strong>注：</strong> 如果没有特殊指明，本小节的所有操作均在 Kubernetes-01 节点上执行，然后远程分发文件和执行命令；</p>
<p><strong>下载Flanneld二进制文件</strong></p>
<p>Flanneld下载地址：<a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://github.com/coreos/flannel/releases">https://github.com/coreos/flannel/releases</a></p>
<p>我们从上面的 Flanneld下载地址 下载安装包（这里我们安装flannel-v0.11.0）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">mkdir flannel</span><br><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;coreos&#x2F;flannel&#x2F;releases&#x2F;download&#x2F;v0.11.0&#x2F;flannel-v0.11.0-linux-amd64.tar.gz</span><br><span class="line">tar -xzvf flannel-v0.11.0-linux-amd64.tar.gz -C flannel</span><br></pre></td></tr></table></figure>


<p><strong>分发二进制文件到集群所有节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp flannel&#x2F;&#123;flanneld,mk-docker-opts.sh&#125; root@$&#123;node_ip&#125;:&#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;*&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223704848.png" alt="image-20210114223704848"></p>
<p><strong>创建Flannel证书和私钥</strong></p>
<p>flanneld 从 etcd 集群存取网段分配信息，而 etcd 集群启用了双向 x509 证书认证，所以需要为 flanneld 生成证书和私钥。创建证书签名请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cat &gt; flanneld-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;flanneld&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;4Paradigm&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>该证书只会被 kubectl 当做 client 证书使用，所以 hosts 字段为空。</li>
</ul>
<p><strong>生成证书和私钥：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca.pem \</span><br><span class="line">  -ca-key&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-key.pem \</span><br><span class="line">  -config&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca-config.json \</span><br><span class="line">  -profile&#x3D;kubernetes flanneld-csr.json | cfssljson -bare flanneld</span><br><span class="line"></span><br><span class="line">ls flanneld*pem</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223710782.png" alt="image-20210114223710782"></p>
<p>将生成的证书和私钥分发到<strong>所有节点</strong>（master 和 worker）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p &#x2F;etc&#x2F;flanneld&#x2F;cert&quot;</span><br><span class="line">    scp flanneld*.pem root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;flanneld&#x2F;cert</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223718385.png" alt="image-20210114223718385"></p>
<p><strong>向etcd写入集群Pod网段信息（本步骤只需执行一次）</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">ETCDCTL_API&#x3D;2 etcdctl \</span><br><span class="line">  --endpoints&#x3D;$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">  --ca-file&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;ca.pem \</span><br><span class="line">  --cert-file&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;flanneld.pem \</span><br><span class="line">  --key-file&#x3D;&#x2F;opt&#x2F;k8s&#x2F;work&#x2F;flanneld-key.pem \</span><br><span class="line">  mk $&#123;FLANNEL_ETCD_PREFIX&#125;&#x2F;config &#39;&#123;&quot;Network&quot;:&quot;&#39;$&#123;CLUSTER_CIDR&#125;&#39;&quot;, &quot;SubnetLen&quot;: 24, &quot;Backend&quot;: &#123;&quot;Type&quot;: &quot;vxlan&quot;&#125;&#125;&#39;</span><br></pre></td></tr></table></figure>
<ul>
<li>flanneld 当前版本 (v0.11.0) 不支持 etcd v3，故使用 etcd v2 API 写入配置 key 和网段数据；</li>
<li>写入的 Pod 网段 ${CLUSTER_CIDR} 地址段（如 /16）必须小于 SubnetLen，必须与 kube-controller-manager 的 –cluster-cidr 参数值一致；</li>
</ul>
<p>注：这里是Flannel网络部署的最大坑点、如果是v0.11.0版本在执行此命令之前一定要在前面加上 ETCDCTL_API=2 强制使用ETCD V2版本。</p>
<p><strong>创建 flanneld 的 systemd unit 文件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">cat &gt; flanneld.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Flanneld overlay address etcd agent</span><br><span class="line">After&#x3D;network.target</span><br><span class="line">After&#x3D;network-online.target</span><br><span class="line">Wants&#x3D;network-online.target</span><br><span class="line">After&#x3D;etcd.service</span><br><span class="line">Before&#x3D;docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type&#x3D;notify</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;flanneld \\</span><br><span class="line">  -etcd-cafile&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;cert&#x2F;ca.pem \\</span><br><span class="line">  -etcd-certfile&#x3D;&#x2F;etc&#x2F;flanneld&#x2F;cert&#x2F;flanneld.pem \\</span><br><span class="line">  -etcd-keyfile&#x3D;&#x2F;etc&#x2F;flanneld&#x2F;cert&#x2F;flanneld-key.pem \\</span><br><span class="line">  -etcd-endpoints&#x3D;$&#123;ETCD_ENDPOINTS&#125; \\</span><br><span class="line">  -etcd-prefix&#x3D;$&#123;FLANNEL_ETCD_PREFIX&#125; \\</span><br><span class="line">  -iface&#x3D;$&#123;IFACE&#125; \\</span><br><span class="line">  -ip-masq</span><br><span class="line">ExecStartPost&#x3D;&#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d &#x2F;run&#x2F;flannel&#x2F;docker</span><br><span class="line">Restart&#x3D;always</span><br><span class="line">RestartSec&#x3D;5</span><br><span class="line">StartLimitInterval&#x3D;0</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br><span class="line">RequiredBy&#x3D;docker.service</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>mk-docker-opts.sh 脚本将分配给 flanneld 的 Pod 子网段信息写入 /run/flannel/docker 文件，后续 docker 启动时使用这个文件中的环境变量配置 docker0 网桥；</li>
<li>flanneld 使用系统缺省路由所在的接口与其它节点通信，对于有多个网络接口（如内网和公网）的节点，可以用 -iface 参数指定通信接口;</li>
<li>flanneld 运行时需要 root 权限；</li>
<li>-ip-masq: flanneld 为访问 Pod 网络外的流量设置 SNAT 规则，同时将传递给 Docker 的变量 –ip-masq（/run/flannel/docker 文件中）设置为 false，这样 Docker 将不再创建 SNAT 规则； Docker 的 –ip-masq 为 true 时，创建的 SNAT 规则比较“暴力”：将所有本节点 Pod 发起的、访问非 docker0 接口的请求做 SNAT，这样访问其他节点 Pod 的请求来源 IP 会被设置为 flannel.1 接口的 IP，导致目的 Pod 看不到真实的来源 Pod IP。 flanneld 创建的 SNAT 规则比较温和，只对访问非 Pod 网段的请求做 SNAT。</li>
</ul>
<p><strong>分发 flanneld systemd unit 文件到所有节点</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp flanneld.service root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>启动 flanneld 服务</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable flanneld &amp;&amp; systemctl restart flanneld&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>检查启动结果</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status flanneld|grep Active&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<p>确保状态为 active (running)，否则可以通过 journalctl -u flanneld 命令查看日志，确认原因。</p>
<p><strong>检查分配给各 flanneld 的 Pod 网段信息</strong></p>
<p>查看集群 Pod 网段(/16)：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223725868.png" alt="image-20210114223725868"></p>
<p>查看已分配的 Pod 子网段列表(/24):</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223730344.png" alt="image-20210114223730344"></p>
<p>查看某一 Pod 网段对应的节点 IP 和 flannel 接口地址:</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223735935.png" alt="image-20210114223735935"></p>
<ul>
<li>172.30.41.0/24 被分配给节点 Kubernetes-03（172.16.200.13）；</li>
<li>VtepMAC 为 Kubernetes-03 节点的 flannel.1 网卡 MAC 地址；</li>
</ul>
<p><strong>检查节点 flannel 网络信息</strong></p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223741291.png" alt="image-20210114223741291"></p>
<p>flannel.1 网卡的地址为分配的 Pod 子网段的第一个 IP（.0），且是 /32 的地址；</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223746506.png" alt="image-20210114223746506"></p>
<ul>
<li>到其它节点 Pod 网段请求都被转发到 flannel.1 网卡；</li>
<li>flanneld 根据 etcd 中子网段的信息，如 ${FLANNEL_ETCD_PREFIX}/subnets/172.30.42.0-24 ，来决定进请求发送给哪个节点的互联 IP；</li>
</ul>
<p><strong>验证各节点能否通过Pod网络互通</strong></p>
<p>在<strong>各节点上部署</strong> flannel 后，检查是否创建了 flannel 接口(名称可能为 flannel0、flannel.0、flannel.1 等)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh $&#123;node_ip&#125; &quot;&#x2F;usr&#x2F;sbin&#x2F;ip addr show flannel.1|grep -w inet&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223752844.png" alt="image-20210114223752844"></p>
<p><strong>在各节点上 ping 所有 flannel 接口 IP，确保能通：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh $&#123;node_ip&#125; &quot;ping -c 1 172.30.41.0&quot;</span><br><span class="line">    ssh $&#123;node_ip&#125; &quot;ping -c 1 172.30.42.0&quot;</span><br><span class="line">    ssh $&#123;node_ip&#125; &quot;ping -c 1 172.30.62.0&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223758350.png" alt="image-20210114223758350"></p>
<h1 id="8、部署Docker"><a href="#8、部署Docker" class="headerlink" title="8、部署Docker"></a>8、部署Docker</h1><p>docker 运行和管理容器，kubelet 通过 Container Runtime Interface (CRI) 与它进行交互。</p>
<p>注：在开始部署Docker之前一定要记得提前部署Flannel网络；如果没有特殊指明，本小节的所有操作<strong>均在 Kubernetes-01 节点上执行</strong>，然后远程分发文件和执行命令；如果之前安装过Docker的相关版本、记得一定要把Docker提前卸载干净。</p>
<p>Docker卸载命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 查询已安装的Docker版本</span><br><span class="line">rpm -qa | grep docker</span><br><span class="line"></span><br><span class="line"># 卸载已安装的Docker版本</span><br><span class="line">yum remove -y *** </span><br><span class="line"></span><br><span class="line"># 重启主机</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure>


<p><strong>安装依赖包</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;yum install -y epel-release&quot; &amp;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;yum install -y chrony conntrack ipvsadm ipset jq iptables curl sysstat libseccomp wget socat git&quot; &amp;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>下载Docker二进制文件：</strong></p>
<p>Docker下载地址：<a target="_blank" rel="noopener" href="https://blog.z0ukun.com/wp-content/themes/begin4.6/inc/go.php?url=https://download.docker.com/linux/static/stable/x86_64/">https://download.docker.com/linux/static/stable/x86_64/</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">wget https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;static&#x2F;stable&#x2F;x86_64&#x2F;docker-18.09.6.tgz</span><br><span class="line">tar -xvf docker-18.09.6.tgz</span><br></pre></td></tr></table></figure>


<p><strong>分发Docker二进制文件到所有的Worker节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp docker&#x2F;*  root@$&#123;node_ip&#125;:&#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;chmod +x &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;*&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>创建和分发 systemd unit 文件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">cat &gt; docker.service &lt;&lt;&quot;EOF&quot;</span><br><span class="line">[Unit]</span><br><span class="line">Description&#x3D;Docker Application Container Engine</span><br><span class="line">Documentation&#x3D;http:&#x2F;&#x2F;docs.docker.io</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory&#x3D;##DOCKER_DIR##</span><br><span class="line">Environment&#x3D;&quot;PATH&#x3D;&#x2F;opt&#x2F;k8s&#x2F;bin:&#x2F;bin:&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;usr&#x2F;sbin&quot;</span><br><span class="line">EnvironmentFile&#x3D;-&#x2F;run&#x2F;flannel&#x2F;docker</span><br><span class="line">ExecStart&#x3D;&#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;dockerd $DOCKER_NETWORK_OPTIONS</span><br><span class="line">ExecReload&#x3D;&#x2F;bin&#x2F;kill -s HUP $MAINPID</span><br><span class="line">Restart&#x3D;on-failure</span><br><span class="line">RestartSec&#x3D;5</span><br><span class="line">LimitNOFILE&#x3D;infinity</span><br><span class="line">LimitNPROC&#x3D;infinity</span><br><span class="line">LimitCORE&#x3D;infinity</span><br><span class="line">Delegate&#x3D;yes</span><br><span class="line">KillMode&#x3D;process</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>EOF 前后有双引号，这样 bash 不会替换文档中的变量，如 $DOCKER_NETWORK_OPTIONS (这些环境变量是 systemd 负责替换的。)；</li>
<li>dockerd 运行时会调用其它 docker 命令，如 docker-proxy，所以需要将 docker 命令所在的目录加到 PATH 环境变量中；</li>
<li>flanneld 启动时将网络配置写入 /run/flannel/docker 文件中，dockerd 启动前读取该文件中的环境变量 DOCKER_NETWORK_OPTIONS ，然后设置 docker0 网桥网段； 如果指定了多个 EnvironmentFile 选项，则必须将 /run/flannel/docker 放在最后(确保 docker0 使用 flanneld 生成的 bip 参数)；</li>
<li>docker 需要以 root 用于运行；</li>
<li>docker 从 1.13 版本开始，可能将 iptables FORWARD chain的默认策略设置为DROP，从而导致 ping 其它 Node 上的 Pod IP 失败，遇到这种情况时，需要手动设置策略为 ACCEPT：sudo iptables -P FORWARD ACCEPT；并且把以下命令写入 /etc/rc.local 文件中，防止节点重启iptables FORWARD chain的默认策略又还原为DROP：/sbin/iptables -P FORWARD ACCEPT</li>
</ul>
<p><strong>分发 systemd unit 文件到所有 worker 机器:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">sed -i -e &quot;s|##DOCKER_DIR##|$&#123;DOCKER_DIR&#125;|&quot; docker.service</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    scp docker.service root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>配置和分发 docker 配置文件</strong></p>
<p>使用国内的仓库镜像服务器以加快 pull image 的速度，同时增加下载的并发数 (需要重启 dockerd 生效)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">cat &gt; docker-daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;registry-mirrors&quot;: [&quot;https:&#x2F;&#x2F;docker.mirrors.ustc.edu.cn&quot;,&quot;https:&#x2F;&#x2F;hub-mirror.c.163.com&quot;],</span><br><span class="line">    &quot;insecure-registries&quot;: [&quot;docker02:35000&quot;],</span><br><span class="line">    &quot;max-concurrent-downloads&quot;: 20,</span><br><span class="line">    &quot;live-restore&quot;: true,</span><br><span class="line">    &quot;max-concurrent-uploads&quot;: 10,</span><br><span class="line">    &quot;debug&quot;: true,</span><br><span class="line">    &quot;data-root&quot;: &quot;$&#123;DOCKER_DIR&#125;&#x2F;data&quot;,</span><br><span class="line">    &quot;exec-root&quot;: &quot;$&#123;DOCKER_DIR&#125;&#x2F;exec&quot;,</span><br><span class="line">    &quot;log-opts&quot;: &#123;</span><br><span class="line">      &quot;max-size&quot;: &quot;100m&quot;,</span><br><span class="line">      &quot;max-file&quot;: &quot;5&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>


<p><strong>分发 docker 配置文件到所有 worker 节点：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;k8s&#x2F;work</span><br><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;mkdir -p  &#x2F;etc&#x2F;docker&#x2F; $&#123;DOCKER_DIR&#125;&#x2F;&#123;data,exec&#125;&quot;</span><br><span class="line">    scp docker-daemon.json root@$&#123;node_ip&#125;:&#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>启动 docker 服务</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl daemon-reload &amp;&amp; systemctl enable docker &amp;&amp; systemctl restart docker&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>


<p><strong>检查服务运行状态</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;systemctl status docker|grep Active&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223807089.png" alt="image-20210114223807089"></p>
<p>确保状态为 active (running)，否则可以通过 journalctl -u docker 查看日志，确认原因。</p>
<p><strong>检查 docker0 网桥</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;opt&#x2F;k8s&#x2F;bin&#x2F;environment.sh</span><br><span class="line">for node_ip in $&#123;NODE_IPS[@]&#125;</span><br><span class="line">  do</span><br><span class="line">    echo &quot;&gt;&gt;&gt; $&#123;node_ip&#125;&quot;</span><br><span class="line">    ssh root@$&#123;node_ip&#125; &quot;&#x2F;usr&#x2F;sbin&#x2F;ip addr show flannel.1 &amp;&amp; &#x2F;usr&#x2F;sbin&#x2F;ip addr show docker0&quot;</span><br><span class="line">  done</span><br></pre></td></tr></table></figure>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223813082.png" alt="image-20210114223813082"></p>
<p>确认各 worker 节点的 docker0 网桥和 flannel.1 接口的 IP 处于同一个网段中(如下 172.30.42.0/32 位于 172.30.42.1/24 中)：</p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223818702.png" alt="image-20210114223818702"></p>
<p>注: 如果你的服务安装顺序不对或者机器环境比较复杂, docker服务早于flanneld服务安装，此时 worker 节点的 docker0 网桥和 flannel.1 接口的 IP可能不会同处同一个网段下，这个时候请先停止docker服务, 手工删除docker0网卡，重新启动docker服务后即可修复:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop docker</span><br><span class="line">ip link delete docker0</span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure>


<p><strong>查看 docker 的状态信息</strong></p>
<p><img src="https://image-1303893285.cos.ap-shanghai.myqcloud.com/image/image-20210114223823825.png" alt="image-20210114223823825"></p>
<p><strong>更新 kubelet 配置并重启服务（每个节点上都操作）</strong></p>
<p>需要删除 kubelet 的 systemd unit 文件(/etc/systemd/system/kubelet.service)，删除下面 4 行（若有）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--network-plugin&#x3D;cni \\</span><br><span class="line">--cni-conf-dir&#x3D;&#x2F;etc&#x2F;cni&#x2F;net.d \\</span><br><span class="line">--container-runtime&#x3D;remote \\</span><br><span class="line">--container-runtime-endpoint&#x3D;unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;containerd&#x2F;containerd.sock \\</span><br></pre></td></tr></table></figure>


<p><strong>然后重启 kubelet 服务：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure>


<h1 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h1><h2 id="1、kubeconfig是什么"><a href="#1、kubeconfig是什么" class="headerlink" title="1、kubeconfig是什么"></a>1、kubeconfig是什么</h2><p>上述配置过程中，kubectl，controller-manager都配置了kubeconfig。</p>
<p>kubeconfig文件是一个文件，用于配置与kubectl命令行工具（或其他客户端）一起使用时对Kubernetes的访问。</p>
<h2 id="2、调度器扩展程序"><a href="#2、调度器扩展程序" class="headerlink" title="2、调度器扩展程序"></a>2、调度器扩展程序</h2><p>上述，scheduler集群配置过程中，出现了 创建scheduler配置文件这步。这实际上是配置了调度器扩展程序。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;kube-scheduler.yaml.template &lt;&lt;EOF</span><br><span class="line">apiVersion: kubescheduler.config.k8s.io/v1alpha1</span><br><span class="line">kind: KubeSchedulerConfiguration</span><br><span class="line">bindTimeoutSeconds: 600</span><br><span class="line">clientConnection:</span><br><span class="line">  burst: 200</span><br><span class="line">  kubeconfig: &quot;/etc/kubernetes/kube-scheduler.kubeconfig&quot;</span><br><span class="line">  qps: 100</span><br><span class="line">enableContentionProfiling: false</span><br><span class="line">enableProfiling: true</span><br><span class="line">hardPodAffinitySymmetricWeight: 1</span><br><span class="line">healthzBindAddress: ##NODE_IP##:10251</span><br><span class="line">leaderElection:</span><br><span class="line">  leaderElect: true</span><br><span class="line">metricsBindAddress: ##NODE_IP##:10251</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://www.qikqiak.com/post/custom-kube-scheduler/">自定义 Kubernetes 调度器</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://heavyfish.github.io/2020/11/03/k8s/Kubernetes%20in%20Action%20%E7%AC%94%E8%AE%B0%2012~13/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/heavyfish.github.io/images/avatar.gif">
      <meta itemprop="name" content="Shenxr">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="速查笔记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/heavyfish.github.io/2020/11/03/k8s/Kubernetes%20in%20Action%20%E7%AC%94%E8%AE%B0%2012~13/" class="post-title-link" itemprop="url">Kubernetes in Action 12～13</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-03 17:13:12" itemprop="dateCreated datePublished" datetime="2020-11-03T17:13:12+08:00">2020-11-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-14 22:49:47" itemprop="dateModified" datetime="2021-01-14T22:49:47+08:00">2021-01-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/heavyfish.github.io/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="12、Kubernetes-API服务器的安全防护"><a href="#12、Kubernetes-API服务器的安全防护" class="headerlink" title="12、Kubernetes API服务器的安全防护"></a>12、Kubernetes API服务器的安全防护</h1><h2 id="12-1、了解认证机制"><a href="#12-1、了解认证机制" class="headerlink" title="12.1、了解认证机制"></a>12.1、了解认证机制</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104131845611.png" alt="image-20201104131845611" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104131929879.png" alt="image-20201104131929879" style="zoom:50%;" />

<h3 id="12-1-1、用户和组"><a href="#12-1-1、用户和组" class="headerlink" title="12.1.1、用户和组"></a>12.1.1、用户和组</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104132128364.png" alt="image-20201104132128364" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104132146600.png" alt="image-20201104132146600" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104132220038.png" alt="image-20201104132220038" style="zoom:50%;" />

<h3 id="12-1-2、ServiceAccount介绍"><a href="#12-1-2、ServiceAccount介绍" class="headerlink" title="12.1.2、ServiceAccount介绍"></a>12.1.2、ServiceAccount介绍</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104132529083.png" alt="image-20201104132529083" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104132645545.png" alt="image-20201104132645545" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104132737769.png" alt="image-20201104132737769" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104132836173.png" alt="image-20201104132836173" style="zoom:50%;" />

<h3 id="12-1-3、创建-ServiceAccount"><a href="#12-1-3、创建-ServiceAccount" class="headerlink" title="12.1.3、创建 ServiceAccount"></a>12.1.3、创建 ServiceAccount</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104133046865.png" alt="image-20201104133046865" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104133149824.png" alt="image-20201104133149824" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104133239985.png" alt="image-20201104133239985" style="zoom:50%;" />

<h3 id="12-1-4、将ServiceAccount分配给Pod"><a href="#12-1-4、将ServiceAccount分配给Pod" class="headerlink" title="12.1.4、将ServiceAccount分配给Pod"></a>12.1.4、将ServiceAccount分配给Pod</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104133337912.png" alt="image-20201104133337912" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104133428658.png" alt="image-20201104133428658" style="zoom:50%;" />

<h2 id="12-2、通过基于角色的权限控制加强集群安全"><a href="#12-2、通过基于角色的权限控制加强集群安全" class="headerlink" title="12.2、通过基于角色的权限控制加强集群安全"></a>12.2、通过基于角色的权限控制加强集群安全</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104133758323.png" alt="image-20201104133758323" style="zoom:50%;" />

<h3 id="12-2-1、介绍RBAC授权插件"><a href="#12-2-1、介绍RBAC授权插件" class="headerlink" title="12.2.1、介绍RBAC授权插件"></a>12.2.1、介绍RBAC授权插件</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104133950402.png" alt="image-20201104133950402" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104134057918.png" alt="image-20201104134057918" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104134126712.png" alt="image-20201104134126712" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104134218896.png" alt="image-20201104134218896" style="zoom:50%;" />

<h3 id="12-2-2、介绍RBAC资源"><a href="#12-2-2、介绍RBAC资源" class="headerlink" title="12.2.2、介绍RBAC资源"></a>12.2.2、介绍RBAC资源</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104134347791.png" alt="image-20201104134347791" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104134454450.png" alt="image-20201104134454450" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104134752325.png" alt="image-20201104134752325" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104134813090.png" alt="image-20201104134813090" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104134952715.png" alt="image-20201104134952715" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104135018848.png" alt="image-20201104135018848" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104135207135.png" alt="image-20201104135207135" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104135341404.png" alt="image-20201104135341404" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104135356711.png" alt="image-20201104135356711" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104135447828.png" alt="image-20201104135447828" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104135642475.png" alt="image-20201104135642475" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104135707836.png" alt="image-20201104135707836" style="zoom:50%;" />

<h3 id="12-2-4、使用-ClusterRole-和-ClusterRoleBinding"><a href="#12-2-4、使用-ClusterRole-和-ClusterRoleBinding" class="headerlink" title="12.2.4、使用 ClusterRole 和 ClusterRoleBinding"></a>12.2.4、使用 ClusterRole 和 ClusterRoleBinding</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104140039239.png" alt="image-20201104140039239" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104140101442.png" alt="image-20201104140101442" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104140227728.png" alt="image-20201104140227728" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104140444533.png" alt="image-20201104140444533" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104141013227.png" alt="image-20201104141013227" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104140612627.png" alt="image-20201104140612627" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104140708219.png" alt="image-20201104140708219" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104140733032.png" alt="image-20201104140733032" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104141033244.png" alt="image-20201104141033244" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104141106711.png" alt="image-20201104141106711" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104141157039.png" alt="image-20201104141157039" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104141226513.png" alt="image-20201104141226513" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104141244577.png" alt="image-20201104141244577" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104141325922.png" alt="image-20201104141325922" style="zoom:50%;" />

<h3 id="12-2-5、了解默认的-ClusterRole-和-ClusterRoleBinding"><a href="#12-2-5、了解默认的-ClusterRole-和-ClusterRoleBinding" class="headerlink" title="12.2.5、了解默认的 ClusterRole 和 ClusterRoleBinding"></a>12.2.5、了解默认的 ClusterRole 和 ClusterRoleBinding</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104141839900.png" alt="image-20201104141839900" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104141941991.png" alt="image-20201104141941991" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104142149981.png" alt="image-20201104142149981" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104142213987.png" alt="image-20201104142213987" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104142247685.png" alt="image-20201104142247685" style="zoom:50%;" />

<h2 id="12-3、本章小结"><a href="#12-3、本章小结" class="headerlink" title="12.3、本章小结"></a>12.3、本章小结</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201104142320349.png" alt="image-20201104142320349" style="zoom:50%;" />


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://heavyfish.github.io/2020/11/02/k8s/Kubernetes%20in%20Action%20%E7%AC%94%E8%AE%B010~11/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/heavyfish.github.io/images/avatar.gif">
      <meta itemprop="name" content="Shenxr">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="速查笔记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/heavyfish.github.io/2020/11/02/k8s/Kubernetes%20in%20Action%20%E7%AC%94%E8%AE%B010~11/" class="post-title-link" itemprop="url">Kubernetes in Action 10～11</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-02 12:27:55" itemprop="dateCreated datePublished" datetime="2020-11-02T12:27:55+08:00">2020-11-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-14 22:49:39" itemprop="dateModified" datetime="2021-01-14T22:49:39+08:00">2021-01-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/heavyfish.github.io/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="10、StatefulSet：部署有状态的多副本应用"><a href="#10、StatefulSet：部署有状态的多副本应用" class="headerlink" title="10、StatefulSet：部署有状态的多副本应用"></a>10、StatefulSet：部署有状态的多副本应用</h1><h2 id="10-1、复制有状态Pod"><a href="#10-1、复制有状态Pod" class="headerlink" title="10.1、复制有状态Pod"></a>10.1、复制有状态Pod</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102164413172.png" alt="image-20201102164413172" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102164528277.png" alt="image-20201102164528277" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102164915594.png" alt="image-20201102164915594" style="zoom:50%;" />

<h2 id="10-2、了解Statefulset"><a href="#10-2、了解Statefulset" class="headerlink" title="10.2、了解Statefulset"></a>10.2、了解Statefulset</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102165041089.png" alt="image-20201102165041089" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102165118926.png" alt="image-20201102165118926" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102165341321.png" alt="image-20201102165341321" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102165417185.png" alt="image-20201102165417185" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102165502143.png" alt="image-20201102165502143" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102165555279.png" alt="image-20201102165555279" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102165705335.png" alt="image-20201102165705335" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102165808180.png" alt="image-20201102165808180" style="zoom:50%;" />

<h2 id="10-3、使用Statefulset"><a href="#10-3、使用Statefulset" class="headerlink" title="10.3、使用Statefulset"></a>10.3、使用Statefulset</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102165941862.png" alt="image-20201102165941862" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102170030890.png" alt="image-20201102170030890" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102170422283.png" alt="image-20201102170422283" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102170440880.png" alt="image-20201102170440880" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102170635376.png" alt="image-20201102170635376" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102170808627.png" alt="image-20201102170808627" style="zoom:50%;" />

<h3 id="10-3-3、使用你的Pod"><a href="#10-3-3、使用你的Pod" class="headerlink" title="10.3.3、使用你的Pod"></a>10.3.3、使用你的Pod</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102171112114.png" alt="image-20201102171112114" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102171145416.png" alt="image-20201102171145416" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102171247670.png" alt="image-20201102171247670" style="zoom:50%;" />

<h2 id="10-4、在Statefulset中发现伙伴节点"><a href="#10-4、在Statefulset中发现伙伴节点" class="headerlink" title="10.4、在Statefulset中发现伙伴节点"></a>10.4、在Statefulset中发现伙伴节点</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102171439575.png" alt="image-20201102171439575" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102171528055.png" alt="image-20201102171528055" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102171633946.png" alt="image-20201102171633946" style="zoom:50%;" />

<blockquote>
<p>注意：返回的SRV记录顺序是随机的， 因为它们拥有相同的优先级。 所以不要 期望总是看到kubia-0会排在kubia-1前面</p>
</blockquote>
<h3 id="10-4-1、通过DNS实现伙伴彼此发现"><a href="#10-4-1、通过DNS实现伙伴彼此发现" class="headerlink" title="10.4.1、通过DNS实现伙伴彼此发现"></a>10.4.1、通过DNS实现伙伴彼此发现</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102171813230.png" alt="image-20201102171813230" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102171838453.png" alt="image-20201102171838453" style="zoom:50%;" />

<h3 id="10-4-2、更新Statefulset"><a href="#10-4-2、更新Statefulset" class="headerlink" title="10.4.2、更新Statefulset"></a>10.4.2、更新Statefulset</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 修改 ymal 中的 image 属性</span></span><br><span class="line">kubectl edit statefulset kubia</span><br></pre></td></tr></table></figure>
<p>在 Kubernetes 1.7 及以后的版本中，StatefulSet 的 <code>.spec.updateStrategy</code> 字段让您可以配置和禁用掉自动滚动更新 Pod 的容器、标签、资源请求或限制、以及注解。</p>
<p><code>RollingUpdate</code> 更新策略对 StatefulSet 中的 Pod 执行自动的滚动更新。在没有声明 <code>.spec.updateStrategy</code> 时，<code>RollingUpdate</code> 是默认配置。 当 StatefulSet 的 <code>.spec.updateStrategy.type</code> 被设置为 <code>RollingUpdate</code> 时，StatefulSet 控制器会删除和重建 StatefulSet 中的每个 Pod。 它将按照与 Pod 终止相同的顺序（从最大序号到最小序号）进行，每次更新一个 Pod。它会等到被更新的 Pod 进入 Running 和 Ready 状态，然后再更新其前一个。</p>
<p>在默认 <a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/#pod-management-policies">Pod 管理策略</a>(<code>OrderedReady</code>) 时使用 <a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/#rolling-updates">滚动更新</a> ，可能进入需要人工干预才能修复的损坏状态。如果更新后 Pod 模板配置进入无法运行或就绪的状态（例如，由于错误的二进制文件或应用程序级配置错误）StatefulSet 将停止回滚并等待。在这种状态下，仅将 Pod 模板还原为正确的配置是不够的。由于 <a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/issues/67250">已知问题</a>，StatefulSet 将继续等待损坏状态的 Pod 准备就绪（永远不会发生），然后再尝试将其恢复为正常工作配置。恢复模板后，还必须删除更新导致的异常 Pod。这样， StatefulSet 才会开始使用被还原的模板来重新创建 Pod。</p>
<h2 id="10-5、了解Statefulset如何处理节点失效"><a href="#10-5、了解Statefulset如何处理节点失效" class="headerlink" title="10.5、了解Statefulset如何处理节点失效"></a>10.5、了解Statefulset如何处理节点失效</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102172633847.png" alt="image-20201102172633847" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102172809924.png" alt="image-20201102172809924" style="zoom:50%;" />

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在节点断网的情况下，pod是无法正常删除的</span></span><br><span class="line">kubectl delete pod kubia-0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 告诉API服务器直接删除Pod</span></span><br><span class="line">kubectl delete po kubia-0 --force --grace-period 0</span><br></pre></td></tr></table></figure>
<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102173009632.png" alt="image-20201102173009632" style="zoom:50%;" />

<h2 id="10-6、本章小结"><a href="#10-6、本章小结" class="headerlink" title="10.6、本章小结"></a>10.6、本章小结</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201102173036545.png" alt="image-20201102173036545" style="zoom:50%;" />

<h1 id="11、了解Kubernetes机理"><a href="#11、了解Kubernetes机理" class="headerlink" title="11、了解Kubernetes机理"></a>11、了解Kubernetes机理</h1><h2 id="11-1、了解架构"><a href="#11-1、了解架构" class="headerlink" title="11.1、了解架构"></a>11.1、了解架构</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103120440329.png" alt="image-20201103120440329" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103120509226.png" alt="image-20201103120509226" style="zoom:50%;" />

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 检查控制平面组件状态</span></span><br><span class="line">kubectl get componentstatuses</span><br></pre></td></tr></table></figure>
<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103120633871.png" alt="image-20201103120633871" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103120752246.png" alt="image-20201103120752246" style="zoom:50%;" />

<h3 id="11-1-2、kubernetes如何使用Pod"><a href="#11-1-2、kubernetes如何使用Pod" class="headerlink" title="11.1.2、kubernetes如何使用Pod"></a>11.1.2、kubernetes如何使用Pod</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103121114246.png" alt="image-20201103121114246" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103121239402.png" alt="image-20201103121239402" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103121331428.png" alt="image-20201103121331428" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103121403034.png" alt="image-20201103121403034" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103121443503.png" alt="image-20201103121443503" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103121547840.png" alt="image-20201103121547840" style="zoom:50%;" />

<h3 id="11-1-3、API服务器做了什么"><a href="#11-1-3、API服务器做了什么" class="headerlink" title="11.1.3、API服务器做了什么"></a>11.1.3、API服务器做了什么</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103121713961.png" alt="image-20201103121713961" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103121741106.png" alt="image-20201103121741106" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103121848706.png" alt="image-20201103121848706" style="zoom:50%;" />

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">认证-》授权-》准入控制（请求合法性判断）</span><br></pre></td></tr></table></figure>
<h3 id="11-1-4、API服务器如何通知客户端资源变更"><a href="#11-1-4、API服务器如何通知客户端资源变更" class="headerlink" title="11.1.4、API服务器如何通知客户端资源变更"></a>11.1.4、API服务器如何通知客户端资源变更</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103122313362.png" alt="image-20201103122313362" style="zoom:50%;" />

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 打印出整个监听事件的YMAL文件</span></span><br><span class="line">kubect1 get pods -o yaml --watch</span><br></pre></td></tr></table></figure>
<h3 id="11-1-4、List-Watch机制和Informer模块（补充）"><a href="#11-1-4、List-Watch机制和Informer模块（补充）" class="headerlink" title="11.1.4、List-Watch机制和Informer模块（补充）"></a>11.1.4、List-Watch机制和Informer模块（补充）</h3><p><code>Etcd</code>存储集群的数据信息，<code>apiserver</code>作为统一入口，任何对数据的操作都必须经过<code>apiserver</code>。客户端(<code>kubelet</code>/<code>scheduler</code>/<code>controller-manager</code>)通过<code>list-watch</code>监听<code>apiserver</code>中资源(<code>pod/rs/rc</code>等等)的<code>create</code>,<code>update</code>和<code>delete</code>事件，并针对<code>事件类型</code>调用相应的<code>事件处理函数</code>。</p>
<p>那么<code>list-watch</code>具体是什么呢，顾名思义，<code>list-watch</code>有两部分组成，分别是<code>list</code>和<code>watch</code>。<code>list</code>非常好理解，就是调用资源的<code>list API</code>罗列资源，基于<code>HTTP</code>短链接<code>实现；</code>watch<code>则是调用资源的</code>watch API<code>监听资源变更事件，基于</code>HTTP 长链接<code>实现，也是本文重点分析的对象。以</code>pod 资源<code>为例，它的</code>list<code>和</code>watch API<code>分别为：</code></p>
<blockquote>
<p>GET /api/v1/pods</p>
</blockquote>
<p><a href="https://link.zhihu.com/?target=https://v1-10.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/%23watch-list-all-namespaces-66">Watch API</a>，往往带上<code>watch=true</code>，表示采用<code>HTTP 长连接</code>持续监听<code>pod 相关事件</code>，每当有事件来临，返回一个<a href="https://link.zhihu.com/?target=https://v1-10.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/%23watchevent-v1-meta">WatchEvent</a>。</p>
<blockquote>
<p>GET /api/v1/watch/pods</p>
</blockquote>
<p><code>K8S</code>的<code>informer</code>模块封装<code>list-watch API</code>，用户只需要指定资源，编写事件处理函数，<code>AddFunc</code>,<code>UpdateFunc</code>和<code>DeleteFunc</code>等。如下图所示，<code>informer</code>首先通过<code>list API</code>罗列资源，然后调用<code>watch API</code>监听资源的变更事件，并将结果放入到一个<code>FIFO 队列</code>，队列的另一头有协程从中取出事件，并调用对应的注册函数处理事件。<code>Informer</code>还维护了一个只读的<code>Map Store</code>缓存，主要为了提升查询的效率，降低<code>apiserver</code>的负载。</p>
<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103123358079.png" alt="image-20201103123358079" style="zoom:50%;" />

<p><code>list API</code>可以查询当前的资源及其对应的状态(即期望的状态)，客户端通过拿<code>期望的状态</code>和<code>实际的状态</code>进行对比，纠正状态不一致的资源。<code>Watch API</code> 和 <code>apiserver</code>保持一个<code>长链接</code>，接收资源的<code>状态变更事件</code>并做相应处理。如果仅调用 <code>watch API</code>，若某个时间点连接中断，就有可能导致消息丢失，所以需要通过**<code>list API</code>解决<code>消息丢失</code>的问题<strong>。从另一个角度出发，</strong>我们可以认为<code>list API</code>获取全量数据，<code>watch API</code>获取增量数据**。虽然仅仅通过轮询 <code>list API</code>，也能达到同步资源状态的效果，但是存在开销大，实时性不足的问题。</p>
<p>消息必须是实时的，<code>list-watch</code> 机制下，每当<code>apiserver</code> 的资源产生<code>状态变更事件</code>，都会将事件及时的推送给客户端，从而保证了<code>消息的实时性</code>。</p>
<p>消息的顺序性也是非常重要的，在并发的场景下，客户端在短时间内可能会收到同一个资源的多个事件，对于<code>关注最终一致性</code>的 <code>K8S</code> 来说，它需要知道哪个是最近发生的事件，并保证资源的最终状态如同最近事件所表述的状态一样。**<code>K8S</code> 在每个资源的事件中都带一个 <code>resourceVersion</code>的标签，这个标签是递增的数字，所以当客户端并发处理同一个资源的事件时，它就可以对比 <code>resourceVersion</code>来保证最终的状态和最新的事件所期望的状态保持一致。**</p>
<p><code>List-watch</code> 还具有高性能的特点，虽然仅通过周期性调用<code>list API</code>也能达到资源最终一致性的效果，但是周期性频繁的轮询大大的增大了开销，增加<code>apiserver</code>的压力。而**<code>watch</code> 作为异步消息通知机制，复用一条长链接，保证实时性的同时也保证了性能。**</p>
<p><strong><code>Informer</code> 是 <code>Client-go</code> 中的一个核心工具包</strong>。在<code>Kubernetes</code>源码中，如果 <code>Kubernetes</code> 的某个组件，需要 <code>List/Get Kubernetes</code> 中的 <code>Object</code>，在绝大多 数情况下，会直接使用<code>Informer</code>实例中的<code>Lister()</code>方法（该方法包含 了 Get 和 List 方法），而很少直接请求<code>Kubernetes API</code>。<code>Informer</code> 最基本 的功能就是<code>List/Get Kubernetes</code>中的 <code>Object</code>。</p>
<p>二级缓存属于 <code>Informer</code>的底层缓存机制，这两级缓存分别是<code>DeltaFIFO</code>（上图的FIFO）和 <code>LocalStore</code>（上图的MapStore）。</p>
<p>这两级缓存的用途各不相同。<code>DeltaFIFO</code>用来存储<code>Watch API</code>返回的各种事件 ，<code>LocalStore</code> 只会被<code>Lister</code>的<code>List/Get</code>方法访问 。</p>
<p>虽然<code>Informer</code>和 <code>Kubernetes</code> 之间没有<code>resync</code>机制，但<code>Informer</code>内部的这两级缓存之间存在<code>resync</code> 机制。</p>
<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103123852828.png" alt="image-20201103123852828" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103123908623.png" alt="image-20201103123908623" style="zoom:50%;" />

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Informer 在初始化时，Reflector 会先 List API 获得所有的 Pod</span><br><span class="line"></span><br><span class="line">Reflect 拿到全部 Pod 后，会将全部 Pod 放到 Store 中</span><br><span class="line"></span><br><span class="line">如果有人调用 Lister 的 List&#x2F;Get 方法获取 Pod， 那么 Lister 会直接从 Store 中拿数据</span><br><span class="line"></span><br><span class="line">Informer 初始化完成之后，Reflector 开始 Watch Pod，监听 Pod 相关 的所有事件;如果此时 pod_1 被删除，那么 Reflector 会监听到这个事件</span><br><span class="line"></span><br><span class="line">Reflector 将 pod_1 被删除 的这个事件发送到 DeltaFIFO</span><br><span class="line"></span><br><span class="line">DeltaFIFO 首先会将这个事件存储在自己的数据结构中(实际上是一个 queue)，然后会直接操作 Store 中的数据，删除 Store 中的 pod_1</span><br><span class="line"></span><br><span class="line">DeltaFIFO 再 Pop 这个事件到 Controller 中</span><br><span class="line"></span><br><span class="line">Controller 收到这个事件，会触发 Processor 的回调函数</span><br><span class="line"></span><br><span class="line">LocalStore 会周期性地把所有的 Pod 信息重新放到 DeltaFIFO 中</span><br></pre></td></tr></table></figure>
<h3 id="11-1-5、了解调度器"><a href="#11-1-5、了解调度器" class="headerlink" title="11.1.5、了解调度器"></a>11.1.5、了解调度器</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103124849015.png" alt="image-20201103124849015" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103124906385.png" alt="image-20201103124906385" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103124941316.png" alt="image-20201103124941316" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103125037636.png" alt="image-20201103125037636" style="zoom:50%;" />

<h3 id="11-1-6、了解控制器"><a href="#11-1-6、了解控制器" class="headerlink" title="11.1.6、了解控制器"></a>11.1.6、了解控制器</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103143823328.png" alt="image-20201103143823328" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103143958883.png" alt="image-20201103143958883" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103144114929.png" alt="image-20201103144114929" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103144221645.png" alt="image-20201103144221645" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103144321381.png" alt="image-20201103144321381" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103144417102.png" alt="image-20201103144417102" style="zoom:50%;" />

<h3 id="11-1-7、kubelet-做了什么"><a href="#11-1-7、kubelet-做了什么" class="headerlink" title="11.1.7、kubelet 做了什么"></a>11.1.7、kubelet 做了什么</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103144535765.png" alt="image-20201103144535765" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103144608799.png" alt="image-20201103144608799" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103144708330.png" alt="image-20201103144708330" style="zoom:50%;" />

<h3 id="11-1-8、Kubernetes-Service-Proxy-的作用"><a href="#11-1-8、Kubernetes-Service-Proxy-的作用" class="headerlink" title="11.1.8、Kubernetes Service Proxy 的作用"></a>11.1.8、Kubernetes Service Proxy 的作用</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103144817911.png" alt="image-20201103144817911" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103145818656.png" alt="image-20201103145818656" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103145922754.png" alt="image-20201103145922754" style="zoom:50%;" />

<h3 id="11-1-9、介绍Kubernetes-插件"><a href="#11-1-9、介绍Kubernetes-插件" class="headerlink" title="11.1.9、介绍Kubernetes 插件"></a>11.1.9、介绍Kubernetes 插件</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103150025179.png" alt="image-20201103150025179" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103150153694.png" alt="image-20201103150153694" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103150237837.png" alt="image-20201103150237837" style="zoom:50%;" />

<h2 id="11-2、控制器如何协作"><a href="#11-2、控制器如何协作" class="headerlink" title="11.2、控制器如何协作"></a>11.2、控制器如何协作</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103150340604.png" alt="image-20201103150340604" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103150355178.png" alt="image-20201103150355178" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103150421443.png" alt="image-20201103150421443" style="zoom:50%;" />



<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103150659586.png" alt="image-20201103150659586" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103150731909.png" alt="image-20201103150731909" style="zoom:50%;" />

<h3 id="11-2-3、观察集群事件"><a href="#11-2-3、观察集群事件" class="headerlink" title="11.2.3、观察集群事件"></a>11.2.3、观察集群事件</h3><p>控制平面组件和Kubelet执行动作时，都会发送事件给API服务器。<strong>发送事件是通过创建事件资源来实现的，事件资源和其他的Kubemetes资源类似</strong>。每次使用 kubectl describe来检查资源的时候，就能看到资源相关的事件，也可以直接用kubectl get events获取事件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 观察控制器发出的事件</span></span><br><span class="line">kubectl get events --watch</span><br></pre></td></tr></table></figure>
<h2 id="11-3、了解运行中的Pod是什么"><a href="#11-3、了解运行中的Pod是什么" class="headerlink" title="11.3、了解运行中的Pod是什么"></a>11.3、了解运行中的Pod是什么</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103151847139.png" alt="image-20201103151847139" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103151917126.png" alt="image-20201103151917126" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103152016071.png" alt="image-20201103152016071" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103152055867.png" alt="image-20201103152055867" style="zoom:50%;" />

<h2 id="11-4、跨Pod网络"><a href="#11-4、跨Pod网络" class="headerlink" title="11.4、跨Pod网络"></a>11.4、跨Pod网络</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103152242340.png" alt="image-20201103152242340" style="zoom:50%;" />

<h3 id="11-4-1、网络应该是什么样的"><a href="#11-4-1、网络应该是什么样的" class="headerlink" title="11.4.1、网络应该是什么样的"></a>11.4.1、网络应该是什么样的</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103152408024.png" alt="image-20201103152408024" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103152440868.png" alt="image-20201103152440868" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103152529695.png" alt="image-20201103152529695" style="zoom:50%;" />

<h3 id="11-4-2、深入了解网络工作原理"><a href="#11-4-2、深入了解网络工作原理" class="headerlink" title="11.4.2、深入了解网络工作原理"></a>11.4.2、深入了解网络工作原理</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103152632534.png" alt="image-20201103152632534" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103152659765.png" alt="image-20201103152659765" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103153007056.png" alt="image-20201103153007056" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103153046724.png" alt="image-20201103153046724" style="zoom:50%;" />

<h3 id="11-4-3、引入容器网络接口"><a href="#11-4-3、引入容器网络接口" class="headerlink" title="11.4.3、引入容器网络接口"></a>11.4.3、引入容器网络接口</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103153137683.png" alt="image-20201103153137683" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103153202289.png" alt="image-20201103153202289" style="zoom:50%;" />

<h2 id="11-5、服务是如何实现的"><a href="#11-5、服务是如何实现的" class="headerlink" title="11.5、服务是如何实现的"></a>11.5、服务是如何实现的</h2><h3 id="11-5-1、引入kube-proxy"><a href="#11-5-1、引入kube-proxy" class="headerlink" title="11.5.1、引入kube-proxy"></a>11.5.1、引入kube-proxy</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103153434714.png" alt="image-20201103153434714" style="zoom:50%;" />

<h3 id="11-5-2、kube-proxy-如何使用-iptables"><a href="#11-5-2、kube-proxy-如何使用-iptables" class="headerlink" title="11.5.2、kube-proxy 如何使用 iptables"></a>11.5.2、kube-proxy 如何使用 iptables</h3><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103153803829.png" alt="image-20201103153803829" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103153848672.png" alt="image-20201103153848672" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103153906092.png" alt="image-20201103153906092" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103153928025.png" alt="image-20201103153928025" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103153942909.png" alt="image-20201103153942909" style="zoom:50%;" />

<h2 id="11-6、运行高可用集群"><a href="#11-6、运行高可用集群" class="headerlink" title="11.6、运行高可用集群"></a>11.6、运行高可用集群</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103154429762.png" alt="image-20201103154429762" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103154501801.png" alt="image-20201103154501801" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103154514484.png" alt="image-20201103154514484" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103154613368.png" alt="image-20201103154613368" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103154709138.png" alt="image-20201103154709138" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103154846841.png" alt="image-20201103154846841" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103154923039.png" alt="image-20201103154923039" style="zoom:50%;" />

<h2 id="11-7、本章小结"><a href="#11-7、本章小结" class="headerlink" title="11.7、本章小结"></a>11.7、本章小结</h2><img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103154950505.png" alt="image-20201103154950505" style="zoom:50%;" />

<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><h2 id="1、pause-系统调用"><a href="#1、pause-系统调用" class="headerlink" title="1、pause()系统调用"></a>1、pause()系统调用</h2><p>pause（）系统调用用于使调用进程或调用线程休眠，直到发生以下事件之一。</p>
<ul>
<li>调用进程接收的信号的默认行为是终止进程。</li>
<li>信号处理程序执行完毕。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.nayab.xyz/man2/pause-system-call-in-c">pause() system call in C - explained with examples</a></p>
<h1 id="2、pause容器的作用"><a href="#2、pause容器的作用" class="headerlink" title="2、pause容器的作用"></a>2、pause容器的作用</h1><p>在Kubernetes中，pause容器充当pod中所有容器的“父容器”。暂停容器有两个核心职责。首先，它是pod中Linux名称空间共享的基础。其次，在启用PID（processid）命名空间共享的情况下，它充当每个pod的PID 1，并重新捕获僵尸进程。</p>
<p><a target="_blank" rel="noopener" href="https://www.ianlewis.org/en/almighty-pause-container">The Almighty Pause Container</a></p>
<h1 id="3、Kubernetes-如何利用iptables"><a href="#3、Kubernetes-如何利用iptables" class="headerlink" title="3、Kubernetes 如何利用iptables"></a>3、Kubernetes 如何利用iptables</h1><p><a target="_blank" rel="noopener" href="http://www.dbsnake.net/how-kubernetes-use-iptables.html">Kubernetes如何利用iptables</a></p>
<h1 id="4、ipvs"><a href="#4、ipvs" class="headerlink" title="4、ipvs"></a>4、ipvs</h1><p><em>ipvs</em>称之为IP虚拟服务器（IP Virtual Server，简写为<em>IPVS</em>）。是运行在LVS下的提供负载平衡功能的一种技术。</p>
<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103170056935.png" alt="image-20201103170056935" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103165925802.png" alt="image-20201103165925802" style="zoom:50%;" />

<img src="/Users/shenshawn/Library/Application Support/typora-user-images/image-20201103165954417.png" alt="image-20201103165954417" style="zoom:50%;" />

<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/d10bf4086644?utm_campaign=hugo&utm_content=note&utm_medium=seo_notes&utm_source=recommendation">k8s网络原理-ipvs</a></p>
<h1 id="5、ipvs-与-iptables"><a href="#5、ipvs-与-iptables" class="headerlink" title="5、ipvs 与 iptables"></a>5、ipvs 与 iptables</h1><p>kube-proxy 处理 iptables规则的方式意味着它名义上是一个O（n）风格的算法，其中n大致与集群大小成比例增长（或者更准确地说是服务数量和每个服务背后的后端pod数量）。</p>
<p>在IPVS模式下kube-proxy的连接处理具有O（1）的名义计算复杂度。换句话说，在大多数情况下，它的连接处理性能将保持不变，与集群大小无关。</p>
<p>此外，作为一个专用的负载均衡器，IPVS拥有多种不同的调度算法，如循环调度、最短预期延迟、最少连接和各种哈希方法。相比之下，iptables中的kube-proxy使用随机等成本选择算法。</p>
<blockquote>
<p>个人注释：这篇文章很好</p>
<p><a target="_blank" rel="noopener" href="https://www.projectcalico.org/comparing-kube-proxy-modes-iptables-or-ipvs/">Comparing kube-proxy modes: iptables or IPVS?</a></p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/heavyfish.github.io/page/2/">2</a><a class="extend next" rel="next" href="/heavyfish.github.io/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Shenxr</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/heavyfish.github.io/archives/">
        
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Shenxr</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/heavyfish.github.io/lib/anime.min.js"></script>
  <script src="/heavyfish.github.io/lib/velocity/velocity.min.js"></script>
  <script src="/heavyfish.github.io/lib/velocity/velocity.ui.min.js"></script>

<script src="/heavyfish.github.io/js/utils.js"></script>

<script src="/heavyfish.github.io/js/motion.js"></script>


<script src="/heavyfish.github.io/js/schemes/pisces.js"></script>


<script src="/heavyfish.github.io/js/next-boot.js"></script>




  















  

  

</body>
</html>
